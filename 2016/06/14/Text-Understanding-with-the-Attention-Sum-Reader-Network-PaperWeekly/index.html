<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>Text Understanding with the Attention Sum Reader Network #PaperWeekly#</title>
  
   <meta name="description" content="本文是机器阅读系列的第四篇文章，本文的模型常出现在最新的机器阅读paper中related works部分，也是很多更好的模型的基础模型，所以很有必要来看下这篇paper，看得远往往不是因为长得高，而是因为站得高。本文的题目是Text Understanding with the Attention">
  

  <meta property="og:title" content="Text Understanding with the Attention Sum Reader Network #PaperWeekly#"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="PaperWeekly"/>
 <meta property="og:image" content="undefined"/>
  
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="main">
    <div class="behind">
      <div class="back">
        <a href="/" class="black-color"><i class="fa fa-times" aria-hidden="true"></i></a>
      </div>
      <div class="description">
        &nbsp;
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        Text Understanding with the Attention Sum Reader Network #PaperWeekly#
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2016-06-15T04:31:36.000Z">
  <i class="fa fa-calendar"></i>&nbsp;
  2016-06-14
</time>






    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/tags/nlp/">nlp</a>·<a href="/tags/PaperWeekly/">PaperWeekly</a>·<a href="/tags/Reading-Comprehension/">Reading Comprehension</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <p>本文是机器阅读系列的第四篇文章，本文的模型常出现在最新的机器阅读paper中related works部分，也是很多更好的模型的基础模型，所以很有必要来看下这篇paper，看得远往往不是因为长得高，而是因为站得高。本文的题目是<a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="external">Text Understanding with the Attention Sum Reader Network</a>，作者是来自IBM Watson的研究员Rudolf Kadlec，paper最早于2016年3月4日submit在arxiv上。</p>
<p>本文的模型被称作Attention Sum Reader，具体见下图：</p>
<img src="/2016/06/14/Text-Understanding-with-the-Attention-Sum-Reader-Network-PaperWeekly/fig1.png" width="600" height="600">
<p><b>step 1</b> 通过一层Embedding层将document和query中的word分别映射成向量。</p>
<p><b>step 2</b> 用一个单层双向GRU来encode document，得到context representation，每个time step的拼接来表示该词。</p>
<p><b>step 3</b> 用一个单层双向GRU来encode query，用两个方向的last state拼接来表示query。</p>
<p><b>step 4</b> 每个word vector与query vector作点积后归一化的结果作为attention weights，就query与document中的每个词之前的相关性度量。</p>
<p><b>step 5</b> 最后做一次相同词概率的合并，得到每个词的概率，最大概率的那个词即为answer。</p>
<p>模型在CNN/Daily Mail和CBT的Nouns、Named Entity数据集上进行了测试，在当时的情况下都取得了领先的结果。并且得到了一些有趣的结论，比如：在CNN/Daily Mail数据集上，随着document的长度增加，测试的准确率会下降，而在CBT数据集上得到了相反的结论。从中可以看得出，两个数据集有着不同的特征，构造方法也不尽相同，因此同一个模型会有着不同的趋势。</p>
<p>本文的模型相比于Attentive Reader和Impatient Reader更加简单，没有那么多繁琐的attention求解过程，只是用了点乘来作为weights，却得到了比Attentive Reader更好的结果，从这里我们看得出，并不是模型越复杂，计算过程越繁琐就效果一定越好，更多的时候可能是简单的东西会有更好的效果。</p>
<p>另外，在这几篇paper中的related works中，都会提到用Memory Networks来解决这个问题。接下来的文章将会分享Memory Networks在机器阅读理解中的应用，大家敬请关注。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    页阅读量:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    站访问量:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    站访客数:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>




    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" >
        <i class="fa fa-arrow-right"></i>
        </a>
        © XXX 2015-2016
    </div>
    <div class="secondrow">
        <a href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.js"></script>
<script type="text/javascript">

// comments below to disable loading animation
function revealOnScroll() {
  var scrolled = $(window).scrollTop();
  $(".excerpt, .index-title, .index-meta, p").each(function() {
    var current = $(this),
      height = $(window).outerHeight(),
      offsetTop = current.offset().top;
    (scrolled + height + 50 > offsetTop) ? current.addClass("animation"):'';
  });
}
$(window).on("scroll", revealOnScroll);
$(document).ready(revealOnScroll)

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

// back to top scripts
$("a[href='#top']").click(function() {
  $("html, body").animate({ scrollTop: 0 }, 500);
  return false;
});


var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
