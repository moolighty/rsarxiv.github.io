<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>Semi-supervised Sequence Learning #PaperWeekly#</title>
  
   <meta name="description" content="(欢迎大家订阅本博客，订阅地址是RSS)
之前分享过几篇有监督的sentence表示方法，比如Recurrent Convolutional Neural Networks for Text Classification、Convolutional Neural Networks for Sente">
  

  <meta property="og:title" content="Semi-supervised Sequence Learning #PaperWeekly#"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="PaperWeekly"/>
 <meta property="og:image" content="undefined"/>
  
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="main">
    <div class="behind">
      <div class="back">
        <a href="/" class="black-color"><i class="fa fa-times" aria-hidden="true"></i></a>
      </div>
      <div class="description">
        &nbsp;
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        Semi-supervised Sequence Learning #PaperWeekly#
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2016-06-07T14:11:34.000Z">
  <i class="fa fa-calendar"></i>&nbsp;
  2016-06-07
</time>






    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/tags/nlp/">nlp</a>·<a href="/tags/PaperWeekly/">PaperWeekly</a>·<a href="/tags/seq2seq/">seq2seq</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <p>(欢迎大家订阅本博客，订阅地址是<a href="http://rsarxiv.github.io/atom.xml">RSS</a>)</p>
<p>之前分享过几篇有监督的sentence表示方法，比如<a href="http://rsarxiv.github.io/2016/05/27/Recurrent-Convolutional-Neural-Networks-for-Text-Classification-PaperWeekly/">Recurrent Convolutional Neural Networks for Text Classification</a>、<a href="http://rsarxiv.github.io/2016/05/25/Convolutional-Neural-Networks-for-Sentence-Classification-PaperWeekly/">Convolutional Neural Networks for Sentence Classification</a>，也分享过很多几篇无监督的sentence表示方法，比如<a href="http://rsarxiv.github.io/2016/05/24/Distributed-Representations-of-Sentences-and-Documents-PaperWeekly/">Distributed Representations of Sentences and Documents</a>、<a href="http://rsarxiv.github.io/2016/05/28/Skip-Thought-Vectors-PaperWeekly/">Skip-Thought Vectors</a>。本篇将分享是一篇半监督的sentence表示方法，该方法比Paragraph Vectors更容易做微调，与Skip-Thought相比，目标函数并没有它那么困难，因为Skip-Thought是用来预测相邻句子的。本文的题目是<a href="http://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="external">Semi-supervised Sequence Learning</a>，作者是来自Google的<a href="http://homepages.inf.ed.ac.uk/s0681274/About_Me.html" target="_blank" rel="external">Andrew M. Dai</a>博士。</p>
<p>纯粹的有监督学习是通过神经网络来表示一个句子，然后通过分类任务数据集去学习网络参数；而纯粹的无监督学习是通过上文预测下文来学习句子表示，利用得到的表示进行分类任务。本文的方法将无监督学习之后的表示作为有监督训练模型的初始值，所以称为半监督。本文的有监督模型采用LSTM，无监督模型共两种，一种是自编码器，一种是循环神经网络语言模型。</p>
<p>第一种模型称为Sequence AutoEncoder LSTM(SA-LSTM)，模型架构图如下：</p>
<img src="/2016/06/07/Semi-supervised-Sequence-Learning-PaperWeekly/fig1.png" width="400" height="400">
<p>这幅图大家看着都眼熟，和<a href="http://rsarxiv.github.io/2016/05/31/Sequence-to-Sequence-Learning-with-Neural-Networks-PaperWeekly/">Sequence to Sequence Learning with Neural Networks</a>中的seq2seq架构图很相似，只不过target和input一样，即用input来预测input自己。将自编码器学习到的表示作为LSTM的初始值，进行有监督训练。一般来说用LSTM中的最后一个hidden state作为输出，但本文也尝试用了每个hidden state权重递增的线性组合作为输出。这两种思路都是将无监督和有监督分开训练，本文也提供了一种联合训练的思路作为对比，称为joint learning。</p>
<p>第二种模型称为Language Model LSTM(LM-LSTM)，将上图中的encoder部分去掉就是LM模型。语言模型介绍过很多了，比如<a href="http://rsarxiv.github.io/2016/05/20/A-Neural-Probabilistic-Language-Model-PaperWeekly/">A Neural Probabilistic Language Model</a>和<a href="http://rsarxiv.github.io/2016/05/23/Character-Aware-Neural-Language-Models-PaperWeekly/">Character-Aware Neural Language Models</a>，详细的可以看之前的分享，这里不再赘述了。</p>
<p>模型部分就是这些，后面作者在情感分析、文本分类、目标分类等多组任务中进行了对比实验，均取得了不错的结果。</p>
<p>本文的创新点在于结合了无监督和有监督学习两种思路的优点来解决一个传统问题，虽然说无监督是一种趋势所在，但有监督针对具体的问题会有更好的效果。这种融合各类模型优点的模型会更受欢迎，也是一种不错的思路。</p>
<p>这里进行几点说明：</p>
<p>1、为什么不对实验结果进行详细的介绍？</p>
<p>因为我个人更加关注的是解决问题的思路，也就是模型部分；另一方面，paper中的实验结果只能在某些程度上说明问题，对比结果中的数据可能是作者精心挑选的最好数据，并不一定可以复现，所以我不会太纠结于到底哪个模型比哪个模型高几个百分点。而文中的模型思路会带给我更多的启发，所以更加有意义一些。</p>
<p>2、为什么内容总是这么短？</p>
<p>因为我对PaperWeekly的定位是每天一篇或者几天一篇的paper短文介绍和理解，并不是详细地剖析它，我希望内容尽可能短，大家可以用5-10分钟来明白一篇文章的贡献和创新点在哪里，更多的是为了带给大家更多的思考或者说是启发。另外一个方面，短的文章我写起来也会很快，基本上都是前一晚睡觉前来读，六点半早起来写，不影响一天的正常工作生活，却一天一天地在积累着。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    页阅读量:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    站访问量:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    站访客数:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>




    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" >
        <i class="fa fa-arrow-right"></i>
        </a>
        © XXX 2015-2016
    </div>
    <div class="secondrow">
        <a href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.js"></script>
<script type="text/javascript">

// comments below to disable loading animation
function revealOnScroll() {
  var scrolled = $(window).scrollTop();
  $(".excerpt, .index-title, .index-meta, p").each(function() {
    var current = $(this),
      height = $(window).outerHeight(),
      offsetTop = current.offset().top;
    (scrolled + height + 50 > offsetTop) ? current.addClass("animation"):'';
  });
}
$(window).on("scroll", revealOnScroll);
$(document).ready(revealOnScroll)

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

// back to top scripts
$("a[href='#top']").click(function() {
  $("html, body").animate({ scrollTop: 0 }, 500);
  return false;
});


var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
