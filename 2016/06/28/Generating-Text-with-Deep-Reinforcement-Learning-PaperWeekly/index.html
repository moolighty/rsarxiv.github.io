<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>Generating Text with Deep Reinforcement Learning #PaperWeekly#</title>
  
   <meta name="description" content="上一篇介绍了DQN在文字游戏中的应用，本文将分享一篇DQN在文本生成中的应用，将一个领域的知识迁移到其他领域应用的时候，都需要做概念上的等效替换，比如context可以替换为state，被预测的word可以替换为action。本文分享的题目是Generating Text with Deep Rei">
  

  <meta property="og:title" content="Generating Text with Deep Reinforcement Learning #PaperWeekly#"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="PaperWeekly"/>
 <meta property="og:image" content="undefined"/>
  
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="main">
    <div class="behind">
      <div class="back">
        <a href="/" class="black-color"><i class="fa fa-times" aria-hidden="true"></i></a>
      </div>
      <div class="description">
        &nbsp;
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        Generating Text with Deep Reinforcement Learning #PaperWeekly#
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2016-06-28T17:19:32.000Z">
  <i class="fa fa-calendar"></i>&nbsp;
  2016-06-28
</time>






    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/tags/nlp/">nlp</a>·<a href="/tags/PaperWeekly/">PaperWeekly</a>·<a href="/tags/DQN/">DQN</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <p>上一篇介绍了DQN在文字游戏中的应用，本文将分享一篇DQN在文本生成中的应用，将一个领域的知识迁移到其他领域应用的时候，都需要做概念上的等效替换，比如context可以替换为state，被预测的word可以替换为action。本文分享的题目是<a href="http://arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a>，作者是来自National Research Council of Canada的<a href="http://www.site.uottawa.ca/~hguo028/mainpage.htm" target="_blank" rel="external">Hongyu Guo</a>研究员，文章最早于2015年10月30日submit在arxiv上。</p>
<p>语言模型往往用来生成文本，在很多例子中都有应用，比如：自动文摘、bot、机器翻译、QA等等。本文想要做的事情是用DQN来生成文本，起到一个语言模型的作用，并且这是第一次尝试用DQN来生成文本。仔细想想，DQN在解决video games时遇到的情况和现在不同，state可能还好，可生成的action数量远远大于游戏中action的数量，所以，如何解决action的问题对于DQN在NLP中的应用前景至关重要。目前来看，读此类的paper，需要关注的有两个部分：</p>
<p>1、action规模的问题如何解决？</p>
<p>2、DQN中每条数据集包含的元素与NLP问题中各个元素的对应关系。</p>
<p>本文解决第一个问题采用的方法是，用传统的语言模型decoder来为DQN的action生成candidated actions，虽然这个actions集合是动态，但对于每一条数据来说，action的数量只有很少了，与video games差不太多了。</p>
<p>NLP不像video games直接可以用游戏画面作为输入，用多层CNN提取feature进行action选择，因为text不仅仅是一个序列，而且是变长度的，所以一般来说也都是RNN来处理。本文模型如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig1.png" width="600" height="500">
<p>首先，回答关心的第二个问题，DQN中各元素的对应关系（transition tuple）。</p>
<p>DQN中：(s(t),a(t),r(t),s(t+1))<br>本文：([EnSen(t),DeSen(t)],y(t),r(t),[EnSen(t),DeSen(t+1)])</p>
<p>整个模型是一个迭代decoding的过程，通过LSTM decoder生成最初的DeSen(t)之后，开始不断地迭代。在decoder的每一个time step，DQN会从DeLSTM使用的词表中选择一个可以获得最大reward的action作为该time step新生成的词，用这个新词来代替之前的旧词，生成新的状态DeSen(t+1)，依次迭代下去，每一次迭代都只生成一个新词来代替旧词，直到最后一个新词被生成。这里的reward r(t)是计算target sentence和DeSen(t+1)的相似度得来的。</p>
<p>本文在这个模型的基础上，尝试了在decoder部分用双向的LSTM来表示，并且用一个光滑的BLEU来做reward。这一点与<a href="http://rsarxiv.github.io/2016/05/17/%E8%87%AA%E5%8A%A8%E6%96%87%E6%91%98%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89/">Neural Headline Generation with Minimum Risk Training</a>这篇文章从某一个角度来说有一点点类似，本文是用最终的评价指标BLEU作为reward，而那篇文章是用ROUGE指标作为优化函数，最终取得了非常令人满意的结果。</p>
<p>整个算法流程大体上都是遵循DQN的框架，只是细节有一些不同，如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig2.png" width="600" height="600">
<p>实验部分，用了10000个sentences作为训练集，source和target是一样的，是一个autoencoder问题，对比了只用LSTM decoder和本文模型的结果，如下表：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig3.png" width="300" height="300">
<p>验证了本文方法的有效性。</p>
<p>本文较前一篇文字游戏的文章更难的一点是处理大量actions的方法，上一篇其实仍旧是个游戏，actions的数量在一个非常有限的范围内，本篇是做语言模型的，actions和词汇表一样大，这是DQN在NLP中应用最头疼的问题。本文用了DeLSTM在每个time step中使用的Top N个词作为候选actions，很好地解决了这个问题，那么到底有没有更好的方法来减少actions呢？有没有不需要用这么复杂的模型来做处理呢？想到一个idea，用char-level来做语言模型，用到的vocabulary size远远小于word-level，对于DQN来说，actions集合非常固定，并且非常小，只是增大了state的表示。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    页阅读量:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    站访问量:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    站访客数:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>




    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" >
        <i class="fa fa-arrow-right"></i>
        </a>
        © XXX 2015-2016
    </div>
    <div class="secondrow">
        <a href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.js"></script>
<script type="text/javascript">

// comments below to disable loading animation
function revealOnScroll() {
  var scrolled = $(window).scrollTop();
  $(".excerpt, .index-title, .index-meta, p").each(function() {
    var current = $(this),
      height = $(window).outerHeight(),
      offsetTop = current.offset().top;
    (scrolled + height + 50 > offsetTop) ? current.addClass("animation"):'';
  });
}
$(window).on("scroll", revealOnScroll);
$(document).ready(revealOnScroll)

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

// back to top scripts
$("a[href='#top']").click(function() {
  $("html, body").animate({ scrollTop: 0 }, 500);
  return false;
});


var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
