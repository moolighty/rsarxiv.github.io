<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>cs.CL weekly 2016.09.19-2016.09.23</title>
  
   <meta name="description" content="一周值得读Long-Term Trends in the Public Perception of Artificial Intelligence本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。">
  

  <meta property="og:title" content="cs.CL weekly 2016.09.19-2016.09.23"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="PaperWeekly"/>
 <meta property="og:image" content="undefined"/>
  
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="main">
    <div class="behind">
      <div class="back">
        <a href="/" class="black-color"><i class="fa fa-times" aria-hidden="true"></i></a>
      </div>
      <div class="description">
        &nbsp;
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        cs.CL weekly 2016.09.19-2016.09.23
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2016-09-24T16:57:50.000Z">
  <i class="fa fa-calendar"></i>&nbsp;
  2016-09-24
</time>






    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/tags/nlp/">nlp</a>·<a href="/tags/PaperWeekly/">PaperWeekly</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence"><a href="#Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence" class="headerlink" title="Long-Term Trends in the Public Perception of Artificial Intelligence"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" target="_blank" rel="external">Long-Term Trends in the Public Perception of Artificial Intelligence</a></h2><p>本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。</p>
<h2 id="Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary"><a href="#Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary" class="headerlink" title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction beyond the Sentence Boundary</a></h2><p>本文研究的问题是非结构化文本中的关系抽取问题，针对传统方法在抽取关系时仅限于单个句子，本文提出了一种新的方法，从多个句子中进行关系抽取。</p>
<h2 id="What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler"><a href="#What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler" class="headerlink" title="What You Get Is What You See: A Visual Markup Decompiler"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" target="_blank" rel="external">What You Get Is What You See: A Visual Markup Decompiler</a></h2><p>【转发较多】本文研究的问题是如何从web页面中生成html代码，以及如何从公式图片中生成latex代码，为此作者构造了两个相关的大型数据集，用了完全数据驱动的端到端训练方法得到了不错的效果。本文工作来自Harvard。</p>
<p>Demo|Dataset|Code: <a href="http://lstm.seas.harvard.edu/latex/" target="_blank" rel="external">http://lstm.seas.harvard.edu/latex/</a></p>
<h2 id="Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis"><a href="#Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis" class="headerlink" title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" target="_blank" rel="external">Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis</a></h2><p>本文研究的内容是多模态情感分析，针对当前相关高质量数据集规模太小造成的情感依赖于个体特征的问题，提出了一种Select-Additive学习方法提高通用性。 </p>
<h2 id="Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning"><a href="#Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning" class="headerlink" title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" target="_blank" rel="external">Interactive Spoken Content Retrieval by Deep Reinforcement Learning</a></h2><p>本文研究的内容是DQN算法来做语音内容检索，通过人机交互来完成内容检索。DQN相比传统的RL模型明显的优势在于不依赖hand-crafted features。本文被Interspeech 2016录用。</p>
<h2 id="Graph-Structured-Representations-for-Visual-Question-Answering"><a href="#Graph-Structured-Representations-for-Visual-Question-Answering" class="headerlink" title="Graph-Structured Representations for Visual Question Answering"></a><a href="http://arxiv.org/pdf/1609.05600v1.pdf" target="_blank" rel="external">Graph-Structured Representations for Visual Question Answering</a></h2><p>本文研究内容为VQA，VQA的主要挑战在于对visual和text两个领域都需要理解。传统的模型中常常忽略场景中的结构和问题中的语言结构，本文针对这两个问题提出了一种图模型，取得了不错的效果。</p>
<h2 id="Context-aware-Sequential-Recommendation"><a href="#Context-aware-Sequential-Recommendation" class="headerlink" title="Context-aware Sequential Recommendation"></a><a href="http://arxiv.org/pdf/1609.05787v1.pdf" target="_blank" rel="external">Context-aware Sequential Recommendation</a></h2><p>用户行为建模是推荐系统中的一个关键部件，行为数据是序列数据，天然适合用RNN来建模。但实际应用中context信息(time,location,weahter)也很重要，本文针对这个问题提出了一种CA-RNN模型将context考虑在内，取得了不错效果。</p>
<h2 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h2><p>本文研究内容为机器阅读理解，之前效果不错的方法大多数停留在有限的几轮reasoning，本文用增强学习来动态地决定是否继续读下去或者停下来进行答案选择。本文工作来自微软研究院。</p>
<h2 id="Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference"><a href="#Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference" class="headerlink" title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" target="_blank" rel="external">Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference</a></h2><p>本文研究内容为自然语言推理，作者认为LSTM类的模型潜力并没有被充分挖掘，基于此，本文在传统LSTM模型的基础上增加了syntactic parse信息，得到了更好的效果。</p>
<h2 id="A-framework-for-mining-process-models-from-emails-logs"><a href="#A-framework-for-mining-process-models-from-emails-logs" class="headerlink" title="A framework for mining process models from emails logs"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" target="_blank" rel="external">A framework for mining process models from emails logs</a></h2><p>本文研究的内容是邮件日志的挖掘，作者提出了一种无监督的挖掘方法，并且提出了一种半自动化的邮件标注方法。</p>
<h2 id="Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution"><a href="#Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution" class="headerlink" title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" target="_blank" rel="external">Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution</a></h2><p>本文研究内容为authorship attribution，是一个典型的多分类任务。作者利用字符级别的多通道CNN模型对大规模dataset进行了建模，取得了不错的结果。作者之一来自aylien.com 公司，一家非常出色的NLP SaaS 公司。</p>
<h2 id="Minimally-Supervised-Written-to-Spoken-Text-Normalization"><a href="#Minimally-Supervised-Written-to-Spoken-Text-Normalization" class="headerlink" title="Minimally Supervised Written-to-Spoken Text Normalization"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" target="_blank" rel="external">Minimally Supervised Written-to-Spoken Text Normalization</a></h2><p>本文研究的内容是特定语言领域知识在构建text normalization system的时候应该如何做trade-off，本文作者来自Google。</p>
<h2 id="Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention"><a href="#Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention" class="headerlink" title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" target="_blank" rel="external">Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention</a></h2><p>本文研究内容是如何识别隐式的discourse关系，作者提出了一种多层注意力模型，联合注意力机制和外部memory来做关系识别。本文是EMNLP2016的长文。</p>
<h2 id="SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks"><a href="#SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks" class="headerlink" title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" target="_blank" rel="external">SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</a></h2><p>【转发较多】本文提出了一种新的正则化方法，通过在训练过程中调整label来实现，达到了和Dropout接近的效果。</p>
<h2 id="The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA"><a href="#The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA" class="headerlink" title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" target="_blank" rel="external">The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)</a></h2><p>本文提出了一个1 million的Visual Question Answer Dataset，数据地址：<a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" target="_blank" rel="external">http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/</a></p>
<h2 id="Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs"><a href="#Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs" class="headerlink" title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"></a><a href="http://arxiv.org/pdf/1609.07075v1.pdf" target="_blank" rel="external">Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs</a></h2><p>【转发较多】当前知识表示存在两个挑战：1、如何更好地利用entity的context；2、如何发现与entity相关的句子；针对这两个问题，本文提出了一种从多个句子中学习表示的模型。给定每个entity的参考句子，首先用带池化的RNN或LSTM来encode与该entity相关的句子，然后用attention模型来衡量每个句子的信息量，最后得到entity的表示。模型在triple classification和link prediction两个任务上都取得了满意的结果。本文工作来自@刘知远THU组。</p>
<p>刘知远：我觉得这个工作的最有意思的地方是，能够为实体找到最有信息量的句子，这些句子往往是该实体的定义或描述。这样，在构建知识图谱时，我们就可以自动为新增的实体构建对应的文本描述信息了。</p>
<h2 id="Semantic-Tagging-with-Deep-Residual-Networks"><a href="#Semantic-Tagging-with-Deep-Residual-Networks" class="headerlink" title="Semantic Tagging with Deep Residual Networks"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" target="_blank" rel="external">Semantic Tagging with Deep Residual Networks</a></h2><p>本文提出一种多语言智能tagger，模型采用了char-level和word-level的深度残差网络，在词性标注任务中取得了不错的效果，本文COLING 2016在审。</p>
<h2 id="Image-embodied-Knowledge-Representation-Learning"><a href="#Image-embodied-Knowledge-Representation-Learning" class="headerlink" title="Image-embodied Knowledge Representation Learning"></a><a href="http://arxiv.org/pdf/1609.07028v1.pdf" target="_blank" rel="external">Image-embodied Knowledge Representation Learning</a></h2><p>【转发较多】entity图像中包含丰富的信息，大多数传统方法并没有利用这一点，本文提出了一种知识表示模型，利用了triples和image信息，并在知识图谱补全和triple分类两个任务中取得了不错的效果。本文是一篇典型的多信息融合的文章，非常值得思考！工作同样来自@刘知远THU老师组。</p>
<h2 id="Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling"><a href="#Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling" class="headerlink" title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" target="_blank" rel="external">Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling</a></h2><p>推特上的推对于topic建模有以下缺点：1、短；2、非结构化；3、口语化；也有优点：1、作者；2、hashtags；3、粉丝网络。本文结合推特信息的优点提出了一种新模型。topic model是个老话题了，多源信息的融合是突破研究瓶颈一个不错的方向，本文的方法同样可借鉴于微博和其他社交网络。</p>
<h2 id="Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning"><a href="#Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning" class="headerlink" title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" target="_blank" rel="external">Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning</a></h2><p>【转发较多】Attention类模型在端到端语音识别领域取得了不错的效果，但当输入噪声非常大的的时候，识别长句子效果不是很好。CTC是另外一种不错的端到端模型，本文结合两者的优势构建模型。构建了联合模型之后，克服了之前的问题。大家都在用Attention，都说Attention好，但终究还是有些情境下attention并不能如人意。那么问题来了，到底哪些场景下attention表现不好，原因是什么？想清楚这个到底之后，改进的方法大概也就在路上了。#Attention Model的缺点#</p>
<h1 id="资源分享"><a href="#资源分享" class="headerlink" title="资源分享"></a>资源分享</h1><h2 id="Bots-Product-Hunt"><a href="#Bots-Product-Hunt" class="headerlink" title="Bots - Product Hunt"></a><a href="https://www.producthunt.com/topics/bots" target="_blank" rel="external">Bots - Product Hunt</a></h2><p>一个分享和点评各种好玩product的站点，其中一个栏目有各种各样的bot。</p>
<h2 id="Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go"><a href="#Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go" class="headerlink" title="Gorgonia is a library that helps facilitate machine learning in Go"></a><a href="https://github.com/chewxy/gorgonia" target="_blank" rel="external">Gorgonia is a library that helps facilitate machine learning in Go</a></h2><p>用Go写的机器学习开源框架。</p>
<h2 id="A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task"><a href="#A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task" class="headerlink" title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"></a><a href="https://github.com/danqi/rc-cnn-dailymail" target="_blank" rel="external">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a></h2><p>这篇paper的代码放出来了，同时包括CNN和Daily Mail的数据集。来自斯坦福Danqi Chen的工作。</p>
<h1 id="业界新闻"><a href="#业界新闻" class="headerlink" title="业界新闻"></a>业界新闻</h1><h2 id="API-AI-is-joining-Google"><a href="#API-AI-is-joining-Google" class="headerlink" title="API.AI is joining Google!"></a><a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" target="_blank" rel="external">API.AI is joining Google!</a></h2><p>chatbot构建平台api.ai被Google收购了</p>
<h2 id="Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch"><a href="#Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch" class="headerlink" title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch "></a><a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" target="_blank" rel="external">Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch </a></h2><p>TechCrunch报道称，继api.ai被google收购之后，一家做自然语言理解的公司angel.ai也几乎被Amazon收购。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    页阅读量:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    站访问量:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    站访客数:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>




    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" >
        <i class="fa fa-arrow-right"></i>
        </a>
        © XXX 2015-2016
    </div>
    <div class="secondrow">
        <a href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.js"></script>
<script type="text/javascript">

// comments below to disable loading animation
function revealOnScroll() {
  var scrolled = $(window).scrollTop();
  $(".excerpt, .index-title, .index-meta, p").each(function() {
    var current = $(this),
      height = $(window).outerHeight(),
      offsetTop = current.offset().top;
    (scrolled + height + 50 > offsetTop) ? current.addClass("animation"):'';
  });
}
$(window).on("scroll", revealOnScroll);
$(document).ready(revealOnScroll)

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

// back to top scripts
$("a[href='#top']").click(function() {
  $("html, body").animate({ scrollTop: 0 }, 500);
  return false;
});


var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
