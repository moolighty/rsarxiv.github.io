<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>PaperWeekly</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://rsarxiv.github.io/"/>
  <updated>2017-01-20T19:49:28.000Z</updated>
  <id>http://rsarxiv.github.io/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PaperWeekly 第二十二期</title>
    <link href="http://rsarxiv.github.io/2017/01/20/PaperWeekly-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%8C%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2017/01/20/PaperWeekly-第二十二期/</id>
    <published>2017-01-20T18:54:36.000Z</published>
    <updated>2017-01-20T19:49:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>Image Caption是一个融合计算机视觉、自然语言处理和机器学习的问题，它类似于翻译一副图片为一段描述文字。该任务对于人类来说非常容易，但是对于机器却非常具有挑战性，它不仅需要利用模型去理解图片的内容并且还需要用自然语言去表达它们之间的关系。除此之外，模型还需要能够抓住图像的语义信息，并且生成人类可读的句子。<br>随着机器翻译和大数据的兴起，出现了Image Caption的研究浪潮。当前大多数的Image Caption方法基于encoder-decoder模型。其中encoder一般为卷积神经网络，利用最后全连接层或者卷积层的特征作作为图像的特征，decoder一般为递归神经网络，主要用于图像描述的生成。由于普通RNN存在梯度下降的问题，RNN只能记忆之前有限的时间单元的内容，而LSTM是一种特殊的RNN架构，能够解决梯度消失等问题，并且其具有长期记忆，所以一般在decoder阶段采用LSTM.</p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>Image Caption问题可以定义为二元组(I,S)的形式， 其中I表示图，S为目标单词序列，其中S={S1,S2,…}，其中St为来自于数据集提取的单词。训练的目标是使最大似然p(S|I)取得最大值，即使生成的语句和目标语句更加匹配，也可以表达为用尽可能准确的用语句去描述图像。</p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>论文中常用数据集为Flickr8k,Flick30k,MSCOCO,其中各个数据集的图片数量如下表所示。</p>
<p><img src="media/22-1.jpg" alt=""></p>
<p><img src="media/22-2.jpg" alt=""></p>
<p>数据集图片和描述示例如图</p>
<p>其中每张图像都至少有5张参考描述。为了使每张图像具有多种互相独立的描述，数据集使用了不同的语法去描述同一张图像。如示例图所示，相同图像的不同描述侧重场景的不同方面或者使用不同的语法构成。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本文主要介绍基于神经网络的方法</p>
<h2 id="1-NIC-1"><a href="#1-NIC-1" class="headerlink" title="1 NIC[1]"></a>1 NIC[1]</h2><p>Show and Tell: A Neural Image Caption Generator<br>本文提出了一种encoder-decoder框架，其中通过CNN提取图像特征，然后经过LSTM生成目标语言，其目标函数为最大化目标描述的最大似然估计。</p>
<p><img src="media/22-3.jpg" alt=""></p>
<p>该模型主要包括encoder-decoder两个部分。encoder部分为一个用于提取图像特征的卷积神经网络，可以采用VGG16，VGG19, GoogleNet等模型, decoder为经典的LSTM递归神经网络，其中第一步的输入为经过卷积神经网络提取的图像特征，其后时刻输入为每个单词的词向量表达。对于每个单词首先通过one-hot向量进行表示，然后经过词嵌入模型，变成与图像特征相同的维度。</p>
<h2 id="2-MS-Captivator-2"><a href="#2-MS-Captivator-2" class="headerlink" title="2 MS Captivator[2]"></a>2 MS Captivator[2]</h2><p>From captions to visual concepts and back<br>本文首先利用多实例学习，去训练视觉检测器来提取一副图像中所包含的单词，然后学习一个统计模型用于生成描述。对于视觉检测器部分，由于数据集对图像并没有准确的边框标注，并且一些形容词、动词也不能通过图像直接表达，所以本文采用Multiple Instance Learning(MIL)的弱监督方法，用于训练检测器。</p>
<p><img src="media/22-4.jpg" alt=""></p>
<h2 id="3-Hard-Attention-Soft-Attention-3"><a href="#3-Hard-Attention-Soft-Attention-3" class="headerlink" title="3 Hard-Attention Soft-Attention[3]"></a>3 Hard-Attention Soft-Attention[3]</h2><p>Show, atten and tell: Neural image caption generation with visual attention<br>受最近注意机制在机器翻译中发展的启发，作者提出了在图像的卷积特征中结合空间注意机制的方法，然后将上下文信息输入到encoder-decoder框架中。在encoder阶段，与之前直接通过全连接层提取特征不同，作者使用较低层的卷积层作为图像特征，其中卷积层保留了图像空间信息，然后结合注意机制，能够动态的选择图像的空间特征用于decoder阶段。在decoder阶段，输入增加了图像上下文向量，该向量是当前时刻图像的显著区域的特征表达。</p>
<p><img src="media/22-5.jpg" alt=""></p>
<h2 id="4-gLSTM-4"><a href="#4-gLSTM-4" class="headerlink" title="4 gLSTM[4]"></a>4 gLSTM[4]</h2><p>Guiding long-short term memory for image caption generation<br>使用语义信息来指导LSTM在各个时刻生成描述。由于经典的NIC[1]模型，只是在LSTM模型开始时候输入图像，但是LSTM随着时间的增长，会慢慢缺少图像特征的指导，所以本文采取了三种不同的语义信息，用于指导每个时刻单词的生成，其中guidance分别为Retrieval-based guidance (ret-gLSTM), Semantic embedding guidance(emb-gLSTM) ,Image as guidance (img-gLSTM).</p>
<p><img src="media/22-6.jpg" alt=""></p>
<h2 id="5-sentence-condition-5"><a href="#5-sentence-condition-5" class="headerlink" title="5 sentence-condition[5]"></a>5 sentence-condition[5]</h2><p>Image Caption Generation with Text-Conditional Semantic Attention</p>
<p><img src="media/22-7.jpg" alt=""></p>
<p>该模型首先利用卷积神经网络提取图像特征，然后结合图像特征和词嵌入的文本特征作为gLSTM的输入。由于之前gLSTM的guidance都采用了时间不变的信息，忽略了不同时刻guidance信息的不同，而作者采用了text-conditional的方法，并且和图像特征相结合，最终能够根据图像的特定部分用于当前单词的生成。</p>
<h2 id="6-Att-CNN-LSTM-6"><a href="#6-Att-CNN-LSTM-6" class="headerlink" title="6 Att-CNN+LSTM [6]"></a>6 Att-CNN+LSTM [6]</h2><p>What value do explicit high level concepts have in vision to language problems?<br>如图，作者首先利用VggNet模型在ImageNet数据库进行预训练，然后进行多标签数训练。给一张图片，首先产生多个候选区域，将多个候选区域输入CNN产生多标签预测结果，然后将结果经过max pooling作为图像的高层语义信息，最后输入到LSTM用于描述的生成。该方法相当于保留了图像的高层语义信息，不仅在Image Caption上取得了不错的结果，在VQA问题上，也取得很好的成绩。<br><img src="media/22-8.jpg" alt=""></p>
<h2 id="7-MSM-7"><a href="#7-MSM-7" class="headerlink" title="7 MSM[7]"></a>7 MSM[7]</h2><p>BOOSTING IMAGE CAPTIONING WITH ATTRIBUTES</p>
<p><img src="media/22-9.jpg" alt=""></p>
<p>该文研究了图像属性特征对于描述结果的影响，其中图像属性特征通过多实例学习[2]的方法进行提取。作者采用了五种不同的组合形式进行对比。其中第3种、第5种，在五种中的表现出了比较好的效果。由于提取属性的模型，之前用于描述图像的单词的生成，所以属性特征能够更加抓住图像的重要特征。而该文中的第3种形式，相当于在NIC模型的基础上，在之前加上了属性作为LSTM的初始输入，增强了模型对于图像属性的理解。第5种，在每个时间节点将属性和文本信息进行结合作为输入，使每一步单词的生成都能够利用图像属性的信息。</p>
<h2 id="8-When-to-Look-8"><a href="#8-When-to-Look-8" class="headerlink" title="8 When to Look[8]"></a>8 When to Look[8]</h2><p>Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning</p>
<p><img src="media/22-10.jpg" alt=""></p>
<p>该文主要提出了何时利用何种特征的概念。由于有些描述单词可能并不直接和图像相关，而是可以从当前生成的描述中推测出来，所以当前单词的生成可能依赖图像，也可能依赖于语言模型。基于以上思想，作者提出了“视觉哨兵”的概念，能够以自适应的方法决定当前生成单词，是利用图像特征还是文本特征。</p>
<h1 id="当前结果"><a href="#当前结果" class="headerlink" title="当前结果"></a>当前结果</h1><p>本文列出的模型的在COCO测试集上的结果如下：</p>
<p><img src="media/22-11.jpg" alt=""></p>
<p>以下为online MSCOCO testing server的结果：</p>
<p><img src="media/22-12.jpg" alt=""></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li>Vinyals O, Toshev A, Bengio S, et al. Show and tell: A neural image caption generator[J]. Computer Science, 2015:3156-3164.</li>
<li>Fang H, Gupta S, Iandola F, et al. From captions to visual concepts and back[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2015:1473-1482.</li>
<li>Xu K, Ba J, Kiros R, et al. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention[J]. Computer Science, 2016:2048-2057.</li>
<li>Jia X, Gavves E, Fernando B, et al. Guiding Long-Short Term Memory for Image Caption Generation[J]. 2015.</li>
<li>Zhou L, Xu C, Koch P, et al. Image Caption Generation with Text-Conditional Semantic Attention[J]. 2016.</li>
<li>Wu Q, Shen C, Liu L, et al. What Value Do Explicit High Level Concepts Have in Vision to Language Problems?[J]. Computer Science, 2016.</li>
<li>Yao T, Pan Y, Li Y, et al. Boosting Image Captioning with Attributes[J]. 2016.</li>
<li>Lu J, Xiong C, Parikh D, et al. Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning[J]. 2016.</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;Image Caption是一个融合计算机视觉、自然语言处理和机器学习的问题，它类似于翻译一副图片为一段描述文字。该任务对于人类来说非常容易
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>近期对话系统领域高质量paper汇总</title>
    <link href="http://rsarxiv.github.io/2017/01/17/%E8%BF%91%E6%9C%9F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E9%A2%86%E5%9F%9F%E9%AB%98%E8%B4%A8%E9%87%8Fpaper%E6%B1%87%E6%80%BB/"/>
    <id>http://rsarxiv.github.io/2017/01/17/近期对话系统领域高质量paper汇总/</id>
    <published>2017-01-17T22:02:42.000Z</published>
    <updated>2017-01-18T01:18:05.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Dialog-Context-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#1-Dialog-Context-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="1 Dialog Context Language Modeling with Recurrent Neural Networks"></a>1 Dialog Context Language Modeling with Recurrent Neural Networks</h2><p>Authors: Bing Liu, Ian Lane<br>Link: <a href="https://arxiv.org/abs/1701.04056" target="_blank" rel="external">https://arxiv.org/abs/1701.04056</a><br>Tags: Context; LM</p>
<h2 id="2-A-Copy-Augmented-Sequence-to-Sequence-Architecture-Gives-Good-Performance-on-Task-Oriented-Dialogue"><a href="#2-A-Copy-Augmented-Sequence-to-Sequence-Architecture-Gives-Good-Performance-on-Task-Oriented-Dialogue" class="headerlink" title="2 A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue"></a>2 A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue</h2><p>Authors: Mihail Eric, Christopher D. Manning<br>Link: <a href="https://arxiv.org/abs/1701.04024" target="_blank" rel="external">https://arxiv.org/abs/1701.04024</a><br>Tags: Copy-Augmented Seq2Seq; Task-Oriented</p>
<h2 id="3-Generating-Long-and-Diverse-Responses-with-Neural-Conversation-Models"><a href="#3-Generating-Long-and-Diverse-Responses-with-Neural-Conversation-Models" class="headerlink" title="3 Generating Long and Diverse Responses with Neural Conversation Models"></a>3 Generating Long and Diverse Responses with Neural Conversation Models</h2><p>Authors: Louis Shao, Stephan Gouws, Denny Britz, Anna Goldie, Brian Strope, Ray Kurzweil<br>Link: <a href="https://arxiv.org/abs/1701.03185" target="_blank" rel="external">https://arxiv.org/abs/1701.03185</a><br>Tags: Long; Diverse</p>
<h2 id="4-RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems"><a href="#4-RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems" class="headerlink" title="4 RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems"></a>4 RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems</h2><p>Authors: Chongyang Tao, Lili Mou, Dongyan Zhao, Rui Yan<br>Link: <a href="https://arxiv.org/abs/1701.03079" target="_blank" rel="external">https://arxiv.org/abs/1701.03079</a><br>Tags: Automatic Evaluation; Open Domain</p>
<h2 id="5-Neural-Personalized-Response-Generation-as-Domain-Adaptation"><a href="#5-Neural-Personalized-Response-Generation-as-Domain-Adaptation" class="headerlink" title="5 Neural Personalized Response Generation as Domain Adaptation"></a>5 Neural Personalized Response Generation as Domain Adaptation</h2><p>Authors: Weinan Zhang, Ting Liu, Yifa Wang, Qingfu Zhu<br>Link: <a href="https://arxiv.org/abs/1701.02073" target="_blank" rel="external">https://arxiv.org/abs/1701.02073</a><br>Tags: Personalize; Response Generation</p>
<h2 id="6-A-User-Simulator-for-Task-Completion-Dialogues"><a href="#6-A-User-Simulator-for-Task-Completion-Dialogues" class="headerlink" title="6 A User Simulator for Task-Completion Dialogues"></a>6 A User Simulator for Task-Completion Dialogues</h2><p>Authors: Xiujun Li, Zachary C. Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao, Yun-Nung Chen<br>Link: <a href="https://arxiv.org/abs/1612.05688" target="_blank" rel="external">https://arxiv.org/abs/1612.05688</a><br>Tags: User Simulator</p>
<h2 id="7-Learning-Through-Dialogue-Interactions"><a href="#7-Learning-Through-Dialogue-Interactions" class="headerlink" title="7 Learning Through Dialogue Interactions"></a>7 Learning Through Dialogue Interactions</h2><p>Authors: Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc’Aurelio Ranzato, Jason Weston<br>Link: <a href="https://arxiv.org/abs/1612.04936" target="_blank" rel="external">https://arxiv.org/abs/1612.04936</a><br>Tags: Reinforcement Learning</p>
<h2 id="8-Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents"><a href="#8-Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents" class="headerlink" title="8 Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents"></a>8 Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents</h2><p>Authors: Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li<br>Link: <a href="https://arxiv.org/abs/1612.03929" target="_blank" rel="external">https://arxiv.org/abs/1612.03929</a><br>Tags: Seq2Seq; Reinforcement Learning; Open Domain</p>
<h2 id="9-Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots"><a href="#9-Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots" class="headerlink" title="9 Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots"></a>9 Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots</h2><p>Authors: Yu Wu, Wei Wu, Ming Zhou, Zhoujun Li<br>Link: <a href="https://arxiv.org/abs/1612.01627" target="_blank" rel="external">https://arxiv.org/abs/1612.01627</a><br>Tags: Multi-turn; Retrieval-based</p>
<h2 id="10-End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager"><a href="#10-End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager" class="headerlink" title="10 End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager"></a>10 End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager</h2><p>Authors: Xuesong Yang, Yun-Nung Chen, Dilek Hakkani-Tur, Paul Crook, Xiujun Li, Jianfeng Gao, Li Deng<br>Link: <a href="https://arxiv.org/abs/1612.00913" target="_blank" rel="external">https://arxiv.org/abs/1612.00913</a><br>Tags: Joint Learning; NLU; Dialogue Manager</p>
<h2 id="11-Dialogue-Learning-With-Human-In-The-Loop"><a href="#11-Dialogue-Learning-With-Human-In-The-Loop" class="headerlink" title="11 Dialogue Learning With Human-In-The-Loop"></a>11 Dialogue Learning With Human-In-The-Loop</h2><p>Authors: Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc’Aurelio Ranzato, Jason Weston<br>Link: <a href="https://arxiv.org/abs/1611.09823" target="_blank" rel="external">https://arxiv.org/abs/1611.09823</a><br>Tags: Interactive; Reinforcement Learning</p>
<h2 id="12-A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation"><a href="#12-A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation" class="headerlink" title="12 A Simple, Fast Diverse Decoding Algorithm for Neural Generation"></a>12 A Simple, Fast Diverse Decoding Algorithm for Neural Generation</h2><p>Authors: Jiwei Li, Will Monroe, Dan Jurafsky<br>Link: <a href="https://arxiv.org/abs/1611.08562" target="_blank" rel="external">https://arxiv.org/abs/1611.08562</a><br>Tags: Diverse</p>
<h2 id="13-Coherent-Dialogue-with-Attention-based-Language-Models"><a href="#13-Coherent-Dialogue-with-Attention-based-Language-Models" class="headerlink" title="13 Coherent Dialogue with Attention-based Language Models"></a>13 Coherent Dialogue with Attention-based Language Models</h2><p>Authors: Hongyuan Mei, Mohit Bansal, Matthew R. Walter<br>Link: <a href="https://arxiv.org/abs/1611.06997" target="_blank" rel="external">https://arxiv.org/abs/1611.06997</a><br>Tags: Coherent; Attention</p>
<h2 id="14-Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review"><a href="#14-Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review" class="headerlink" title="14 Generative Deep Neural Networks for Dialogue: A Short Review"></a>14 Generative Deep Neural Networks for Dialogue: A Short Review</h2><p>Authors: Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, Joelle Pineau<br>Link: <a href="https://arxiv.org/abs/1611.06216" target="_blank" rel="external">https://arxiv.org/abs/1611.06216</a><br>Tags: Review; Generative DNN</p>
<h2 id="15-Detecting-Context-Dependent-Messages-in-a-Conversational-Environment"><a href="#15-Detecting-Context-Dependent-Messages-in-a-Conversational-Environment" class="headerlink" title="15 Detecting Context Dependent Messages in a Conversational Environment"></a>15 Detecting Context Dependent Messages in a Conversational Environment</h2><p>Authors: Chaozhuo Li, Yu Wu, Wei Wu, Chen Xing, Zhoujun Li, Ming Zhou<br>Link: <a href="https://arxiv.org/abs/1611.00483" target="_blank" rel="external">https://arxiv.org/abs/1611.00483</a><br>Tags: Context</p>
<h2 id="16-Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog-Systems"><a href="#16-Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog-Systems" class="headerlink" title="16 Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems"></a>16 Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems</h2><p>Authors: Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang<br>Link: <a href="https://arxiv.org/abs/1610.07149" target="_blank" rel="external">https://arxiv.org/abs/1610.07149</a><br>Tags: Retrieval-Based; Generation-Based</p>
<h2 id="17-Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding"><a href="#17-Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding" class="headerlink" title="17 Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding"></a>17 Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding</h2><p>Authors: Lina M. Rojas Barahona, Milica Gasic, Nikola Mrkšić, Pei-Hao Su, Stefan Ultes, Tsung-Hsien Wen, Steve Young<br>Link: <a href="https://arxiv.org/abs/1610.04120" target="_blank" rel="external">https://arxiv.org/abs/1610.04120</a><br>Tags: Context; SLU</p>
<h2 id="18-Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling"><a href="#18-Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling" class="headerlink" title="18 Dialogue Session Segmentation by Embedding-Enhanced TextTiling"></a>18 Dialogue Session Segmentation by Embedding-Enhanced TextTiling</h2><p>Authors: Yiping Song, Lili Mou, Rui Yan, Li Yi, Zinan Zhu, Xiaohua Hu, Ming Zhang<br>Link: <a href="https://arxiv.org/abs/1610.03955" target="_blank" rel="external">https://arxiv.org/abs/1610.03955</a><br>Tags: Context</p>
<h2 id="19-Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#19-Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="19 Personalizing a Dialogue System with Transfer Learning"></a>19 Personalizing a Dialogue System with Transfer Learning</h2><p>Authors: Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang<br>Link: <a href="https://arxiv.org/abs/1610.02891" target="_blank" rel="external">https://arxiv.org/abs/1610.02891</a><br>Tags: Personalize; Transfer Learning</p>
<h2 id="20-Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning"><a href="#20-Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning" class="headerlink" title="20 Dialogue manager domain adaptation using Gaussian process reinforcement learning"></a>20 Dialogue manager domain adaptation using Gaussian process reinforcement learning</h2><p>Authors: Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, Steve Young<br>Link: <a href="https://arxiv.org/abs/1609.02846" target="_blank" rel="external">https://arxiv.org/abs/1609.02846</a><br>Tags: Dialogue Manager; Gaussian Process Reinforcement Learning</p>
<h2 id="21-Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#21-Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="21 Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a>21 Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</h2><p>Authors: Bing Liu, Ian Lane<br>Link: <a href="https://arxiv.org/abs/1609.01462" target="_blank" rel="external">https://arxiv.org/abs/1609.01462</a><br>Tags: Joint Learning; SLU; LM</p>
<h2 id="22-End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#22-End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="22 End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a>22 End-to-End Reinforcement Learning of Dialogue Agents for Information Access</h2><p>Authors: Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng<br>Link: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="external">https://arxiv.org/abs/1609.00777</a><br>Tags: Reinforcement Learning; Task-oriented</p>
<h2 id="23-A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#23-A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="23 A Context-aware Natural Language Generator for Dialogue Systems"></a>23 A Context-aware Natural Language Generator for Dialogue Systems</h2><p>Authors: Ondřej Dušek, Filip Jurčíček<br>Link: <a href="https://arxiv.org/abs/1608.07076" target="_blank" rel="external">https://arxiv.org/abs/1608.07076</a><br>Tags: Context; NLG</p>
<h2 id="24-Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation"><a href="#24-Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation" class="headerlink" title="24 Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation"></a>24 Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</h2><p>Authors: Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin<br>Link: <a href="https://arxiv.org/abs/1607.00970" target="_blank" rel="external">https://arxiv.org/abs/1607.00970</a><br>Tags: Seq2Seq; Short-Text</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-Dialog-Context-Language-Modeling-with-Recurrent-Neural-Networks&quot;&gt;&lt;a href=&quot;#1-Dialog-Context-Language-Modeling-with-Recurrent-Neura
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2017.01.09-2017.01.13)</title>
    <link href="http://rsarxiv.github.io/2017/01/14/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2017-01-09-2017-01-13/"/>
    <id>http://rsarxiv.github.io/2017/01/14/本周值得读-2017-01-09-2017-01-13/</id>
    <published>2017-01-14T18:27:18.000Z</published>
    <updated>2017-01-14T18:46:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Neural-Personalized-Response-Generation-as-Domain-Adaptation"><a href="#Neural-Personalized-Response-Generation-as-Domain-Adaptation" class="headerlink" title="Neural Personalized Response Generation as Domain Adaptation"></a><a href="http://t.cn/RM6jy36" target="_blank" rel="external">Neural Personalized Response Generation as Domain Adaptation</a></h1><p>【个性化】【对话生成】  本文研究的问题是如何生成个性化的对话，模型仍是基于经典的seq2seq+attention，在该模型的基础上通过两个步骤来生成特定style的对话，第一步是initialization，第二步是adaptation。工作来自哈工大 @刘挺 老师组，他们推出了一个聊天机器人 “笨笨” （可微信搜），而且具有中文阅读理解的功能。关于生成更多样的对话内容，可以参考 PaperWeekly 第十八期 — 提高seq2seq方法所生成对话的流畅度和多样性 <a href="http://t.cn/RIVUKnr" target="_blank" rel="external">http://t.cn/RIVUKnr</a></p>
<h1 id="RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems"><a href="#RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems" class="headerlink" title="RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems"></a><a href="http://t.cn/RMKeK0L" target="_blank" rel="external">RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems</a></h1><p>【对话系统】【评价】 本文研究的问题也是当前对话系统中非常关键的一个问题，如何更加准确地自动评价模型的效果，本文提出了一种新的评价方法RUBER，旨在通过生成的reply和用户的当前query来联合评判效果，建议从业者和相关研究人员精读。 </p>
<h1 id="Generating-Long-and-Diverse-Responses-with-Neural-Conversation-Models"><a href="#Generating-Long-and-Diverse-Responses-with-Neural-Conversation-Models" class="headerlink" title="Generating Long and Diverse Responses with Neural Conversation Models"></a><a href="http://t.cn/RM9SyPf" target="_blank" rel="external">Generating Long and Diverse Responses with Neural Conversation Models</a></h1><p>【对话生成】【seq2seq】 本文研究的问题是如何生成一个又长、又多样的对话，模型仍是基于经典的seq2seq，在decoding部分，加了一个所谓的self-attention部件来保证对话长度和连贯性，在解空间中用随机beam search来搜索候选对话，然后进行重排得到最终结果。关于seq2seq生成对话，可以参看PaperWeekly 第十八期 — 提高seq2seq方法所生成对话的流畅度和多样性<a href="http://t.cn/RIVUKnr" target="_blank" rel="external">http://t.cn/RIVUKnr</a></p>
<h1 id="Decoding-as-Continuous-Optimization-in-Neural-Machine-Translation"><a href="#Decoding-as-Continuous-Optimization-in-Neural-Machine-Translation" class="headerlink" title="Decoding as Continuous Optimization in Neural Machine Translation"></a><a href="http://t.cn/RMKeGX1" target="_blank" rel="external">Decoding as Continuous Optimization in Neural Machine Translation</a></h1><p>【seq2seq】【解码】 本文的亮点在于将seq2seq模型中的解码部分转化成一个连续优化的问题，通过比较成熟的优化算法来解决解码问题，这个思路可以被应用到所有seq2seq解决方案中。</p>
<h1 id="OpenNMT-Open-Source-Toolkit-for-Neural-Machine-Translation"><a href="#OpenNMT-Open-Source-Toolkit-for-Neural-Machine-Translation" class="headerlink" title="OpenNMT: Open-Source Toolkit for Neural Machine Translation"></a><a href="http://t.cn/RMKex91" target="_blank" rel="external">OpenNMT: Open-Source Toolkit for Neural Machine Translation</a></h1><p>【NMT】【开源】 Harvard NLP组和SYSTRAN公司联合推出的开源机器翻译系统OpenNMT，torch实现，代码地址：<a href="https://github.com/opennmt/opennmt" target="_blank" rel="external">https://github.com/opennmt/opennmt</a> 主页地址：<a href="http://opennmt.net/" target="_blank" rel="external">http://opennmt.net/</a></p>
<h1 id="Implicitly-Incorporating-Morphological-Information-into-Word-Embedding"><a href="#Implicitly-Incorporating-Morphological-Information-into-Word-Embedding" class="headerlink" title="Implicitly Incorporating Morphological Information into Word Embedding"></a><a href="http://t.cn/RM6Oe27" target="_blank" rel="external">Implicitly Incorporating Morphological Information into Word Embedding</a></h1><p>【词向量】将词形信息考虑在词向量模型中是一种常见的增强手段，一般的做法是将词的前缀、后缀和词根作为独立的token进行建模，而本文的思路则是用能够代表前缀、后缀意思的词来代替进行建模。</p>
<h1 id="Real-Multi-Sense-or-Pseudo-Multi-Sense-An-Approach-to-Improve-Word-Representation"><a href="#Real-Multi-Sense-or-Pseudo-Multi-Sense-An-Approach-to-Improve-Word-Representation" class="headerlink" title="Real Multi-Sense or Pseudo Multi-Sense: An Approach to Improve Word Representation"></a><a href="http://t.cn/RM6Rsdv" target="_blank" rel="external">Real Multi-Sense or Pseudo Multi-Sense: An Approach to Improve Word Representation</a></h1><p>【真假多义词】 词向量是一个非常活跃的研究领域，word2vec提供了一种非常简单粗暴、充满问题的词向量，比如一个典型的问题是一词多义，于是很多的工作都是在解决一词多义的问题，但一个词对应的多个向量其实都指向同一个词义，本文的工作正是对这些伪一词多义进行识别，降低语言研究的复杂度。</p>
<h1 id="Multi-level-Representations-for-Fine-Grained-Typing-of-Knowledge-Base-Entities"><a href="#Multi-level-Representations-for-Fine-Grained-Typing-of-Knowledge-Base-Entities" class="headerlink" title="Multi-level Representations for Fine-Grained Typing of Knowledge Base Entities"></a><a href="http://t.cn/RM68yGy" target="_blank" rel="external">Multi-level Representations for Fine-Grained Typing of Knowledge Base Entities</a></h1><p>【entity表示】 entity是知识图谱的基础组件，很多的entity都是罕见词（短语），entity的表示是一个相对困难的问题。本文提出了一种char-level、word-level和entity-level三种level的联合表示模型，得到了不错的效果。本文非常值得精读！数据和代码都已公开 <a href="http://cistern.cis.lmu.de/figment/" target="_blank" rel="external">http://cistern.cis.lmu.de/figment/</a></p>
<h1 id="Task-Specific-Attentive-Pooling-of-Phrase-Alignments-Contributes-to-Sentence-Matching"><a href="#Task-Specific-Attentive-Pooling-of-Phrase-Alignments-Contributes-to-Sentence-Matching" class="headerlink" title="Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching"></a><a href="http://t.cn/RM6lxze" target="_blank" rel="external">Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching</a></h1><p>【短语对齐】 本文研究的问题是句子匹配，该问题常常被应用于文本蕴含和答案选择两个任务上，针对短语识别、表示和对齐等关键问题，本文提出了一种基于GRU的NN模型，取得了不错的效果。本文作者是@Wenpeng_Yin </p>
<h1 id="Parsing-Universal-Dependencies-without-training"><a href="#Parsing-Universal-Dependencies-without-training" class="headerlink" title="Parsing Universal Dependencies without training"></a><a href="http://t.cn/RM9XkMy" target="_blank" rel="external">Parsing Universal Dependencies without training</a></h1><p>【依存分析】【无监督】 本文的工作是基于pagerank和一些规则来做无监督式的依存文法分析，无监督的paper总是让人眼前一亮，EACL2017。”在现今去规则化和拼语料库的机器学习型parser盛行时，少有的使用规则，无监督的Parser。每人研究都有自己支撑点，在没有被完全推翻时，自然会坚持，不为热潮激流所动，我认为这是理性研究者的主骨，我一直有敬畏之心。尽管各家学说各异，相信还是以结果优良和可发展性为最终评价标准”(观点来自微博 王伟DL)</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Neural-Personalized-Response-Generation-as-Domain-Adaptation&quot;&gt;&lt;a href=&quot;#Neural-Personalized-Response-Generation-as-Domain-Adaptation
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>高考机器人距离我们还有多远？</title>
    <link href="http://rsarxiv.github.io/2017/01/13/%E9%AB%98%E8%80%83%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B7%9D%E7%A6%BB%E6%88%91%E4%BB%AC%E8%BF%98%E6%9C%89%E5%A4%9A%E8%BF%9C%EF%BC%9F/"/>
    <id>http://rsarxiv.github.io/2017/01/13/高考机器人距离我们还有多远？/</id>
    <published>2017-01-13T22:57:16.000Z</published>
    <updated>2017-01-14T18:26:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>2016年初，随着AlphaGo战胜韩国棋王李世乭九段，人工智能重新被推到风口浪尖，一时间大家纷纷开始讨论人工智能将会带来什么，将会改变什么，不管是媒体还是学者纷纷将关注点转移到了人工智能上面；号称将改变人类交互方式的聊天机器人也如雨后春笋般地出现在街上、桥下和田野中；2016年末，一个叫做master的计算机程序在网络上接连战胜了几乎所有的围棋高手，经过证实正是AlphaGo的升级版；接着，德州扑克在新年伊始也被人工智能攻破。</p>
<p>“还有谁？！”人工智能仿佛没了对手，仿佛人类的生活马上就会迎来革命性的变化，不由自由地陷入到人工智能威胁的恐惧当中。但，近日一则题为《日本AI机器人Torobo-kun放弃高考计划：阅读理解难以逾越》的新闻备受关注，给处在沸腾边缘的人工智能浪潮浇了一盆冷水。</p>
<blockquote>
<p>最近，日本国立情报学研究所（NII）的研究人员宣布，放弃让人工智能系统“Torobo-kun”参加东京大学入学考试的计划。作为NII开发的人工智能机器人，Torobo-kun的终极目标是通过日本顶尖高校东京大学的入学考试，而目前的研究结果表明，这一计划遇到了难以逾越的障碍。</p>
</blockquote>
<p>高考对于大家来说是一个充满回忆的词，也是一种相对来讲公平（但不一定科学）的评价体系，对一个学生的知识掌握程度和推理、归纳、总结等能力有比较好的评判。人工智能的研究既然达到了不错的水准，自然而然会来挑战一下高考这种高智力的测试。其实，不仅仅是日本开展了针对机器人高考的研究，国家863“超脑计划”也开展了相关的项目，准备在2017年同高中生们一同参加文科高考，考试科目分别是语文、数学和文综。</p>
<p>如果不仅仅限于高考这种形式的话，很多的顶尖研究机构在很早的时候就开展了利用人工智能来解数学、物理、化学、生物、地理、历史等各门学科的题，比如大名鼎鼎的Halo Project和OpenAI的Aristo Project，其中有的已经宣告失败，有的仍在努力尝试。</p>
<h1 id="高考机器人"><a href="#高考机器人" class="headerlink" title="高考机器人"></a>高考机器人</h1><h2 id="高考机器人计划（Todai-Robot-Project）"><a href="#高考机器人计划（Todai-Robot-Project）" class="headerlink" title="高考机器人计划（Todai Robot Project）"></a>高考机器人计划（Todai Robot Project）</h2><p>Todai机器人计划是日本国立情报学研究所（NII）于2011年提出的研究计划，目标是开发一套机器人系统，参加东京大学入门测试并且通过，在项目的早期研发中，顺利地通过了绝大多数的私立大学和一部分公立大学的入学考试，但水平离东京大学的要求仍有较大差距。究其原因，尽管现有的研究水平在很多任务上相比于传统的方法已经有较大的进步了，但对于真正理解人类语言，然后进行推理、归纳和总结还有很长的路要走。比如“谁是曹丕的父亲，谁是中国三国时期魏国的第一位皇帝？”，高考机器人Torobo-kun未能给出正确的答案。虽然Torobo-kun知道曹丕是曹操的儿子，但它没能想出曹操就是曹丕的父亲，因为它不理解父子关系。历时近6年的研究项目就此宣布失败，项目期间共发表了14篇相关的论文。</p>
<h2 id="题型分析"><a href="#题型分析" class="headerlink" title="题型分析"></a>题型分析</h2><p>直观地理解，对于机器人来说，考察记忆的题目会比考察推理、归纳的题目更容易一些，选择题比填空题更容易一些，客观题比主观题更容易一些，文科的题目比理科的题目更容易一些。高考机器人是一个非常综合的任务，包括了图像识别、语音识别、自然语言处理和生成、问答系统和知识图谱等许多研究内容，而现如今流行的深度学习成功地将图像识别和语音识别的精度提升到了工业级的标准，同时也为自然语言处理的很多任务带来了全新的解决方案，但仍无法达到工业级的标准。</p>
<p>考试题目分类众多，本文选择几个典型的题型进行分析。</p>
<p>### </p>
<p>### </p>
<p>###</p>
<p>###</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>1、失败原因（与研究难点关联）<br>2、评论（对这件事进行评论）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;2016年初，随着AlphaGo战胜韩国棋王李世乭九段，人工智能重新被推到风口浪尖，一时间大家纷纷开始讨论人工智能将会带来什么，将会改变什么
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第二十一期</title>
    <link href="http://rsarxiv.github.io/2017/01/11/PaperWeekly-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%80%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2017/01/11/PaperWeekly-第二十一期/</id>
    <published>2017-01-11T20:00:23.000Z</published>
    <updated>2017-01-11T21:06:12.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>多信息融合是一个重要的研究趋势，尤其是对于训练数据缺乏的任务来说，如何融入其他相关信息来提高本任务的准确率是一个非常值得研究的问题。机器翻译是一个热门的研究领域，随着训练数据规模地增加，各种NN模型的效果也取得了突破的进展，google和百度均已部署上线NMT系统；融合图像、音频、视频、文本等各种模态数据的多模态研究也是一个非常热门的研究方向，本期PaperWeekly将为大家带来NMT和多模态交叉研究的paper解读，共3篇paper：</p>
<p>1、Attention-based Multimodal Neural Machine Translation, 2016<br>2、Multimodal Attention for Neural Machine Translation, 2016<br>3、Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot, 2016</p>
<h1 id="Attention-based-Multimodal-Neural-Machine-Translation"><a href="#Attention-based-Multimodal-Neural-Machine-Translation" class="headerlink" title="Attention-based Multimodal Neural Machine Translation"></a><a href="https://www.aclweb.org/anthology/W/W16/W16-2360.pdf" target="_blank" rel="external">Attention-based Multimodal Neural Machine Translation</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Po-Yao Huang, Frederick Liu, Sz-Rung Shiang, Jean Oh, Chris Dyer</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>CMU</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Visual Features, Attention, Multimodal NMT</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>多模态神经机器翻译，在传统的seq2seq翻译模型上，利用图像特征信息帮助提高机器翻译的结果</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>在WMT16的多模态神经网络机器翻译新任务上的工作。<br>提出了3种如何将visual feature加入到seq2seq网络中的encoder，从而使得decoder更好的attention到与图像，语义相关部分的模型： global visual feature， regional visual feature，paralle threads.</p>
<p><img src="media/global_visual.png" alt="global_visua"></p>
<p>global visual： 直接将VGG中的fc7抽出的feature加入到encoder的first step(head)或者是last step(tail)</p>
<p><img src="media/region_visual.png" alt="region_visua"></p>
<p>regional visual： 先用R-CNN抽出region box的信息，再用VGG得到fc7的特征，将top4对应的region feature，以及global visual feature分别作为每一个step输入到encoder中</p>
<p><img src="media/parallel_threads.png" alt="parallel_threads"></p>
<p>parallel threads: 与regional visual相对应的是，每个thread只利用一个region box的feature，和global visual一样的网络，将top 4对应的4 threads和gloabl thread一起做average pooling，每个therad的参数共享; attention则对应所有threads中的所有hidden states</p>
<p>同时本文还提出了三种rescoring translation的结果的方法， 用 1）language model 2）bilingual autoencoder 3）bilingual dictionary分别来挑选translation的句子，发现bilingual dictionary来删选翻译的句子效果最好</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>数据集： WMT2016 (En-Ge)<br>图像特征提取： VGG， R-CNN</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>在En-Ge的结果如图：<br><img src="media/en-ge.png" alt="en-ge"></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>NMT： Kalchbrenner and Blunsom 2013<br>Attention NMT： Bahdanau 2014<br>Joint Space Learning： Zhang 2014，Su 2015，Kiros 2014<br>多模态上相关工作目前并没有很多，值得快速入手</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文提出了一种针对图像和文本结合的神经网络翻译模型，非常自然的将图像特征加入到seq2seq模型的encoder部分，使decoder不仅能够attention在文本上，同时也能够focus到图像上(global或者region)；并且模型的设计比较简单，没有加入太多复杂的模块。<br>不过只是简单的将图像的特征作为seq中的一个step，并没有考虑文本和图像之间的相关关系，如joint space，相信加入joint learing会有提升。</p>
<h2 id="完成人信息"><a href="#完成人信息" class="headerlink" title="完成人信息"></a>完成人信息</h2><p>Lijun Wu from SYSU.</p>
<h1 id="Multimodal-Attention-for-Neural-Machine-Translation"><a href="#Multimodal-Attention-for-Neural-Machine-Translation" class="headerlink" title="Multimodal Attention for Neural Machine Translation"></a><a href="https://arxiv.org/abs/1609.03976" target="_blank" rel="external">Multimodal Attention for Neural Machine Translation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Ozan Caglayan, Loïc Barrault, Fethi Bougares</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>University of Le Mans, Galatasaray University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>NMT, Attention</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv 2016.09</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>给定图片和源语言描述的情况下，基于attention机制,生成目标语言的图片描述。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>模型有两个encoder，一个是textual encoder,是一个双向GRU，用于获取源语言文本的向量表示$A^{txt} = {a^{txt}_1,a^{txt}_2,…}$，另外一个是visual encoder,使用的是现成由ImageNet数据集训好的ResNet-50网络，用于获取图片的向量表示。$A^{im} = {a^{im}_1,a^{im}_2,…}$. Decoder部分，是两层的stakced GRU,先用attention方式，分别获取文本部分和图像部分的context向量$c^{txt}$和$c^{im}$,然后将两个向量concat在一起，作为新的context 向量$c$。<br>如图：</p>
<p><img src="media/mul_attention.jpg" alt="mul_attention"></p>
<p>这样decoder部分的解码翻译的时候，不仅可以考虑到源语言的文本信息，也可以考虑到原始图片的信息。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p><a href="https://github.com/elliottd/GroundedTranslation" target="_blank" rel="external">IAPRTC-12 dataset for English and German</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>2014年Bahdanau的Neural Machine Translation by Jointly Learning to Align and Translate，使NMT超过了传统的PBMT，后来的NMT论文基本都是在这个文章基础上进行的改进。<br>2015年Elliott的工作Multi-language image description with neural sequence models. 也是在给定源语言和图片的情况下，生成目标语言。不过并没有使用attention机制。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>该文章的创新之处，在于对图片描述文字进行翻译的时候，考虑到了图片本身的特征信息并引入attention机制。在源语言文本生成出错的情况下，因为有图片信息参考，在一定程度上，可以减轻这种错误带来的影响。不过文章并没有利用外部英德平行语料，这可以考虑作为后面的改进方向。</p>
<h2 id="完成人信息-1"><a href="#完成人信息-1" class="headerlink" title="完成人信息"></a>完成人信息</h2><p>xiaose@mail.ustc.edu.cn<br>中国科学技术大学</p>
<h1 id="Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot"><a href="#Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot" class="headerlink" title="Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot"></a><a href="https://arxiv.org/pdf/1611.04503.pdf" target="_blank" rel="external">Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Hideki Nakayama，Noriki Nishida</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>The University of Tokyo</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>pivot, multimodal, NMT</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.11</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>在没有平行语料的情况下，用image当作pivot来实现机器翻译</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>整体上讲，模型分成两部分。第一部分是多模态embedding，采用pairwise ranking loss来定义损失函数；第二部分是用RNN来实现的decoder,跟image caption里面的decoder类似。对这个问题来说，我们的训练数据包括$i^{s}$：源端的图片，$d^{s}$：源端图片对应的句子描述；$i^{t}$：目标端的图片，$d^{t}$：目标端图片对应的句子描述，和源端用的不一样的语言。文中提出了2个模型来解决这个问题：<br><img src="media/21-1-1.png" alt="21-1"></p>
<p>模型1的多模态端包括了图片的encoder和源句子的encoder。图片encoder可以对源图片和目标图片通用。多模态端用$i^{s}$,$d^{s}$进行训练，损失函数为：</p>
<p><img src="media/21-2.png" alt="21-2"></p>
<p>$E^{v}$表示图片的encoder(比如用VGG-16提取图片的feature), $E^{s}$表示源句子的encoder(比如用RNN)，$d^{s}_{ng}$表示和源端图片不相关的描述。Decoder端用$i^{t}$,$d^{t}$进行训练，损失函数为标准的 cross-entropy loss（称作图片损失):</p>
<p><img src="media/21-3.png" alt="21-3"></p>
<p>模型2比模型1更复杂一点。在源端增加了一个目标句子描述的encoder。因此，在多模态embedding的学习中，损失函数增加了目标图片和目标图片描述的pairwise ranking loss.</p>
<p><img src="media/21-4.png" alt="21-4"></p>
<p>在decoder的学习中，模型2除了前面的公式2定义的图片损失外，还增加了目标描述的reconstruction loss，即从多模态端输入目标描述，希望通过embedding和decoder重建这个目标描述。<br><img src="media/21-5.png" alt="21-5"></p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>两个Multilingual image-description的数据集：IAPR-TC12（包含2万图片以及英语和德语的描述）和 Multi30K（包含3万图片以及英语和德语的描述)</p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>对于没有平行语料的机器翻译，多数文章是用某种常见语言作为pivot，比如“Neural Machine Translation with Pivot Languages”, 用英语作为西班牙语法语以及德语法语之间的pivot。缺点是翻译的时候还是要经过pivot那一步。 另外，还要一些工作是用一个模型实现many to many的翻译。在这种情况下，没有平行语料的语言对也能用这个模型进行翻译。不需要经过pivot那个中间层，但是效果一般会差一点。比如“Google’s Multilingual Neural Machine Translation System”这篇文章。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>这篇文章的思路很新颖，考虑用图片来作为pivot，实现没有平行语料的语言对之间的翻译。训练完成后可以直接从源语言到目标语言进行翻译，不需要经过图片。但是正如文中提到的，这种方法跟有语料训练出来的翻译效果比起来还是差很多，并且翻译的句子都比较短。另外，对一些图片难以表达的信息很难通过这种方式学到。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>交叉领域的研究总是会带给大家惊喜，交叉领域的交叉领域更是如此，这个领域刚刚开坑，欢迎各位有志之士跳坑。并且在2016年举办了第一届多模态机器翻译（Multimodal Machine Translation）和多语看图说话（Crosslingual Image Description）比赛，比赛主页<a href="http://www.statmt.org/wmt16/multimodal-task.html" target="_blank" rel="external">http://www.statmt.org/wmt16/multimodal-task.html</a>, 总结性的paper <a href="http://anthology.aclweb.org/W/W16/W16-2346.pdf" target="_blank" rel="external">http://anthology.aclweb.org/W/W16/W16-2346.pdf</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;多信息融合是一个重要的研究趋势，尤其是对于训练数据缺乏的任务来说，如何融入其他相关信息来提高本任务的准确率是一个非常值得研究的问题。机器翻译是一个热
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.12.26-2017.01.06)</title>
    <link href="http://rsarxiv.github.io/2017/01/06/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-12-26-2017-01-06/"/>
    <id>http://rsarxiv.github.io/2017/01/06/本周值得读-2016-12-26-2017-01-06/</id>
    <published>2017-01-07T06:06:34.000Z</published>
    <updated>2017-01-07T06:24:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Neural-Hawkes-Process-A-Neurally-Self-Modulating-Multivariate-Point-Process"><a href="#The-Neural-Hawkes-Process-A-Neurally-Self-Modulating-Multivariate-Point-Process" class="headerlink" title="The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process"></a><a href="http://t.cn/RMwnQmN" target="_blank" rel="external">The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process</a></h1><p>【时间序列模型】 本文提出了一个通用的连续时间序列模型—Neural Hawkes process，用来学习事件流中不同事件之间的影响关系，进而对未来事件的发生时间和类型进行预测。该模型在传统Hawkes process的基础上，用 Recurrent Neural Network 来总结事件流的历史信息，并动态地估计不同时刻不同事件之间复杂的相互影响关系，进而得出未来事件的发生时间和类型的概率分布。此模型可以用于多种事件流的分析，包括医学诊断，消费者行为，和社交网络活动的预测等，并在多个数据集上表现出了显著的优势。作者来自约翰霍普金斯大学NLP组，主页地址<a href="http://www.cs.jhu.edu/~hmei/" target="_blank" rel="external">http://www.cs.jhu.edu/~hmei/</a>  有需要讨论的可以直接联系作者本文  hmei@cs.jhu.edu</p>
<h1 id="Understanding-Image-and-Text-Simultaneously-a-Dual-Vision-Language-Machine-Comprehension-Task"><a href="#Understanding-Image-and-Text-Simultaneously-a-Dual-Vision-Language-Machine-Comprehension-Task" class="headerlink" title="Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task"></a><a href="http://t.cn/RIYdnYx" target="_blank" rel="external">Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task</a></h1><p>【多模态】image caption任务的自动评价存在一定的弊端，本文提出了新的任务，即给定一幅图，给出n个caption选项，只有一个是正确答案，通过准确率来评价算法的效果。构建这样一个任务需要先针对每一张图生成多个难度较高的干扰选项，本文提出了一些构造方法，并且在coco数据集上生成了本文的数据集，通过人工选择获得该任务的准确率上限。数据集已开放，地址 <a href="https://github.com/google/mcic-coco" target="_blank" rel="external">https://github.com/google/mcic-coco</a></p>
<h1 id="A-Joint-Speaker-Listener-Reinforcer-Model-for-Referring-Expressions"><a href="#A-Joint-Speaker-Listener-Reinforcer-Model-for-Referring-Expressions" class="headerlink" title="A Joint Speaker-Listener-Reinforcer Model for Referring Expressions"></a><a href="http://t.cn/RMhX58u" target="_blank" rel="external">A Joint Speaker-Listener-Reinforcer Model for Referring Expressions</a></h1><p>【多模态】本文研究的问题非常有趣，是Referring Expressions，简单点说就是给一张图和一个描述，要求找到描述中对应的object，通常包括两个任务：1、根据图片和指定object生成一个描述；2、根据图片和描述来找object。本文构建了一个联合训练模型，将两个任务一起训练，加上一层增强学习来提高所生成描述的多样性，得到了不错的结果。demo和dataset地址：<a href="https://vision.cs.unc.edu/refer/" target="_blank" rel="external">https://vision.cs.unc.edu/refer/</a></p>
<h1 id="Supervised-Opinion-Aspect-Extraction-by-Exploiting-Past-Extraction-Results"><a href="#Supervised-Opinion-Aspect-Extraction-by-Exploiting-Past-Extraction-Results" class="headerlink" title="Supervised Opinion Aspect Extraction by Exploiting Past Extraction Results"></a><a href="http://t.cn/RIYgOoK" target="_blank" rel="external">Supervised Opinion Aspect Extraction by Exploiting Past Extraction Results</a></h1><p>【观点挖掘】【迁移学习】本文做的工作是将某一些领域中已经抽取的非常好的aspect迁移至新的领域，比如screen在苹果手机中存在这么一个aspect，其他品牌的手机也存在，其他的电子设备可能也存在，利用已有的“知识”来提高准确率。</p>
<h1 id="Language-Modeling-with-Gated-Convolutional-Networks"><a href="#Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="Language Modeling with Gated Convolutional Networks"></a><a href="http://t.cn/RIYkG0b" target="_blank" rel="external">Language Modeling with Gated Convolutional Networks</a></h1><p>【CNN语言模型】本文的工作是将CNN模型和一种gate机制结合起来做语言模型，挑战了RNN在这个领域的霸主地位。工作来自Facebook，他们对CNN有非常的偏好。 </p>
<h1 id="Understanding-Neural-Networks-through-Representation-Erasure"><a href="#Understanding-Neural-Networks-through-Representation-Erasure" class="headerlink" title="Understanding Neural Networks through Representation Erasure"></a><a href="http://t.cn/RIRFnkr" target="_blank" rel="external">Understanding Neural Networks through Representation Erasure</a></h1><p>【解释神经网络】大家都知道深度学习效果好，但原因确实解释不清楚。本文尝试着做了一些解释方面的工作，通过“erase”掉一些representation来研究结果的变化，甚至通过增强学习来研究最多“erase”掉哪些representation仍不影响最终的结果。深度学习如果有了可解释性，相信又将会是一个新的研究水平了。 </p>
<h1 id="Shortcut-Sequence-Tagging"><a href="#Shortcut-Sequence-Tagging" class="headerlink" title="Shortcut Sequence Tagging"></a><a href="http://t.cn/RMw38iV" target="_blank" rel="external">Shortcut Sequence Tagging</a></h1><p>【新网络结构】本文针对多层RNN难训练的问题，提出了一种gate机制和shortcuts机制混合的方法，并研究了不同的组合效果。方法在序列标注问题上进行验证，从结果上来看，提高的不多，也从侧面反映出一个问题，现有的网络结构加一些排列组合或者小改动很难解决根本性的问题。</p>
<h1 id="Unsupervised-neural-and-Bayesian-models-for-zero-resource-speech-processing"><a href="#Unsupervised-neural-and-Bayesian-models-for-zero-resource-speech-processing" class="headerlink" title="Unsupervised neural and Bayesian models for zero-resource speech processing"></a><a href="http://t.cn/RMLugMZ" target="_blank" rel="external">Unsupervised neural and Bayesian models for zero-resource speech processing</a></h1><p>【无监督】【贝叶斯】本文是一篇来自爱丁堡大学的博士论文。</p>
<h1 id="Textual-Entailment-with-Structured-Attentions-and-Composition"><a href="#Textual-Entailment-with-Structured-Attentions-and-Composition" class="headerlink" title="Textual Entailment with Structured Attentions and Composition"></a><a href="http://t.cn/RM4seBe" target="_blank" rel="external">Textual Entailment with Structured Attentions and Composition</a></h1><p>【文本蕴含】本文的贡献在于将attention应用到了句法树上，而不是只对句子做attention。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;The-Neural-Hawkes-Process-A-Neurally-Self-Modulating-Multivariate-Point-Process&quot;&gt;&lt;a href=&quot;#The-Neural-Hawkes-Process-A-Neurally-Self
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第二十期</title>
    <link href="http://rsarxiv.github.io/2017/01/06/PaperWeekly-%E7%AC%AC%E4%BA%8C%E5%8D%81%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2017/01/06/PaperWeekly-第二十期/</id>
    <published>2017-01-06T18:31:23.000Z</published>
    <updated>2017-01-06T18:49:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GAN（Generative-Adversarial-Nets）研究进展"><a href="#GAN（Generative-Adversarial-Nets）研究进展" class="headerlink" title="GAN（Generative Adversarial Nets）研究进展"></a>GAN（Generative Adversarial Nets）研究进展</h1><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>1、Unsupervised learning</p>
<p>首先我们从generative model说起。generattive model的目的是找到一个函数可以最大的近似数据的真实分布。如果我们用 f(X; 𝜃) 来表示这样一个函数，那么找到一个使生成的数据最像真实数据的 𝜃 就是一个maximum likelihood estimation的过程。问题在于，当数据的分布比较复杂时，我们需要的 f 也会变复杂。现在我们有深度网络结构可以表达这样一个复杂的函数（deep generative model），但是训练过程成为了关键。基于sampling的训练过程显然不是很高效的。因此，如何设计模型以便利用backpropagation来训练网络成为了一个重要的目标。当前两个比较突出的模型实现的就是这个目的，一个是variational autoencoder(VAE)，另一个就是这篇文章的主题generative adversarial nets。</p>
<p>这篇文章会从基本的GAN模型讲起，重点讨论模型公式背后的原理。之后会讨论几篇GAN的扩展工作，希望能够扩展一下大家的思路，也可以加深对GAN模型的理解。下面的关系图大致描述了这些模型之间的继承关系。我们会按照图中的关系一个一个展开。</p>
<p><img src="media/gan-kg.png" alt="gan-kg"></p>
<p>2、GAN</p>
<p>首先是最经典的GAN模型。由Ian Goodfellow和Bengio等在2014年提出。为了简明扼要，我们直接看图说话。</p>
<p><img src="media/gan-formula.png" alt="gan-formula"></p>
<p>图中上半部分是GAN模型的基本架构。我们先从一个简单的分布中采样一个噪声信号 z（实际中可以采用[0, 1]的均匀分布或者是标准正态分布），然后经过一个生成函数后映射为我们想要的数据分布 Xg （z 和 X 都是向量）。生成的数据和真实数据都会输入一个识别网络 D。识别网络通过判别输出一个标量，表示数据来自真实数据的<strong>概率</strong>。在实现上，G 和 D 都是可微分函数，都可以用多层神经网络实现。因此上面的整个模型的参数就可以利用backpropagation来训练得到。</p>
<p>图中的下半部分是模型训练中的目标函数。仔细看可以发现这个公式很像cross entropy，注意D是 P(Xdata) 的近似。对于 D 而言要尽量使公式最大化（识别能力强），而对于 G 又想使之最小（生成的数据接近实际数据）。整个训练是一个迭代过程，但是在迭代中，对 D 的优化又是内循环。所以每次迭代，D 先训练 k次，G 训练一次。</p>
<p>GAN模型最大的优势就是训练简单，但是也有缺点比如训练的稳定性。有趣的是，在这篇文章future work部分，作者提出了5个可能扩展的方向，而现在回过头来看，后续的很多工作真的就是在照着这几个思路填坑。比如第一个conditional generative model就是后面要讲的conditional GAN的思路，而最后一个determing better distribution to sample z from during training则是后面InfoGAN的思路。</p>
<p>下面是来自twitter[9] 的一幅图，很好的总结了各种衍生模型的结构。</p>
<p><img src="media/gan.jpeg" alt="gan"></p>
<p>2.1 DCGAN </p>
<p>上面Ian J. Goodfellow等人的文章提出了GAN的模型和训练框架，但是没有描述具体的实现，而DCGAN[2] 这篇文章讲的就是用deep convolutional network实现一个生成图片的GAN模型。这篇文章没有在基本模型上有所扩展，但是他描述了很多实现上细节，尤其是让GAN模型stable的方法。所以如果对于GAN的实现有兴趣，这篇文章也是必读。此外，最新NIPS2016也有最新的关于训练GAN模型的总结 [How to Train a GAN? Tips and tricks to make GANs work] (<a href="https://github.com/soumith/ganhacks" target="_blank" rel="external">https://github.com/soumith/ganhacks</a> “GAN tricks”)。</p>
<p>3、InfoGAN</p>
<p>在GAN模型中，生成模型的输入是一个连续的噪声信号，由于没有任何约束，即便我们得到一个有效的生成模型，z也不能被很好的解释。为了使输入包含可以解释，更有信息的意义，InfoGAN[7]的模型在z之外，又增加了一个输入c，称之为隐含输入(latent code)，然后通过约束c与生成数据之间的关系，使得c里面可以包含某些语义特征(semantic feature)，比如对MNIST数据，c可以是digit(0-9)，倾斜度，笔画厚度等。具体做法是：首先我们确定需要表达几个特征以及这些特征的数据类型，比如是类别(categorical)还是连续数值，对每个特征我们用一个维度表示ci  。</p>
<p>接下来，利用互信息量来约束c。原理在于，如果 c 和生成的图像之间存在某种特定的对应（如果c是图像的某些特征，则有这样的函数存在），那么c和G(z,c)之间就应该有互信息量。如果是无约束的情况，比如z单独的每一个维度都跟和G(z)没有特定的关系，那么它们之间的互信息量应该接近0。所以加上这个约束之后，要优化的目标函数就变成了</p>
<pre><code>min max V(D,G) = V(D,G) - 𝜆 I(c;G(z,c))
</code></pre><p>接下来就是如何处理 I(c; G)​。由于 I(c;G(z,c))​ 的计算需要 p(c|x)​，而我们并不知道真实的分布。这时候，我们需要用一个 Q(c|x)​ 来近似，很显然，Q可以用神经网络来实现。此外， 可以利用reparametrization（见附录）的技巧来简化网络。</p>
<p>在实际中，由于Q和D都是输入 x，而且识别网络D除了可以输出概率，也可以做特征提取，因此Q可以和D共享参数。在正常的D之后，额外加一层full connected layer，利用softmax等可以输出c。这也是图3中的结构。</p>
<p>4、 Conditional GAN</p>
<p>Conditional GAN的基本模型见图3。所谓conditional的意思就是，生成图片的模型变成了 P(X|z, c)，而c是我们额外提供的信息。这里要注意conditional GAN和Info GAN的结构区别</p>
<ul>
<li>Info中c信息是需要网络去学习提取的特征，而这里是需要我们输入网络的信息。</li>
<li>Info中c只输入生成网络，而这里需要同时输入生成和识别网络，以便让网络学习到它们之间的关联。</li>
</ul>
<p>在Conditional GAN中，随着c的变换可以衍生出很多应用，比如输入可以是label，可以是分类。甚至是另外一个图片，比如可以做image to image的风格转换，也可以做分辨率提升super-resolution。这里我们以Text-to-Image[5] 为例，讲一下conditional GAN的一种建模方法。</p>
<p>同样，先上图：</p>
<p><img src="media/text2img.png" alt="text2img"></p>
<p>模型的任务是给定一句文字描述，然后可以生成符合描述的图像。可以看到，网络的输入除了采样噪声z以外还有文字信息。整个任务分为两大部分：第一部分是要对文字进行编码(text encoding)，这部分并不是Conditonal GAN模型的一部分，可以使用RNN或者char-CNN等。文中用的是deep convolutional and recurrent text encoder[4] ，感兴趣可以去看这篇文章[4]。</p>
<p>在模型中，文字信息同时输入 G 和 D 是关键所在，这样网络才能够将文字和图片关联起来。其次，在训练中，原GAN中 D 只需要判断两种数据：real/fake的图片。而这里，D 需要判断（输入）三种数据{real image, right text}，{real image, wrong text}以及{fake image, right text}。</p>
<p>5、 StackGAN</p>
<p>StackGAN[8] 模型本质就是是Conditional GAN，只不过它使用了两层conditional GAN模型，第一层模型 P(X1|z, c) 利用输入的文字信息c生成一个较低分辨率的图片。之后第二层模型 P(X|c,,X1) 基于第一层生成的图片以及文字信息生成更加优化的图片。文中给出的实验效果非常的惊人，可以生成256x256的非常真实的图片。这里不再重复细节。下图为简化的StackGAN模型。</p>
<p><img src="media/stackGAN.png" alt="stackGAN"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Goodfellow, Ian, et al. “Generative adversarial nets.” <em>Advances in Neural Information Processing Systems</em>. 2014.</li>
<li>Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised representation learning with deep convolutional generative adversarial networks.” <em>arXiv preprint arXiv:1511.06434</em> (2015).</li>
<li>Reed, Scott, et al. “Generative adversarial text to image synthesis.” <em>arXiv preprint arXiv:1605.05396</em> (2016).</li>
<li>Reed, Scott, et al. “Learning Deep Representations of Fine-Grained Visual Descriptions.” <em>arXiv preprint arXiv:1605.05395</em> (2016).</li>
<li>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</li>
<li>Image-to-Image Translation with Conditional Adversarial Networks</li>
<li>Chen, Xi, et al. “Infogan: Interpretable representation learning by information maximizing generative adversarial nets.” <em>Advances in Neural Information Processing Systems</em>. 2016.</li>
<li>Zhang, Han, et al. “StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.” <em>arXiv preprint arXiv:1612.03242</em> (2016).</li>
<li><a href="https://twitter.com/ch402/status/793535193835417601" target="_blank" rel="external">https://twitter.com/ch402/status/793535193835417601</a></li>
</ol>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>看了几篇关于GAN的文章，发现有几个建模的小trick</p>
<ul>
<li>在生成模型中，之所以可以从一个简单的分布采样，然后通过一个网络（参数需要学习）去近似数据的分布 背后的原理是</li>
</ul>
<blockquote>
<p>Any distribution in d dim can be generated by taking a set of d normal distribution variables. mapping through a sufficiently complicated function. So provided powerful function approximators, we can simply learn a function mapping independent norm distribution z to whatever X.</p>
</blockquote>
<ul>
<li><p>在模型中，如果目标函数中某个条件概率无法直接得到，那么可以学习一个网络Q去近似。利用KL divergence D{KL}[P||Q] = H(P,Q) - H(P) 以及<br>D{KL} &gt;= 0 可以推出一个更易优化的上/下界。</p>
</li>
<li><p><strong>reparametrization trick</strong> 举个例子，比如模型中用一个网络 Q(z|x) 来近似真实的 P(z|x)，我们常用正态分布来建模Q，即<br>N(μ, 𝛴)（这里 μ 和 𝛴 都是带参数的网络，通过学习得到）。当采样的 x 通过 Q 后就可以得到z。但是由于这一步是随机过程，backpropagation就会中断。这个时候我们就可以利用 N(μ, 𝛴) = N(0, I) ⨉ 𝜮 + μ 将随机过程转移到输入端。先从标准正态分布采样 z0，此时网络 Q 并不直接输出z，而是输出两个参数μ 和 𝛴，之后在通过 z=z0 ⨉ 𝛴 + μ 得到z。由于中间节点变成了常规运算，因此backpropagation可以正常传回输入端。</p>
<p>  ​</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GAN（Generative-Adversarial-Nets）研究进展&quot;&gt;&lt;a href=&quot;#GAN（Generative-Adversarial-Nets）研究进展&quot; class=&quot;headerlink&quot; title=&quot;GAN（Generative Adver
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>2016年自然语言处理领域15篇值得读的Paper</title>
    <link href="http://rsarxiv.github.io/2016/12/29/2016%E5%B9%B4%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E9%A2%86%E5%9F%9F10%E7%AF%87%E5%80%BC%E5%BE%97%E8%AF%BB%E7%9A%84Paper/"/>
    <id>http://rsarxiv.github.io/2016/12/29/2016年自然语言处理领域10篇值得读的Paper/</id>
    <published>2016-12-30T04:10:12.000Z</published>
    <updated>2017-01-03T03:49:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-to-Compose-Neural-Networks-for-Question-Answering"><a href="#Learning-to-Compose-Neural-Networks-for-Question-Answering" class="headerlink" title="Learning to Compose Neural Networks for Question Answering"></a><a href="https://arxiv.org/abs/1601.01705" target="_blank" rel="external">Learning to Compose Neural Networks for Question Answering</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Department of Electrical Engineering and Computer Sciences<br>University of California, Berkeley</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Question Answering</p>
<h1 id="Text-understanding-with-the-attention-sum-reader-network"><a href="#Text-understanding-with-the-attention-sum-reader-network" class="headerlink" title="Text understanding with the attention sum reader network"></a><a href="https://arxiv.org/abs/1603.01547" target="_blank" rel="external">Text understanding with the attention sum reader network</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, Jan Kleindienst</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>IBM Watson</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension </p>
<h1 id="Improving-Information-Extraction-by-Acquiring-External-Evidence-with-Reinforcement-Learning"><a href="#Improving-Information-Extraction-by-Acquiring-External-Evidence-with-Reinforcement-Learning" class="headerlink" title="Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning"></a><a href="https://arxiv.org/abs/1603.07954" target="_blank" rel="external">Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Karthik Narasimhan, Adam Yala, Regina Barzilay</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>CSAIL, MIT</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Information Extraction; Reinforcement Learning</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="https://arxiv.org/abs/1603.08148" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, Yoshua Bengio</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Universite de Montr´eal<br>IBM T.J. Watson Research<br>CIFAR Senior Fellow</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Unknown Words</p>
<h1 id="Sequence-to-Sequence-Learning-as-Beam-Search-Optimization"><a href="#Sequence-to-Sequence-Learning-as-Beam-Search-Optimization" class="headerlink" title="Sequence-to-Sequence Learning as Beam-Search Optimization"></a><a href="https://arxiv.org/abs/1606.02960" target="_blank" rel="external">Sequence-to-Sequence Learning as Beam-Search Optimization</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p>Sam Wiseman, Alexander M. Rush</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>School of Engineering and Applied Sciences, Harvard University</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Seq2Seq; Beam Search</p>
<h1 id="SQuAD-100-000-Questions-for-Machine-Comprehension-of-Text"><a href="#SQuAD-100-000-Questions-for-Machine-Comprehension-of-Text" class="headerlink" title="SQuAD: 100,000+ Questions for Machine Comprehension of Text"></a><a href="https://arxiv.org/abs/1606.05250" target="_blank" rel="external">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a></h1><h2 id="作者-5"><a href="#作者-5" class="headerlink" title="作者"></a>作者</h2><p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang</p>
<h2 id="单位-5"><a href="#单位-5" class="headerlink" title="单位"></a>单位</h2><p>Computer Science Department<br>Stanford University</p>
<h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension; Dataset</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><h2 id="作者-6"><a href="#作者-6" class="headerlink" title="作者"></a>作者</h2><p>Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng</p>
<h2 id="单位-6"><a href="#单位-6" class="headerlink" title="单位"></a>单位</h2><p>School of Computer Science, Carnegie Mellon University<br>Microsoft Research<br>National Taiwan University</p>
<h2 id="关键词-6"><a href="#关键词-6" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning; Dialogue System</p>
<h1 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="https://arxiv.org/abs/1609.05284" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h1><h2 id="作者-7"><a href="#作者-7" class="headerlink" title="作者"></a>作者</h2><p>Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen</p>
<h2 id="单位-7"><a href="#单位-7" class="headerlink" title="单位"></a>单位</h2><p>Microsoft Research Redmond</p>
<h2 id="关键词-7"><a href="#关键词-7" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension </p>
<h1 id="Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Learning"></a><a href="https://arxiv.org/abs/1610.02891" target="_blank" rel="external">Personalizing a Dialogue System with Transfer Learning</a></h1><h2 id="作者-8"><a href="#作者-8" class="headerlink" title="作者"></a>作者</h2><p>Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang</p>
<h2 id="单位-8"><a href="#单位-8" class="headerlink" title="单位"></a>单位</h2><p>The Hong Kong University of Science and Technology</p>
<h2 id="关键词-8"><a href="#关键词-8" class="headerlink" title="关键词"></a>关键词</h2><p>Dialogue System; Transfer Learning</p>
<h1 id="LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Network"><a href="#LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Network" class="headerlink" title="LightRNN Memory and Computation-Efficient Recurrent Neural Network"></a><a href="https://arxiv.org/abs/1610.09893" target="_blank" rel="external">LightRNN Memory and Computation-Efficient Recurrent Neural Network</a></h1><h2 id="作者-9"><a href="#作者-9" class="headerlink" title="作者"></a>作者</h2><p>Xiang Li, Tao Qin, Jian Yang, Tie-Yan Liu</p>
<h2 id="单位-9"><a href="#单位-9" class="headerlink" title="单位"></a>单位</h2><p>Nanjing University of Science and Technology<br>Microsoft Research Asia</p>
<h2 id="关键词-9"><a href="#关键词-9" class="headerlink" title="关键词"></a>关键词</h2><p>New Recurrent Neural Network</p>
<h1 id="Dual-Learning-for-Machine-Translation"><a href="#Dual-Learning-for-Machine-Translation" class="headerlink" title="Dual Learning for Machine Translation"></a><a href="https://arxiv.org/abs/1611.00179" target="_blank" rel="external">Dual Learning for Machine Translation</a></h1><h2 id="作者-10"><a href="#作者-10" class="headerlink" title="作者"></a>作者</h2><p>Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma</p>
<h2 id="单位-10"><a href="#单位-10" class="headerlink" title="单位"></a>单位</h2><p>University of Science and Technology of China<br>Key Laboratory of Machine Perception (MOE), School of EECS, Peking University<br>Microsoft Research</p>
<h2 id="关键词-10"><a href="#关键词-10" class="headerlink" title="关键词"></a>关键词</h2><p>Dual Learning; Neural Machine Translation</p>
<h1 id="Neural-Machine-Translation-with-Reconstruction"><a href="#Neural-Machine-Translation-with-Reconstruction" class="headerlink" title="Neural Machine Translation with Reconstruction"></a><a href="https://arxiv.org/abs/1611.01874" target="_blank" rel="external">Neural Machine Translation with Reconstruction</a></h1><h2 id="作者-11"><a href="#作者-11" class="headerlink" title="作者"></a>作者</h2><p>Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li</p>
<h2 id="单位-11"><a href="#单位-11" class="headerlink" title="单位"></a>单位</h2><p>Noah’s Ark Lab, Huawei Technologies<br>Department of Computer Science and Technology, Tsinghua University</p>
<h2 id="关键词-11"><a href="#关键词-11" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation</p>
<h1 id="Linguistically-Regularized-LSTMs-for-Sentiment-Classification"><a href="#Linguistically-Regularized-LSTMs-for-Sentiment-Classification" class="headerlink" title="Linguistically Regularized LSTMs for Sentiment Classification"></a><a href="https://arxiv.org/abs/1611.03949" target="_blank" rel="external">Linguistically Regularized LSTMs for Sentiment Classification</a></h1><h2 id="作者-12"><a href="#作者-12" class="headerlink" title="作者"></a>作者</h2><p>Qiao Qian, Minlie Huang, Xiaoyan Zhu</p>
<h2 id="单位-12"><a href="#单位-12" class="headerlink" title="单位"></a>单位</h2><p>State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology<br>Dept. of Computer Science and Technology, Tsinghua University</p>
<h2 id="关键词-12"><a href="#关键词-12" class="headerlink" title="关键词"></a>关键词</h2><p>Sentiment Classification; LSTM</p>
<h1 id="Google’s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation"><a href="#Google’s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation" class="headerlink" title="Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"></a><a href="https://arxiv.org/abs/1611.04558" target="_blank" rel="external">Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</a></h1><h2 id="作者-13"><a href="#作者-13" class="headerlink" title="作者"></a>作者</h2><p>Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean</p>
<h2 id="单位-13"><a href="#单位-13" class="headerlink" title="单位"></a>单位</h2><p>Google</p>
<h2 id="关键词-13"><a href="#关键词-13" class="headerlink" title="关键词"></a>关键词</h2><p>Multilingual Neural Machine Translation; Zero-Shot</p>
<h1 id="Language-Modeling-with-Gated-Convolutional-Networks"><a href="#Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="Language Modeling with Gated Convolutional Networks"></a><a href="https://arxiv.org/abs/1612.08083" target="_blank" rel="external">Language Modeling with Gated Convolutional Networks</a></h1><h2 id="作者-14"><a href="#作者-14" class="headerlink" title="作者"></a>作者</h2><p>Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier</p>
<h2 id="单位-14"><a href="#单位-14" class="headerlink" title="单位"></a>单位</h2><p>Facebook AI Research</p>
<h2 id="关键词-14"><a href="#关键词-14" class="headerlink" title="关键词"></a>关键词</h2><p>Language Modeling; Gated CNN</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Learning-to-Compose-Neural-Networks-for-Question-Answering&quot;&gt;&lt;a href=&quot;#Learning-to-Compose-Neural-Networks-for-Question-Answering&quot; cl
    
    </summary>
    
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>告别2016，迎接2017</title>
    <link href="http://rsarxiv.github.io/2016/12/29/%E5%91%8A%E5%88%AB2016%EF%BC%8C%E8%BF%8E%E6%8E%A52017/"/>
    <id>http://rsarxiv.github.io/2016/12/29/告别2016，迎接2017/</id>
    <published>2016-12-29T19:20:43.000Z</published>
    <updated>2016-12-30T18:02:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>2016年即将结束，首先对支持PaperWeekly的各位童鞋表示衷心的感谢，感谢你们让我有动力将这个用来督促我自己多读paper的side project坚持一直做下来，感谢各位对自然语言处理感兴趣并且愿意牺牲一些个人时间来写paper note的小伙伴，也感谢每天坚持一起刷arXiv来保证周末推荐“每周值得读”质量的几位童鞋，感谢加入PaperWeekly交流群每天都贡献很多高质量讨论内容的各位朋友，感谢为三个交流群做消息同步机器人的种瓜同学。</p>
<p>PaperWeekly从刚开始只有我一个人，到现在一共有50多位一起愿意分享内容的小伙伴，并且这个数字随着大家的热情参与会逐渐增加，正是有了这么多积极参与的小伙伴，才有了PaperWeekly一周敢做一个topic的底气。从9月1号重新组织PaperWeekly的内容形式，到今天为止，一共发布了17期内容，加上之前我自己写的2期内容，一共是19期内容，19期意味着19周的时间，19周的时间我们可以走过很多地方，吃过很多美食，看过很多美景，而我们选择了读19周的paper，选择了写19周的paper note，选择了推荐这19周中高质量的paper，选择了分享这19周以来大家的成长、积累与思考。</p>
<p>19周的时间，PaperWeekly一共完成了83篇paper notes，而这83篇paper可以用19个独立的topic组织起来，比如：</p>
<p>1、提高seq2seq生成对话的流畅性和多样性；<br>2、通过无监督/半监督的方法来做命名实体识别（NER）；<br>3、哪些ICLR2017的paper值得关注；<br>4、Attention模型在NMT任务中的应用和进展；<br>5、文本摘要技术的进展情况；<br>6、增强学习在对话生成中的应用；<br>7、GAN的研究进展；</p>
<p>每个topic都涉及到了一个研究方向，有的内容非常热门，比如GAN，有的内容非常经典，比如NER，每个topic都会抓住一些特点来归纳几篇paper，为准备入门、正在入门、已经入门的同学提供了服务和方便。</p>
<p>从8.25开始，PaperWeekly推出了“每周值得读”栏目，旨在充当arXiv上自然语言处理方面的人工过滤器，旨在解决信息过载问题，旨在帮助大家更快地了解到哪些paper更值得关注。</p>
<p>从8.25开始，PaperWeekly一共推荐了153篇高质量的paper，当然每个人对于质量的理解都会有所偏差，有的paper给整个研究带来了巨大的影响，有的paper可能对某个领域有所提高，有的paper所蕴含的思想会带来很多的启发，这是一件仁者见仁智者见智的事情。</p>
<p>在做PaperWeekly的时候，我观察到大家有一定的招聘需求，可能是公司，也可能是院校或者科研机构，但是在交流群中发的效果又不是很好，于是做了个决定，在11月中旬开始推出了一项新的服务—公益广告服务，从第一个帮助清华大学刘知远老师招博士后开始至今已经发了一些广告了，虽然还没有做效果反馈工作，但我们确实尽力在帮这些需要帮助的企业或者院校，如果您有这样的招聘需求，可以私信来联系我，如果可以与PaperWeekly合作写一期文章会更好！</p>
<p>在做PaperWeekly的时候，我也有过一阵迷茫，就是关于PaperWeekly到底是什么的思考，记得是一个周日晚上，我到了夜里3点仍没有睡着，就爬起来写了一篇《PaperWeekly到底是什么》的文章，来好好地定义了一下我们所做的事情以及所想追求的东西。最后，我是这么定义PaperWeekly的，“PaperWeekly是一个由50多名喜欢分享知识的童鞋利用宝贵的业余时间来一起，以一周为单位、对一个topic进行多篇paper解读和对比总结的、不追求热点、不搞些噱头的爱心公益组织，旨在分享知识。”</p>
<p>对一个东西的定位很重要，直接决定了对这个东西的态度和所应采取的方式、方法。我做不到拿一些哗众取宠的名字来命名文章标题，也做不到过分地夸大或者贬低某一个东西，我只想纯粹地做这么一件事情。各种指标对我们来说没有意义，哪怕没有人来读文章，而我们每天所读的这些paper，所学到的知识都不会减少，当然我希望大家写的东西可以分享给更多的人，让更多的人一起来感受科技的进步和学术的前沿，但我们不会刻意地去追求什么。我一直认为人能够坚持并且努力做好一件事情的最大动力是热爱，是那种没有半点虚伪、没有半点功利的热爱。因为热爱，所以纯粹。</p>
<p>PaperWeekly不是一个完美的东西，但是一个成长的东西，是一个一直在努力变好的东西。2016快要结束了，在2017年里，我们将不断地完善文章质量，丰富文章的形式，增加一些群内的直播交流活动，比如针对某一篇、某几篇paper的讨论，不定期地邀请更多的业界大牛来讲一讲理论和技术如何在工业界落地等等。</p>
<p>PaperWeekly是一个非常开放的组织，随时欢迎想一起写paper notes或者写分享的童鞋加入，让我们不断地努力，不断地壮大力量，在2017年书写出更多值得读的文章，产生更多高质量的讨论内容，一起为国内自然语言处理的发展贡献一点点力量。</p>
<p>最后，感谢各位合作伙伴对PaperWeekly的大力支持，感谢机器之心、科研圈、IEEE计算科学评论、ChatbotChina、将门创投等媒体和机构的支持。</p>
<p>2016年是一个开始，也仅仅是一个开始，2017年即将到来，PaperWeekly将与深度学习社区AI100进行深度合作，为大家提供更好的服务！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2016年即将结束，首先对支持PaperWeekly的各位童鞋表示衷心的感谢，感谢你们让我有动力将这个用来督促我自己多读paper的side project坚持一直做下来，感谢各位对自然语言处理感兴趣并且愿意牺牲一些个人时间来写paper note的小伙伴，也感谢每天坚持一
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.12.19-2016.12.23)</title>
    <link href="http://rsarxiv.github.io/2016/12/25/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-12-19-2016-12-23/"/>
    <id>http://rsarxiv.github.io/2016/12/25/本周值得读-2016-12-19-2016-12-23/</id>
    <published>2016-12-25T18:31:57.000Z</published>
    <updated>2016-12-25T18:39:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Machine-Reading-with-Background-Knowledge"><a href="#Machine-Reading-with-Background-Knowledge" class="headerlink" title="Machine Reading with Background Knowledge"></a><a href="http://t.cn/RIx3EjP" target="_blank" rel="external">Machine Reading with Background Knowledge</a></h2><p>【语义理解】在理解一句话的时候通常是直接分析该句话，而没有借助其他外部的知识，所以常常会产生一些歧义或者错误。本文的思路是在分析一句话时，借助一些背景知识来进行辅助，文中给出了两个任务，一个是句法分析中的介词短语消歧，一个是名词短语的关系抽取，都取得了明显的效果。本文作者包括了《机器学习》的作者Tom M. Mitchell教授。单纯地基于统计方法来做句法分析或者语义角色标注确实会遇到一些瓶颈，借助外部的背景知识是一个不错的思路。随着本文一起还开放了一个数据集 Prepositional Phrase Attachment Ambiguity (PPA) dataset <a href="http://t.cn/RIx1lEm" target="_blank" rel="external">http://t.cn/RIx1lEm</a></p>
<h2 id="A-User-Simulator-for-Task-Completion-Dialogues"><a href="#A-User-Simulator-for-Task-Completion-Dialogues" class="headerlink" title="A User Simulator for Task-Completion Dialogues"></a><a href="http://t.cn/RI9czrW" target="_blank" rel="external">A User Simulator for Task-Completion Dialogues</a></h2><p>【对话系统】本文研究的问题非常有用，人人都在做chatbot，却苦于没有训练数据，用户模拟是一个不错的思路。本文探索了一种模拟真实用户来训练chatbot的方法，文中给出了模拟器的设计和部分代码，涉及到的领域包括找电影和订电影票。虽然效果有很大提升空间，但是个不错的尝试。推荐给研究和开发chatbot的童鞋。源代码也同时开放了，地址 <a href="http://t.cn/RICfMSB" target="_blank" rel="external">http://t.cn/RICfMSB</a> 感兴趣的童鞋可以研究下。</p>
<h2 id="Reducing-Redundant-Computations-with-Flexible-Attention"><a href="#Reducing-Redundant-Computations-with-Flexible-Attention" class="headerlink" title="Reducing Redundant Computations with Flexible Attention"></a><a href="http://t.cn/RI9f3Bx" target="_blank" rel="external">Reducing Redundant Computations with Flexible Attention</a></h2><p>【注意力模型优化】注意力已经是一个应用比较广泛的深度学习模型，本文对decoding过程中的计算效率进行了优化，提出了一种Flexible注意力模型，在每一步解码时都会通过一个惩罚函数来过滤掉一些不重要的encoder unit，从而降低计算量。 </p>
<h2 id="Improving-Tweet-Representations-using-Temporal-and-User-Context"><a href="#Improving-Tweet-Representations-using-Temporal-and-User-Context" class="headerlink" title="Improving Tweet Representations using Temporal and User Context"></a><a href="http://t.cn/RI9I8LS" target="_blank" rel="external">Improving Tweet Representations using Temporal and User Context</a></h2><p>【用户画像】本文在对tweet进行表示学习时，通过引入用户timeline上相邻的tweets来提高准确度。</p>
<h2 id="Automatic-Generation-of-Grounded-Visual-Questions"><a href="#Automatic-Generation-of-Grounded-Visual-Questions" class="headerlink" title="Automatic Generation of Grounded Visual Questions"></a><a href="http://t.cn/RIKmwoo" target="_blank" rel="external">Automatic Generation of Grounded Visual Questions</a></h2><p>【VQA】【问题生成】可视化问答是个很有意思的东西，本文提出了一种新的任务，自动生成与图片内容相关的问题，有一点image caption的意思，只是说这里用来提问。感兴趣的童鞋可以关注一下。 </p>
<h2 id="CLEVR-A-Diagnostic-Dataset-for-Compositional-Language-and-Elementary-Visual-Reasoning"><a href="#CLEVR-A-Diagnostic-Dataset-for-Compositional-Language-and-Elementary-Visual-Reasoning" class="headerlink" title="CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"></a><a href="http://t.cn/RICIat8" target="_blank" rel="external">CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning</a></h2><p>【VQA】【数据福利】Li Feifei组发布的一组VQA数据集，100k规模的图片集，值得关注！文中提到数据和相关的处理代码近期会公开。</p>
<h2 id="Fast-Domain-Adaptation-for-Neural-Machine-Translation"><a href="#Fast-Domain-Adaptation-for-Neural-Machine-Translation" class="headerlink" title="Fast Domain Adaptation for Neural Machine Translation"></a><a href="http://t.cn/RICJro8" target="_blank" rel="external">Fast Domain Adaptation for Neural Machine Translation</a></h2><p>【机器翻译】【迁移学习】本文的工作是将某一个领域中训练好的模型以最低的代价迁移到领域外，同时保证领域内和领域外都有不错的效果。具体的思路是：先训练出一个不错的baseline model，然后在baseline的基础上使用领域外的少量数据进行几个回合的训练，得到一个continue model，然后将baseline和continue进行mix，得到最终的model。</p>
<h2 id="A-Context-aware-Attention-Network-for-Interactive-Question-Answering"><a href="#A-Context-aware-Attention-Network-for-Interactive-Question-Answering" class="headerlink" title="A Context-aware Attention Network for Interactive Question Answering"></a><a href="http://t.cn/RINpcT9" target="_blank" rel="external">A Context-aware Attention Network for Interactive Question Answering</a></h2><p>【交互式QA】本文的工作亮点在于做问答时提供了一种交互机制，当answer模块觉得现有的信息无法回答question的话，会生成一个更加深入的问题给用户，通过学习用户的反馈来生成答案。</p>
<h2 id="中文信息处理发展报告"><a href="#中文信息处理发展报告" class="headerlink" title="中文信息处理发展报告"></a><a href="http://t.cn/RINHLN8" target="_blank" rel="external">中文信息处理发展报告</a></h2><p>中国中文信息学会发布2016年《中文信息处理发展报告》，值得一读！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Machine-Reading-with-Background-Knowledge&quot;&gt;&lt;a href=&quot;#Machine-Reading-with-Background-Knowledge&quot; class=&quot;headerlink&quot; title=&quot;Machine Re
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第十九期</title>
    <link href="http://rsarxiv.github.io/2016/12/23/PaperWeekly-%E7%AC%AC%E5%8D%81%E4%B9%9D%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/12/23/PaperWeekly-第十九期/</id>
    <published>2016-12-23T18:40:03.000Z</published>
    <updated>2016-12-23T18:56:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>本期的PaperWeekly一共分享四篇最近arXiv上发布的高质量paper，包括：情感分析、机器阅读理解、知识图谱、文本分类。人工智能及其相关研究日新月异，本文将带着大家了解一下以上四个研究方向都有哪些最新进展。四篇paper分别是：</p>
<p>1、Linguistically Regularized LSTMs for Sentiment Classification, 2016.11<br>2、End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension, 2016.10<br>3、Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples, 2016.10<br>4、AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification, 2016.11</p>
<h1 id="Linguistically-Regularized-LSTMs-for-Sentiment-Classification"><a href="#Linguistically-Regularized-LSTMs-for-Sentiment-Classification" class="headerlink" title="Linguistically Regularized LSTMs for Sentiment Classification"></a><a href="https://arxiv.org/pdf/1611.03949v1.pdf" target="_blank" rel="external">Linguistically Regularized LSTMs for Sentiment Classification</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Qiao Qian, Minlie Huang, Xiaoyan Zhu</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>sentiment classification, neural network models, linguistically coherent representations,</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.11</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>利用语言资源和神经网络相结合来提升情感分类问题的精度</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>在LSTM和Bi-LSTM模型的基础上加入四种规则约束，这四种规则分别是: Non-Sentiment Regularizer,Sentiment Regularizer, Negation Regularizer, Intensity Regularizer.因此，新的loss function变为:</p>
<p><img src="media/eqn.png" alt="eqn"></p>
<p>不同的规则约束对应不同的L函数</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>1、Movie Review (MR) <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>2、Stanford Sentiment Tree- bank (SST) <a href="http://nlp.stanford.edu/sentiment/treebank.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/treebank.html</a></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Neural Networks for Sentiment Classification<br><a href="https://arxiv.org/abs/1412.3555" target="_blank" rel="external">Empirical evaluation of gated recurrent neural networks on sequence modeling</a><br><a href="https://pdfs.semanticscholar.org/5807/664af8e63d5207f59fb263c9e7bd3673be79.pdf" target="_blank" rel="external">Hybrid speech recognition with deep bidirectional lstm</a><br>2、Applying Linguistic Knowledge for Sentiment Classification<br><a href="http://www.site.uottawa.ca/~diana/publications/ci.pdf" target="_blank" rel="external">Sentiment classification of movie reviews using contextual valence shifters</a></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文提出了一种新的基于语言资源约束和LSTM/Bi-LSTM的模型用于情感分类，并通过在MR和SST数据集上的实验和对RNN/RNTN,LSTM,Tree-LSTM,CNN的效果对比证明了这一模型的有效性。除此之外，本文还基于不同的约束进行了实验，证明的不同的约束在提高分类精度上的作用。本文实验丰富，效果的提升虽不显著，但新的模型确实在不同程度上克服了旧模型的一些不足。</p>
<h1 id="End-to-End-Answer-Chunk-Extraction-and-Ranking-for-Reading-Comprehension"><a href="#End-to-End-Answer-Chunk-Extraction-and-Ranking-for-Reading-Comprehension" class="headerlink" title="End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension"></a><a href="https://arxiv.org/pdf/1610.09996v2.pdf" target="_blank" rel="external">End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Yang Yu, Wei Zhang, Kazi Hasan, Mo Yu, Bing Xiang, Bowen Zhou</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>IBM Watson</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Reading Comprehension, Chunk extraction, Ranking</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.10</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>针对答案非定长的阅读理解任务，本文提出了DCR（dynamic chunk reader）模型<br>来从给定的文档中抽取可能的候选答案并进行排序。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>本文提出的模型结构共分为四部分，<br>1、Encoder Layer<br>如图所示，这部分是用双向GRU分别对文档（Passage）和问题（Question）进行编码。<br>2、Attention Layer<br>该层采用的方法与相关工作中的mLSTM类似，文档每个时刻的状态h<sub>j</sub><sup>p</sup>都与问题中的每个状态h<sub>k</sub><sup>q</sup>进行匹配得到一个权重向量α<sub>k</sub>，然后再根据该权重向量对问题的GRU隐层输出h<sup>p</sup>进行加权求和，得到文档中该时刻状态h<sub>j</sub><sup>p</sup>对应的上下文向量β<sub>j</sub>，两个向量h<sub>j</sub><sup>p</sup>和β<sub>j</sub>拼接在一起作为该时刻新的表示v<sub>j</sub>。最后再将上述与问题相关的新文档表示v通过双向GRU，得到文档最终的表示γ。<br><img src="media/DCR.png" alt="DC"></p>
<p>3、Chunk-Representation Layer<br>上一部分获得了与问题相关的文档表示γ，那么这部分则是考虑如何抽取候选答案，并获得候选答案的表示向量。本文提出了两种候选答案抽取方法，第一种方法是抽取所有满足训练数据中答案对应词性标注模式的候选项，第二种方法则是简单粗暴地确定一个候选项最大长度，然后遍历所有可能的候选项。至于候选答案的表示方式，本文将候选答案前向GRU的最后一个时刻状态和反向GRU第一个时刻状态拼接在一起作为最终候选项的表示。<br>4、Ranker Layer<br>已经获得了所有候选项的表示，那么接着就是对所有候选项进行打分排序。本文中打分是采用问题的表示和候选项的表示计算内积的方式得到的，本文训练过程中没有采用常见于排序任务的Margin ranking loss，而是先用softmax对所有候选项计算一个概率值，然后采用交叉熵损失函数进行训练。</p>
<p>本文在SQuAD数据集上进行实验，提出的方法效果比之前两篇SQuAD相关paper的方法有较大的提升。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>1、SQuAD <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="external">https://rajpurkar.github.io/SQuAD-explorer/</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、数据集相关论文<br>SQuAD: 100,000+ Questions for Machine Comprehension of Text<br>2、模型相关论文<br>MACHINE COMPREHENSION USING MATCH-LSTM</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>在对文档和问题编码阶段，本篇论文提出的模型与之前mLSTM那篇paper有些相似。两篇论文中模型的主要区别在于：mLSTM那篇论文采用预测起始、终止位置的方法来确定答案，而本文则是先采用一些规则或Pattern的方法来抽取一些候选答案，然后再对候选答案进行排序。</p>
<h2 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a>联系方式</h2><p>有DL或者NLP相关话题，欢迎讨论。destin.bxwang@gmail.com </p>
<h1 id="Knowledge-will-Propel-Machine-Understanding-of-Content-Extrapolating-from-Current-Examples"><a href="#Knowledge-will-Propel-Machine-Understanding-of-Content-Extrapolating-from-Current-Examples" class="headerlink" title="Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples"></a><a href="https://arxiv.org/abs/1610.07708?from=groupmessage&amp;isappinstalled=0" target="_blank" rel="external">Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Amit Sheth, Sujan Perera, and Sanjaya Wijeratne</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Kno.e.sis Center, Wright State University Dayton, Ohio, USA</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Semantic analysis of multimodal data，Machine intelligence,Understanding complex text，EmojiNet</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.10</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>利用知识和多模态数据来解决特定情况下的复杂文本的深层理解问题</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>1、现知识库在处理特定领域问题中的局限性及解决方法<br>（1）知识库的杂乱<br>解决方法：采用自动判别技术，领域知识库索引技术，利用实体和关系的语义去判别所给定知识库领域中的相关部分。<br>（2）知识库数据的不完备和不充足<br>解决方法：使用 human-in-the-loop模型在真实的临床数据和已有的知识库中去发现更多的实体与实体之间的关系。<br>（3）知识表示技术和推理技术的局限性<br>解决方法：在单个属性的表示中加入了三元组和软逻辑的解释能力及其相关概率值和理由。</p>
<p>2、新的研究应用<br>（1）隐实体链接<br>（2）表情符号语义消歧<br>（3）理解和分析web论坛中关于药物滥用的相关讨论<br>利用相关背景知识加强不同种类信息的信息抽取模型<br><img src="media/img1.png" alt="img1"></p>
<p>3、在健康领域中的文本理解模型<br><img src="media/img2.png" alt="img2"></p>
<p>4、使用感知器和文本资料了解城市交通情况<br>(1)交通领域的概念关系网模型<br>(2)概率图模型<br><img src="media/img3.png" alt="img3"></p>
<p>使用领域知识关联不同模态下的上下文相关数据<br><img src="media/img4.png" alt="img4"></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文主要举例说明了知识将推动机器对内容的理解。总体来看本文像一篇综述性的文章，给出了在知识库创建过程中所遇到的问题的解决方案，同时以实际案例来阐述知识在我们实际问题中应用。</p>
<h1 id="AC-BLSTM-Asymmetric-Convolutional-Bidirectional-LSTM-Networks-for-Text-Classification"><a href="#AC-BLSTM-Asymmetric-Convolutional-Bidirectional-LSTM-Networks-for-Text-Classification" class="headerlink" title="AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification"></a><a href="https://arxiv.org/pdf/1611.01884v2.pdf" target="_blank" rel="external">AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Depeng Liang and Yongdong Zhang</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Guangdong Province Key Laboratory of Computational Science, School of Data and<br>Computer Science, Sun Yat-sen University, Guang Zhou, China</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>ACNN; BLSTM; Text Classification</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.11</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>本文提出了一个新的深度学习的模型–AC-BLSTM的模型（即：将ACNN和BLSTM组合在一起），用于句子和文章层面的分类。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>AC-BLSTM模型可以分成四个部分,如Figure 1所示：<br>1.输入: 输入是一个sentence，使用 ( L <em> d )的矩阵表示，其中L表示句子中的L个词，d表示每个词的词向量的维度<br>2.ACNN(Asymmetric CNN): 传统的CNN采用的是 ( k </em> d ) 大小的filter，ACNN则把filter的过程分成 ( 1 <em> d ) 和 ( k </em> 1 ) 的两个过程，相当于是把 ( k <em> d ) 的filter做因式分解。<br>这一层的输入是一个 ( L </em> d ) 的矩阵，对于n个尺度为( 1 <em> d ) 和( ki </em> 1 )的卷积层的输出是一个 [ (L - ki + 1) <em> n ]的矩阵，如下图所示，本文采用了3种不同的卷积核，所以输出是3种不同的[ (L - ki + 1) </em> n ]的矩阵（图中一个彩色的小方块表示 (1 * n)的向量）<br>3.连接层: 为了给BLSTM构造输入，连接层将3种不同卷积层的输出，以Ct^i表示第1种卷积层为LSTM第t个time step贡献的输入，则LSTM网络的第t步输入Ct = [Ct^1, Ct^2, Ct^3]，其中t属于{1,2,…,L-K+1}, K = max{ki}<br>4.BLSTM: LSTM能够很好的解决long time delay 和long range context的问题，但其处理是单向的，而BLSTM能够解决given point的双边的依赖关系，因此，本文选择了BLSTM网络层来学习ACNN输入的特征的dependencies<br>5.Softmax层: 为了应用于分类问题，本文在最后使用全连接层和softmax函数来实现分类。<br><img src="media/Figure1.jpg" alt="Figure1"></p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>文章中使用的数据集<br>1、SST-1 <a href="http://nlp.stanford.edu/sentiment/index.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/index.html</a><br>2、SST-2 <a href="http://nlp.stanford.edu/sentiment/index.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/index.html</a><br>3、Movie Review(MR) <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>4、SUBJ <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>5、TREC <a href="http://cogcomp.cs.illinois.edu/Data/QA/QC/" target="_blank" rel="external">http://cogcomp.cs.illinois.edu/Data/QA/QC/</a><br>6、YELP13 <a href="https://www.yelp.com/dataset_challenge" target="_blank" rel="external">https://www.yelp.com/dataset_challenge</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Yoon Kim于2014年在<a href="http://www.aclweb.org/anthology/D14-1181" target="_blank" rel="external"><strong>Convolutional neural networks for sentence classification</strong></a>一文中提出将词向量和CNN结合，用于句子分类的模型。在该文中，Kim将不同长度的filter的组合在一起，且提出了static或者可以fine-tuning的word embedding模型<br>2、Zhou et al.则于2015年在<a href="https://arxiv.org/abs/1511.08630" target="_blank" rel="external"><strong>A C-LSTM neural network for text classification</strong></a>一文中提出将CNN和LSTM叠加的模型，且使用固定的word embedding<br>3、Szegedy et al.于2015年在<a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="external"><strong>Rethinking the Inception Architecture for Computer Vision</strong></a>中提出了ACNN模型，这减少了参数的个数且提高了模型的表征</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>这篇文章主要贡献就是提出了一个AC-BSLTM的模型用于文本分类，亮点就在于：ACNN可以在减少参数的个数的同时通过增加更多的非线性性来提高表达能力，而BLSTM能够捕捉输入的两端的信息。两者的结合就提高了分类的精度。但事实上，这两个网络模型都是现有的，本文的工作感觉只是两个网络的连接，在本质上没有太大的改进，且在分类精度上的提高也比较有限。</p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>感谢@方嘉倩 @destin wang 和 @min279 三位童鞋的辛勤工作。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;本期的PaperWeekly一共分享四篇最近arXiv上发布的高质量paper，包括：情感分析、机器阅读理解、知识图谱、文本分类。人工智能及其相关研
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.12.12-2016.12.16)</title>
    <link href="http://rsarxiv.github.io/2016/12/18/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-12-12-2016-12-16/"/>
    <id>http://rsarxiv.github.io/2016/12/18/本周值得读-2016-12-12-2016-12-16/</id>
    <published>2016-12-18T17:16:11.000Z</published>
    <updated>2016-12-18T17:28:36.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Building-Large-Machine-Reading-Comprehension-Datasets-using-Paragraph-Vectors"><a href="#Building-Large-Machine-Reading-Comprehension-Datasets-using-Paragraph-Vectors" class="headerlink" title="Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors "></a><a href="http://t.cn/RIbpc9X" target="_blank" rel="external">Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors </a></h2><p>【机器阅读理解】【数据福利】<br>本文利用一种无监督的方法构建了一组大型的机器阅读理解数据集。其中机器阅读理解问题是提供一篇新闻，从5个候选标题中选择一个正确的。无监督的方法用了Mikolov提出的Paragraph Vector（Word2Vec的文档版），用来训练和计算各个新闻标题之间的相似度，产生候选答案。本文所生成的数据集地址：<a href="https://github.com/google/mcafp" target="_blank" rel="external">https://github.com/google/mcafp</a></p>
<h2 id="Multi-Perspective-Context-Matching-for-Machine-Comprehension"><a href="#Multi-Perspective-Context-Matching-for-Machine-Comprehension" class="headerlink" title="Multi-Perspective Context Matching for Machine Comprehension "></a><a href="http://t.cn/RIbdvXM" target="_blank" rel="external">Multi-Perspective Context Matching for Machine Comprehension </a></h2><p>【机器阅读理解】本文的研究基于SQuAD数据集，提出了一个端到端训练模型，主要的思路是passage中与问题相似的span更加倾向于是正确答案。SQuAD是这个领域中有名的数据集，相应的模型很多，本文的结果相对一般。</p>
<h2 id="ConceptNet-5-5-An-Open-Multilingual-Graph-of-General-Knowledge"><a href="#ConceptNet-5-5-An-Open-Multilingual-Graph-of-General-Knowledge" class="headerlink" title="ConceptNet 5.5: An Open Multilingual Graph of General Knowledge "></a><a href="http://t.cn/RIbgeA5" target="_blank" rel="external">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge </a></h2><p>【知识图谱】【资源推荐】本文介绍了一个通用知识图谱ConceptNet 5.5，图谱主页的地址：<a href="http://conceptnet.io/" target="_blank" rel="external">http://conceptnet.io/</a>  相关的code和文档地址： <a href="https://github.com/commonsense/conceptnet5" target="_blank" rel="external">https://github.com/commonsense/conceptnet5</a></p>
<h2 id="Tracking-the-World-State-with-Recurrent-Entity-Networks"><a href="#Tracking-the-World-State-with-Recurrent-Entity-Networks" class="headerlink" title="Tracking the World State with Recurrent Entity Networks "></a><a href="http://t.cn/RIbsLuo" target="_blank" rel="external">Tracking the World State with Recurrent Entity Networks </a></h2><p>【Dynamic Memory】本文介绍了一种新的模型，Recurrent Entity Network (EntNet)，引用外部动态长程记忆来做推理，并在 SYNTHETIC WORLD MODEL、bAbI和CBT三个任务上得到了验证，值得关注。本文工作来自FB LeCun组。</p>
<h2 id="Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents"><a href="#Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents" class="headerlink" title="Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents "></a><a href="http://t.cn/RIbsrka" target="_blank" rel="external">Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents </a></h2><p>【对话系统】用几个关键词来概括一下本文的工作：1、在线训练；2、seq2seq；3、深度增强学习；4、开放域问题。建议对对话系统感兴趣的童鞋研读。</p>
<h2 id="Neural-Emoji-Recommendation-in-Dialogue-Systems"><a href="#Neural-Emoji-Recommendation-in-Dialogue-Systems" class="headerlink" title="Neural Emoji Recommendation in Dialogue Systems "></a><a href="http://t.cn/RIqZTsq" target="_blank" rel="external">Neural Emoji Recommendation in Dialogue Systems </a></h2><p>【对话系统】【Emoji】Emoji表情是大家在平时聊天时经常会用到的，往往一个表情胜过一句话的表达。本文研究了在多轮对话中如何通过上下文来预测和推荐emoji表情，是个很好玩的工作。如果能够分析和预测更广泛的表情包（不仅限于emoji）的话，可能是件更好玩的事情。</p>
<h2 id="Learning-Through-Dialogue-Interactions"><a href="#Learning-Through-Dialogue-Interactions" class="headerlink" title="Learning Through Dialogue Interactions "></a><a href="http://t.cn/RI5dgWk" target="_blank" rel="external">Learning Through Dialogue Interactions </a></h2><p>【对话系统】Jiwei Li的新文章，通过和Teacher的交互（基于知识库相互问和答）来提高bot的学习能力，整体框架仍是增强学习，值得精读。代码和数据都已开放，地址：<a href="https://github.com/facebook/MemNN/tree/master/AskingQuestions" target="_blank" rel="external">https://github.com/facebook/MemNN/tree/master/AskingQuestions</a> torch实现。</p>
<h2 id="Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models"><a href="#Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models" class="headerlink" title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models "></a><a href="http://t.cn/RVbp10D" target="_blank" rel="external">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models </a></h2><p>【seq2seq多样性】【柱搜索】一篇考虑了生成内容多样性的beam search改进算法，可以应用在chatbot、nmt、image caption、vqa等各种场景中。开源代码用torch实现的，基于neuraltalk2代码。地址：<a href="https://github.com/ashwinkalyan/dbs" target="_blank" rel="external">https://github.com/ashwinkalyan/dbs</a>  在线demo地址：<a href="http://dbs.cloudcv.org/captioning" target="_blank" rel="external">http://dbs.cloudcv.org/captioning</a></p>
<h2 id="Multilingual-Word-Embeddings-using-Multigraphs"><a href="#Multilingual-Word-Embeddings-using-Multigraphs" class="headerlink" title="Multilingual Word Embeddings using Multigraphs "></a><a href="http://t.cn/RIqqODu" target="_blank" rel="external">Multilingual Word Embeddings using Multigraphs </a></h2><p>【词向量】本文给了一组单语和多语的词向量学习方法，基于SkipGram模型，skipgram的context考虑比较简单，本文主要是在context上做了一些文章，添加了一些特征，比如syntactic dependencies and word alignments等。</p>
<h2 id="FastText-zip-Compressing-text-classification-models"><a href="#FastText-zip-Compressing-text-classification-models" class="headerlink" title="FastText.zip: Compressing text classification models "></a><a href="http://t.cn/RI4uuHE" target="_blank" rel="external">FastText.zip: Compressing text classification models </a></h2><p>【模型压缩】模型过大是DL的一个问题，尤其是在部署模型时，这个问题尤其明显。本文工作来自FB，是开源分类工具fasttext的一个模型压缩版。FastText的地址：<a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="Mining-Compatible-Incompatible-Entities-from-Question-and-Answering-via-Yes-No-Answer-Classification-using-Distant-Label-Expansion"><a href="#Mining-Compatible-Incompatible-Entities-from-Question-and-Answering-via-Yes-No-Answer-Classification-using-Distant-Label-Expansion" class="headerlink" title="Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion "></a><a href="http://t.cn/RIqG4QU" target="_blank" rel="external">Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion </a></h2><p>【评论挖掘】本文针对的应用场景是从商品评论中挖掘各种商品的兼容性，比如买了个鼠标，想知道这个鼠标和ipad、pc的兼容性如何。文中的Complementary Entity Recognition 方法来自上周同作者的一篇文章，地址是<a href="https://arxiv.org/abs/1612.01039" target="_blank" rel="external">https://arxiv.org/abs/1612.01039</a> 这个应用场景比较接地气，建议对评论挖掘感兴趣的童鞋阅读。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Building-Large-Machine-Reading-Comprehension-Datasets-using-Paragraph-Vectors&quot;&gt;&lt;a href=&quot;#Building-Large-Machine-Reading-Comprehensio
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第十八期</title>
    <link href="http://rsarxiv.github.io/2016/12/17/PaperWeekly-%E7%AC%AC%E5%8D%81%E5%85%AB%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/12/17/PaperWeekly-第十八期/</id>
    <published>2016-12-17T18:37:27.000Z</published>
    <updated>2016-12-17T19:35:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>对话系统是当前的研究热点，也是风险投资的热点，从2016年初开始，成立了无数家做chatbot、语音助手等类似产品的公司，不管是对用户的，还是对企业的，将对话系统这一应用推到了一个新的高度。seq2seq是当前流行的算法框架，给定一个输入，模型自动给出一个不错的输出，听起来都是一件美好的事情。seq2seq在对话系统中的研究比较多，本期PaperWeekly分享4篇非常新的paper notes，涉及到如何提高所生成对话的流畅度和多样性，使得对话系统能够更加接近人类的对话。4篇paper如下：</p>
<p>1、Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation, 2016<br>2、A Simple, Fast Diverse Decoding Algorithm for Neural Generation, 2016<br>3、DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS, 2016<br>4、A Diversity-Promoting Objective Function for Neural Conversation Models, 2015</p>
<h1 id="Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation"><a href="#Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation" class="headerlink" title="Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation"></a><a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Key Laboratory of High Confidence Software Technologies (Peking University), MoE, China<br>Institute of Software, Peking University, China<br>Institute of Network Computing and Information Systems, Peking Univerity, China<br>Institute of Computer Science and Technology, Peking University, China</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>content-introducing approach<br>neural network-based<br>generative dialogue systems<br>seq2BF</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>使用引入内容方法，用于处理基于神经网络的生成式对话系统</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p><img src="media/model-18.png" alt="mode"></p>
<p>该模型由两部分组成：<br>1、use PMI to predict a keyword for the reply<br>使用逐点互信息(PMI)进行预测，选取PMI值最大的单词作为回答中的关键词，该关键词可以出现在回答语句中的任意位置。<br><img src="media/%E5%85%AC%E5%BC%8F.png" alt="公式"></p>
<p>2、generate a reply conditioned on the keyword as well as the query<br>使用sequence to backward and forward sequences(seq2BF)模型来生成包含关键词的回答。以该关键词为基点，将回答语句划分为两个序列：<br>(1) 反向序列：关键词左侧的所有单词以逆序排列<br>(2) 正向序列：关键词右侧的所有单词以顺序排列</p>
<p>seq2BF模型具体工作如下：<br>(1) 使用seq2seq神经网络将问题编码，仅对关键词左侧的单词进行解码，逆序输出每个单词<br>(2) 使用另一个seq2seq模型将问题再次编码，在给定上步中解码后的逆序单词序列下，对回答中的剩余单词进行顺序解码，输出最终单词序列<br><img src="media/%E5%85%AC%E5%BC%8F3.png" alt="公式3"></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>Dataset：<a href="http://tieba.baidu.com" target="_blank" rel="external">http://tieba.baidu.com</a></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、 Dialogue Systems<br>(1) (Isbell et al., 2000; Wang et al., 2013) retrieval methods<br>(2)  (Ritter et al., 2011) phrase-based machine translation<br>(3)  (Sordoni et al., 2015; Shang et al., 2015) recurrent neural networks </p>
<p>2、 Neural Networks for Sentence Generation<br>(1)  (Sordoni et al., 2015) bag-of-words features<br>(2)  (Shang et al., 2015) seq2seq-like neural networks<br>(3)  (Yao et al., 2015; Serban et al., 2016a) design hierarchical neural networks<br>(4)  (Li et al., 2016a) mutual information training objective</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于，不同与目前普遍存在的从句首到句尾顺序生成目标单词的方法，引入逐点互信息方法来预测回答语句中的关键词，使用seq2BF机制确保该关键词可以出现在目标回答语句的任意位置之中并确保输出的流利度，相比于seq2seq的生成方法显著地提升了对话系统的质量。</p>
<h1 id="A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation"><a href="#A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation" class="headerlink" title="A Simple, Fast Diverse Decoding Algorithm for Neural Generation"></a><a href="https://arxiv.org/abs/1611.08562" target="_blank" rel="external">A Simple, Fast Diverse Decoding Algorithm for Neural Generation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li, Will Monroe and Dan Jurafsky</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Stanford</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>seq2seq, diversity, RL</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>seq2seq模型decoder时改进beam search，引入惩罚因子影响排序结果，并加入强化学习模型来自动学习diversity rate，使得解码出的结果更具多样性</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p><img src="media/18-0.png" alt="18-0"></p>
<p>对比标准beam search，本模型引入惩罚因子，公式如下</p>
<p><img src="media/18-1.png" alt="18-1"></p>
<p>其中$\gamma$称为diversity rate，k’范围为[1,k]，K为beam size<br>强化学习模型中，策略为</p>
<p><img src="media/18-2.png" alt="18-2"></p>
<p>reward为评价指标，例如机器翻译中的BLEU值等</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>1、回复生成实验数据集：OpenSubtitles <a href="https://github.com/jiweil/mutual-information-for-neural-machine-translation" target="_blank" rel="external">https://github.com/jiweil/mutual-information-for-neural-machine-translation</a><br>（代码模型可从作者另外一篇文章的源码稍加改动）</p>
<p>2、机器翻译数据集：WMT’14 <a href="http://www.statmt.org/wmt13/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt13/translation-task.html</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/18-3.png" alt="18-3"></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本模型的创新点在于引入惩罚因子，使得decoder时对standard beam search算法进行重排序，并引入强化学习模型，自动学习diversity rate。作者分别在三个实验上进行验证，机器翻译、摘要抽取与对话回复生成，实验表明在不同的实验上有不同的表现，但是总体而言本方法能够在一定程度上解码出更具有多样性的句子。（思路简明清晰，对于传统的beam search稍加改动，原文中作者提到在Matlab代码中只改动一行即可）</p>
<h1 id="DIVERSE-BEAM-SEARCH-DECODING-DIVERSE-SOLUTIONS-FROM-NEURAL-SEQUENCE-MODELS"><a href="#DIVERSE-BEAM-SEARCH-DECODING-DIVERSE-SOLUTIONS-FROM-NEURAL-SEQUENCE-MODELS" class="headerlink" title="DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS"></a><a href="https://arxiv.org/abs/1610.02424" target="_blank" rel="external">DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun1 Stefan Lee, David Crandall &amp; Dhruv Batra</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Virginia Tech, Blacksburg, VA, USA<br>Indiana University, Bloomington, IN, USA</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Beam Search; Diversity; Image Caption; Machine Translation; Visual Question Answer; Chatbot</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016.10</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何改进beam search解码算法，使其在seq2seq模型中可以生成更加丰富的结果？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>经典的beam search算法以最大后验概率作为优化目标函数，每一个time step只保留B个最优的状态，是一种典型的贪心算法，这个经典算法常常被用于解码可选状态数量多的情形，比如生成对话、生成图片描述、机器翻译等，每一步都有词表大小的可选状态集。seq2seq模型的流行，让这种解码算法的研究变得热门。在生成对话任务时，用经典的beam search会生成类似“我不知道”等这种没有营养的对话，虽然没有语法上的错误，而且可能在一定的评价体系内会得到不错的分数，但实际应用效果太差，因此diversity的研究变得热门。</p>
<p>本文针对diversity的问题，提出了一种改进版的beam search算法，旨在生成更加多样性的话。</p>
<p><img src="media/18-5.png" alt="18-5"></p>
<p>新算法的主要思路是将经典算法中的Beam进行分组，通过引入一个惩罚机制，使得每一组的相似度尽量低，这一项保证了生成的话相互之间差异更大一些，即满足了多样性的需求，在每一组Beam中，用经典的算法进行优化搜索。具体的算法流程如下图：</p>
<p><img src="media/18-6.png" alt="18-6"></p>
<p>实验中，用了Image Caption、Machine Translation和VQA三个任务进行了对比，验证了本文算法的有效性，并且对算法中的几个参数进行了敏感度分析，分析了分组数对多样性的影响。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>1、本文算法torch实现 <a href="https://github.com/ashwinkalyan/dbs" target="_blank" rel="external">https://github.com/ashwinkalyan/dbs</a><br>2、本文在线demo dbs.cloudcv.org<br>3、neuraltalk2实现 <a href="https://github.com/karpathy/neuraltalk2" target="_blank" rel="external">https://github.com/karpathy/neuraltalk2</a><br>4、机器翻译开源实现dl4mt <a href="https://github.com/nyu-dl/dl4mt-tutorial" target="_blank" rel="external">https://github.com/nyu-dl/dl4mt-tutorial</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>相关的工作主要分类两类：<br>1、Diverse M-Best Lists<br>2、Diverse Decoding for RNNs<br>之前Jiwei Li将解码算法的目标函数换成了互信息进行优化解码，对diversity进行了研究。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文研究的问题是一类基础问题，beam search算法作为一种经典的近似解码算法，应用的场景非常多。但在实际应用中，尤其是具体到生成对话、生成答案等任务上，存在一些适应性的问题，比如diversity。只是生成简单而又安全的话对于实际应用没有太多的意义，所以本文的研究非常有意义。本文的实验从三个不同的任务上对改进后的beam search都做了对比验证，非常扎实的结果验证了算法的有效性，并且对几个关键参数进行了敏感度分析，有理有据。同时在github上开源了代码，并且给出了一个在线demo。在评价方面，不仅仅设计了几个自动评价指标，而且用了人工评价的方法对本文算法进行了验证，是一篇非常好的paper，值得学习。</p>
<h1 id="A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models"><a href="#A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models" class="headerlink" title="A Diversity-Promoting Objective Function for Neural Conversation Models"></a><a href="https://arxiv.org/pdf/1510.03055.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Stanford University, Stanford, CA, USA<br>Microsoft Research, Redmond, WA, USA</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Sequence-to-sequence neural network models, conversational responses, Maximum Mutual Information(MMI)</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2015</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>使用MMI训练sequence-to-sequence model for conversational responses generation<br>传统的ML(最大似然估计)在训练sequence-to-sequence model的时候，易产生与输入无关的’safe’ responses(最大似然估计的弊病—-always try to cover all mode of input data)<br>作者通过使用MMI, 最大化输入与输出的互信息，能够有效避免与输入无关的responses，得到更为diverse的responses.</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>MMI最早在speech recognition中提出并应用(discriminative training criteria). 语音识别中，通常先用ML训练声学模型，然后再接MMI和语言模型，对声学模型进一步调优。</p>
<p>在本文中，作者通过提出MMI用于seq-to-seq model的优化。作者提出了MMI-antiLM和MMI-bidi 两个不同的MMI的formulations. MMI在seq-to-seq的应用中存在decoding的问题。</p>
<p>MMI-antiLM中，作者通过使用带有权重的LM以生成更为diverse的responses by penalizing first word。</p>
<p>MMI-bidi中，搜索空间的数目过大，导致expolring所有的可能性在实际中无法实现。作者首先产生N-best list, 然后根据相应的准则函数 re-rank得到的N-best list。</p>
<p>在MMI不同的formulation中，作者通过启发式的设计，使得decoding更为容易且产生的response更为diverse，在相关的数据集上取得了较好的BLEU且产生的response更为diverse。</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>最大后验概率通常作为优化的目标函数，但很多应用场景中得到的结果并不理想。本文采用了一个新的而且也是其他领域中比较常见的目标函数来替换最大后验概率，在生成对话时得到了更加丰富的结果。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对话系统是一个相对高级的、综合性很强的任务，所依赖的基础任务比较多，比如分词、命名实体识别、句法分析、语义角色标注等等。对于规范的中文表达而言，句法分析仍是一个没有解决好的问题，更何况是不那么规范的人话，句法分析的准确性又要下一个level了，随之语义角色标注也得不到好的效果。经典的、基础的任务还有很长的路要走，对话系统这种更难、更复杂的任务相信不是一年、两年就可以突破的事情，虽然现在大热，做的人很多，但就目前的研究水平来看，应该还有很长的路要走。seq2seq是个逃避这些问题的好方法和好思路，但相对来说更加不成熟，而且存在着很多的问题，想通过大量的数据来覆盖所有的问题，是一种不太科学的思路。我想，seq2seq是个好方法，但传统的NLP方法也是必不可少的，而且两者应该是相互补充的。越多的人关注对话系统，就会越快地推动这个领域的发展，希望早日看到靠谱的、成熟的解决方案。感谢@Penny、@tonya、@zhangjun和@皓天 四位童鞋完成的paper notes。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;对话系统是当前的研究热点，也是风险投资的热点，从2016年初开始，成立了无数家做chatbot、语音助手等类似产品的公司，不管是对用户的，还
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.12.05-2016.12.09)</title>
    <link href="http://rsarxiv.github.io/2016/12/11/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-12-05-2016-12-09/"/>
    <id>http://rsarxiv.github.io/2016/12/11/本周值得读-2016-12-05-2016-12-09/</id>
    <published>2016-12-11T16:51:29.000Z</published>
    <updated>2016-12-11T17:01:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager"><a href="#End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager" class="headerlink" title="End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager "></a><a href="http://t.cn/RfDCS5X" target="_blank" rel="external">End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager </a></h2><p>【对话系统】自然语言理解和对话管理通常是两个独立的任务，NLU的误差会影响到对话管理的效果。本文将两个任务联合起来进行端到端的训练，得到了不错的效果。建议研究对话系统的童鞋来读。</p>
<h2 id="Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots"><a href="#Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots" class="headerlink" title="Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots "></a><a href="http://t.cn/RIhcTFP" target="_blank" rel="external">Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots </a></h2><p>【对话系统】本文研究的问题是基于检索的多轮对话机器人，单轮对话和多轮对话的一大区别在于后者需要考虑更多的上下文内容，本文在检索答案时除了相关性还考虑了上下文之间的关系，建议研究检索式聊天机器人的童鞋来读本文。本文还给出了一个测试数据集，地址在：<a href="http://t.cn/RIhf4Sh" target="_blank" rel="external">http://t.cn/RIhf4Sh</a></p>
<h2 id="CER-Complementary-Entity-Recognition-via-Knowledge-Expansion-on-Large-Unlabeled-Product-Reviews"><a href="#CER-Complementary-Entity-Recognition-via-Knowledge-Expansion-on-Large-Unlabeled-Product-Reviews" class="headerlink" title="CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews "></a><a href="http://t.cn/RfDpyCm" target="_blank" rel="external">CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews </a></h2><p>【相关实体识别】本文研究的问题是产品评论数据中的相关实体识别问题，评论数据是个很有意思的数据，用户在买东西时希望可以通过对比买到更好的产品。建议做评论挖掘的童鞋读。</p>
<h2 id="The-Evolution-of-Sentiment-Analysis-A-Review-of-Research-Topics-Venues-and-Top-Cited-Papers"><a href="#The-Evolution-of-Sentiment-Analysis-A-Review-of-Research-Topics-Venues-and-Top-Cited-Papers" class="headerlink" title="The Evolution of Sentiment Analysis - A Review of Research Topics, Venues, and Top Cited Papers "></a><a href="http://t.cn/RIvkAop" target="_blank" rel="external">The Evolution of Sentiment Analysis - A Review of Research Topics, Venues, and Top Cited Papers </a></h2><p>【情感分析】【综述】一篇很细的情感分析的综述，刚刚进入这个领域的童鞋可以来读一读。</p>
<h2 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h2><h2 id="文本上的算法"><a href="#文本上的算法" class="headerlink" title="文本上的算法"></a><a href="http://t.cn/RhtyvzE" target="_blank" rel="external">文本上的算法</a></h2><p>《文本上的算法》v4.0：增加自然语言处理和对话系统章节；丰富了其他内容。</p>
<h2 id="NIPS-2016-Spotlight-Videos"><a href="#NIPS-2016-Spotlight-Videos" class="headerlink" title="NIPS 2016 Spotlight Videos"></a><a href="http://t.cn/RfB5cA2" target="_blank" rel="external">NIPS 2016 Spotlight Videos</a></h2><p>【NIPS 2016 Spotlight Videos】NIPS 2016焦点视频集。神经信息处理系统大会(Conference and Workshop on Neural Information Processing Systems)，简称NIPS，是一个关于机器学习和计算神经科学的国际会议。该会议固定在每年的12月举行,由NIPS基金会主办。NIPS是机器学习领域的顶级会议 。在中国计算机学会的国际学术会议排名中，NIPS为人工智能领域的A类会议。(via @网路冷眼)</p>
<h2 id="2016年深度学习的主要进展"><a href="#2016年深度学习的主要进展" class="headerlink" title="2016年深度学习的主要进展"></a><a href="http://t.cn/RIvuIuV" target="_blank" rel="external">2016年深度学习的主要进展</a></h2><p>2016年深度学习的主要进展，The major advancements in Deep Learning in 2016 (via @视觉机器人)</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读&quot;&gt;&lt;a href=&quot;#一周值得读&quot; class=&quot;headerlink&quot; title=&quot;一周值得读&quot;&gt;&lt;/a&gt;一周值得读&lt;/h1&gt;&lt;h2 id=&quot;End-to-End-Joint-Learning-of-Natural-Language-Underst
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第十七期</title>
    <link href="http://rsarxiv.github.io/2016/12/10/PaperWeekly-%E7%AC%AC%E5%8D%81%E4%B8%83%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/12/10/PaperWeekly-第十七期/</id>
    <published>2016-12-10T18:16:44.000Z</published>
    <updated>2016-12-10T20:07:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>命名实体识别是自然语言处理中一个非常基础的工作，是自然语言处理中关键的一个环节。监督学习是解决命名实体识别的一个基本手段，但标注数据的获取成本往往会比较高，本期PaperWeekly将带大家来看一下如何通过半监督或者无监督的方法来做命名实体识别任务。本期分享的4篇Paper Notes分别是：</p>
<p>1、Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre), 2016<br>2、ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering, 2015<br>3、Bootstrapped Text-level Named Entity Recognition for Literature, 2016<br>4、Recognizing Named Entities in Tweets, 2011</p>
<h1 id="Building-a-Fine-Grained-Entity-Typing-System-Overnight-for-a-New-X-X-Language-Domain-Genre"><a href="#Building-a-Fine-Grained-Entity-Typing-System-Overnight-for-a-New-X-X-Language-Domain-Genre" class="headerlink" title="Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre)"></a><a href="https://arxiv.org/pdf/1603.03112v1.pdf" target="_blank" rel="external">Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre)</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Lifu Huang, Jonathan May, Xiaoman Pan, Heng Ji</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Rensselaer Polytechnic Institute,<br>Information Sciences Institute,<br>Rensselaer Polytechnic Institute</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Entity Recognition and Typing, Unspuversied</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv, 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>细粒度的实体识别是这几年比较流行的工作。传统的方法是需要先预定义一组实体所属类型，随后使用大量的标注数据来训练多分类器。本文针对需要标注数据的问题，提出了一个使用非监督学习的思路来解决这个问题</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本文中方法的架构如下图:</p>
<p><img src="media/overview.png" alt="overvie"></p>
<p>1）通过entity mention的语料，构建entity mention的context<br>2）随后构建知识库的表达<br>3）通过知识库和entity mention进行连接<br>4）将连接后的数据学习三种表达</p>
<ul>
<li>a general entity distributed representation</li>
<li>a specific context representation</li>
<li>a knowledge representation</li>
</ul>
<p>其中entity distributed representation主要是通过上下文来表达实体。<br>而 a specific context representation主要是表达一些local feature和一些语言结构的特征。<br>最后a knowledge representation主要是用来模拟领域相关的知识</p>
<p>最后算法通过一个层次聚类算法来获取entity mention可能的分类信息</p>
<p>1、General Entity Representation<br>entity mention的表达作者主要是用了Skip-gram model通过大量的语料来训练，最终可以得到每个entity mention的表达。这个思路的好处是让两个entity mention属于同一类型时，entity mention的上下文会比较相似，进而可以得到相似的分布式表达</p>
<p>2、a specific context representation<br>为了得到a specific context representation，本文使用AMR（(Abstract Meaning Representation）语法或者句法结构的上下文。<br>其生成的结构如下图所示。根据给定的entity mention以及对应关系，首先选择entity mention可能的类型，如关系为ARG0 capital of ARG1则ARG0可能的类型则为国家，同理ARG1可能的类型为城市。随后将所有entity mention可能的候选类型通过一个encoder-decoder模型得到一个单一的表达</p>
<p><img src="media/context%20specific.png" alt="context specifi"></p>
<p>3、Knowledge Representation</p>
<p>由于entity mention的类型在很多情况是非常依赖领域相关的知识库的。因此本文也对知识库进行建模，从而推断出在某个相关领域下更细粒度的实体。为例计算Knowledge Representation，首先对entity mention跟知识库做连接。随后根据链接的实体和实体对应的属性以及类型信息构建一个基于权重的二步图。构建好的二步图根据 Large-scale information network embedding算法来对这个二步图训练并得到其分布式表达。</p>
<p>最后对于一个entity mention，将该entity mention对应的三种表达General Entity Representation，a specific context representation和Knowledge Representation整合，通过一个hierarchical X-means clustering算法得到这个entity mention在一个分类体系下的type信息。最终完成识别实体类型的信息。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>细粒度的实体识别是这几年比较流行的工作。传统的方法是需要先预定义一组实体所属类型，随后使用大量的标注数据来训练多分类器。这篇文章的创新点是提出了一个非监督学习的算法来识别实体所属的type，这种非监督的方法在缺少标注数据的垂直领域具有一定的实用性。本文的思路主要是通过文章中的entity mention跟知识库进行连接，通过文章的上下文学习entity mention的分布式表达，同时通过学习知识库中实体和类型的分布式表达。最后将这些表达送入一个层次聚类算法，entity mention得到的embedding和相似的知识库符号embedding会聚到同一个聚类下。进而通过非监督的方法对entity mention打上type的标签。实验证明本文的方法可以跟监督学习起到类似的效果。</p>
<h1 id="ClusType-Effective-Entity-Recognition-and-Typing-by-Relation-Phrase-Based-Clustering"><a href="#ClusType-Effective-Entity-Recognition-and-Typing-by-Relation-Phrase-Based-Clustering" class="headerlink" title="ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering"></a><a href="http://nlp.cs.rpi.edu/paper/entitytyping.pdf" target="_blank" rel="external">ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Xiang Ren, Ahmed El-Kishky, Chi Wang, Fangbo Tao, Clare R. Voss, Heng Ji, Jiawei Han</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>University of Illinois at Urbana-Champaign,<br>Microsoft Research, Redmond,<br>Rensselaer Polytechnic Institute,<br>Army Research Laboratory, Adelphi</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Entity Recognition and Typing,<br>Relation Phrase Clustering</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>KDD, 2015</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>远程监督方法在特定领域的实体抽取方面存在领域扩展性差、实体歧义问题以及上下文稀缺三大问题，本文主要研究如何改进这三个问题。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>针对上述的三个问题，本文提出了各自对应的解决思路：只使用浅层的分析方法例如POS等解决领域独立性问题；对entity mention(token span in the text document which refers to a real-world entity)应用词形和上下文联合建模来解决歧义问题；挖掘relation phrase和entity mention的共现情况，利用relation phrase前后实体（主语和宾语）的类别来找到相同的关系，进而辅助实体类型的推断。基于上述的思路，本文提出了ClusType的方法。</p>
<p>ClusType的问题定义如下：给定一个特定领域的文档集合，一个实体类型集合以及一个知识库，主要完成三个任务：第一，从文档集合中抽取出候选的entity mention集合；第二，将一部分entity mention链接到知识库，作为种子entity mention集合；第三，对于剩余未完成知识链接的entity mention集合，预测每一个entity mention的对应实体类别。</p>
<p>根据任务的定义，整个框架也分为三个部分，分别解决这三个任务。</p>
<p>本文方案的具体思路如下：</p>
<p>1、构建关系图</p>
<p>关系图的基本样式如下：  </p>
<p><img src="media/graph.png" alt="graph"></p>
<p>图当中的节点主要分为三种：entity mention, surface name, relation phrase.<br>图中的边的类型也有三种：entity mention和surface name的关系、surface name和relation phrase在语料中的共现情况、entity mention和entity mention的关系，表现entity mention之间的相似程度。这三个关系均是通过邻接矩阵的形式表示。<br>关于三种要素的确定，relation phrase的确定主要参考开放域抽取的方法，entity mention的确定方法也比较简单：首先找到固定长度的一个频繁词串集；为集合中每一个词串计算两两之间的得分，得分越高证明越需要合并；在合并的过程中，利用贪心算法，从得分最高开始合并，直到所有得分均低于某一阈值。</p>
<p>2、种子集合的生成</p>
<p>这里利用了dbpedia-spotlight工具进行entity mention到知识库的映射，只选取置信度得分高于0.8的作为有效输出。</p>
<p>3、实体类型推断<br>目标函数如下：<br><img src="media/function.png" alt="function"><br>公式共分为三部分：<br>第一部分遵循实体关系共现假设：如果一个surface name经常在relation phrase前后出现，那么它的类型应该同relation phrase前后实体的类型相关。  </p>
<p>第二部分遵循两个假设。<br>假设一：如果两个relation phrase相似，那么他们前后实体的类型也应该相似；<br>假设二：判断两个relation phrase相似的特征为词形、上下文和其前后实体的类型。<br>因此，第二部分的作用在于根据两个假设建模一个基于joint non-negative matrix factorization的multi-view clustering.</p>
<p>第三部分就是建模entity mention对应实体类别、entity mention之间的关系以及引入种子集合的监督，利用一个entity mention的surface name和relation phrase对应的关系类别推断关系类型，同时考虑到相似entity mention的一致性以及对于种子集合的预测误差函数。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>本文主要借鉴两方面的工作，一部分是远距离监督的方法，另一部分是开放关系抽取。<br>远距离监督的工作主要有：<br>1、N. Nakashole, T. Tylenda, and G. Weikum. Fine-grained semantic typing of emerging entities. In ACL, 2013.<br>2、T. Lin, O. Etzioni, et al. No noun phrase left behind: de- tecting and typing unlinkable entities. In EMNLP, 2012.<br>3、X. Ling and D. S. Weld. Fine-grained entity recognition. In AAAI, 2012.<br>开放关系抽取的工作主要有：<br>1、A. Fader, S. Soderland, and O. Etzioni. Identifying relations for open information extraction. In EMNLP, 2011.</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文通过对于远程监督方法的缺陷分析，提出了一种基于关系短语的实体识别方法。同时，还提出了一个领域无关的生成relation phrase和entity mention。通过将关系短语的聚类和实体类型的识别联合建模，可以在解决实体歧义和上下文问题上发挥很大的作用，而且可以根据entity mention的surface name和relation phrase预测关系类型。同时，我个人认为，将实体识别和关系识别进行联合建模可以起到一个相互促进的作用，而且可以很好的避免在这两个任务当中引入深度语法分析的工具如依存、句法分析等，减少误差积累和领域依赖性。未来两种任务结合依旧是一个很好的研究方向和热点。</p>
<h1 id="Bootstrapped-Text-level-Named-Entity-Recognition-for-Literature"><a href="#Bootstrapped-Text-level-Named-Entity-Recognition-for-Literature" class="headerlink" title="Bootstrapped Text-level Named Entity Recognition for Literature"></a><a href="http://people.eng.unimelb.edu.au/tbaldwin/pubs/acl2016-ner.pdf" target="_blank" rel="external">Bootstrapped Text-level Named Entity Recognition for Literature</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Julian Brooke，Timothy Baldwin，Adam Hammond</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>English and Comparative Literature San Diego State University<br>Computing and Information Systems The University of Melbourne</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NER，Brown clustering，Text-level context classifier</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>在无标注数据的情况下，对Literature做命名实体识别</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>模型主要分为四个部分：<br>1、Corpus preparation and segmentation<br>使用GutenTag tool对语料做基本的名称切分<br>2、Brown clustering<br>在预先切分好的预料上做Brown clustering。根据Brown clustering的聚类中的每个类的rank值，将聚类结果分成三个类别（PERSON，LOCATION，catch- all category）并将其作为Bootstrap的种子进行训练。<br>3、Text-level context classifier<br>为了解决Brown clustering聚类结果可能出现的一些confusion，引入了Text-level context classifier的思想。构建名称特征向量，将种子集数据放到LR模型中进行训练，得到分类模型。<br>4、Improved phrase classification<br>为解决模型对短语名词分类不准确问题，引入了改进的短语名称分类方法，在LR模型得到的p(t|r)值的基础上进一步对其优化得到修正的p’(t|r) ，修正方法如下：<br> <img src="media/imag1.png" alt="imag1"></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>1、dataset：<a href="https://www.gutenberg.org" target="_blank" rel="external">https://www.gutenberg.org</a><br>2、GutenTag tool：<a href="http://www.projectgutentag.org" target="_blank" rel="external">http://www.projectgutentag.org</a>   </p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>在Literature上做NER任务的工作包括：<br>1、(He et al., 2013)character speech identification<br>2、(Bamman et al., 2014)analysis of characterization<br>3、(Vala et al., 2015)character identification<br>4、(Vala et al. 2015)character identification deal the multiple aliases of the same character problem</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于，使用了无监督学习模型对特定领域(fiction)知识做NER，并取得了很好的效果。但是本文方法主要研究特定领域知识的NER，因此本方法使用在跨领域跨语言的NER识别任务中并不能达到很好的效果，方法具有一定的局限性。</p>
<h1 id="Recognizing-Named-Entities-in-Tweets"><a href="#Recognizing-Named-Entities-in-Tweets" class="headerlink" title="Recognizing Named Entities in Tweets"></a><a href="http://people.dbmi.columbia.edu/~szhang/P11-1037.pdf" target="_blank" rel="external">Recognizing Named Entities in Tweets</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Xiaohua Liu, Shaodian Zhang, Furu Wei, Ming Zhou</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Harbin Institute of Technology,<br>Shanghai Jiao Tong University,<br>Microsoft Research Asia</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Named Entity Recognition, Semi-Supervised Learning</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL, 2011</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何建立一种半监督学习的模型对使用非正式语言的tweet进行命名实体识别？</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>现有的分词、词性标注、NER工具解决非正式语言占主导的tweet时常常会失效，得不到令人满意的结果，而twitter作为一种主流的社交媒体，有着丰富的语料和非常高的研究价值。本文以tweet为研究对象，提出了一种基于bootstrapping的半监督学习方案。</p>
<p>tweet的NER任务包括四类实体：Person、Location、Organization和Product，标注方法用BILOU标注法，而没有用经典的IOB标注法。</p>
<p>本文方案的具体思路如下：</p>
<p><img src="media/knn-crf.png" alt="knn-crf"></p>
<p>1、KNN分类器</p>
<p>将tweet中的每个词用词袋模型表示，输入到KNN中得到一个分类标签，这个标签作为CRF标注时的输入。</p>
<p>2、CRF标注器</p>
<p>NER是一个典型的序列标注任务，CRF是解决序列标注问题的一个典型方法。</p>
<p>3、训练过程：</p>
<p>（1）先根据已有标注数据，训练好初始的KNN和CRF模型。<br>（2）获得未标注的tweet，每条tweet中的每个词都经过KNN分类器，得到一个分类标签和相应的概率，如果这个概率大于预设阈值，则更新这个标签给该词。整个tweet经过KNN之后，作为特征输入到CRF模型中进行预测，如果预测出的结果概率大于预设阈值，则认为该标注结果可靠，加入可靠结果集中。<br>（3）当可靠结果集的数量达到N=1000时，则重新训练KNN和CRF模型，并且清空可靠结果集，继续（2）的过程。</p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>基于bootstrapping做NER任务的工作还包括：</p>
<p>1、Instance weighting for domain adaptation in nlp, 2007<br>2、Domain adaption bootstrapping for named entity recognition, 2009</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>本文是比较早的文章了，算是比较早地探索tweet文本挖掘。bootstrapping是一种经典的半监督学习方法，通过从大量的非标注文本中进行学习和补充，来提高训练数据集的规模。tweet是一种非正式语言的文本，现有的NLP工具基本上都不好用，包括微博、论坛的文本都面临这样的问题，而且这样的文本占据着更大的比重，非常有必要对类似的文本进行NLP工具的研究，大概想了两种思路，要么专门地来研究一套适合这种非正式文本的工具，要么想办法将这样的文本转化为正式的语言，用现有的工具来解决问题。现在很火的chatbot对话理解也面临这样的问题，大家在和bot对话的时候说的话也是类似的非正式语言，如何准确理解和分析这类话，对于chatbot能否真的被应用至关重要。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>NER的应用场景非常广泛，基于监督学习的训练方法是最简单、最有效的方法，但在实际应用中常常会遇到训练数据难以获得的尴尬境地，那么半监督和无监督学习的研究正是为了解决这个问题，值得关注！感谢@高桓 @韩其琛 @min279 @zhangjun 四位童鞋的辛勤工作。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;命名实体识别是自然语言处理中一个非常基础的工作，是自然语言处理中关键的一个环节。监督学习是解决命名实体识别的一个基本手段，但标注数据的获取成
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.11.28-2016.12.02)</title>
    <link href="http://rsarxiv.github.io/2016/12/04/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-11-28-2016-12-02/"/>
    <id>http://rsarxiv.github.io/2016/12/04/本周值得读-2016-11-28-2016-12-02/</id>
    <published>2016-12-04T18:06:33.000Z</published>
    <updated>2016-12-04T18:22:03.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation"><a href="#A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation" class="headerlink" title="A Simple, Fast Diverse Decoding Algorithm for Neural Generation "></a><a href="http://t.cn/Rfj8F3k" target="_blank" rel="external">A Simple, Fast Diverse Decoding Algorithm for Neural Generation </a></h2><p>【beam search】在用seq2seq做一些nlp任务的时候，解码器负责将结果一个个地解出来。解码出的结果应该具有多样性的特点，尤其是在chatbot应用中体现更为突出。传统的beam search算法在解码时常常会解出一些非常安全但是没有实际意义的response，类似于“呵呵呵”，“我认为是这样的”这里的话。本文的工作针对这一问题，提出了一种改进版的beam search算法，通过引入一个惩罚因子来影响排序结果，从而使得解码出的结果更加多样性。建议研究seq2seq或者尝试用它来解决一些问题的童鞋可以精读此文。本文来自Jiwei Li。</p>
<h2 id="Dialogue-Learning-With-Human-In-The-Loop"><a href="#Dialogue-Learning-With-Human-In-The-Loop" class="headerlink" title="Dialogue Learning With Human-In-The-Loop "></a><a href="http://t.cn/Rf8XOcr" target="_blank" rel="external">Dialogue Learning With Human-In-The-Loop </a></h2><p>【对话系统】【在线学习】在线学习是chatbot在与人交互的过程中自动学习的一种方法，快速而且有效。本文给出了一种基于强化学习的在线交互学习方案，作者是Jiwei Li。建议研究或者做chatbot应用的童鞋可以好好研读此文。</p>
<h2 id="Visual-Dialog"><a href="#Visual-Dialog" class="headerlink" title="Visual Dialog "></a><a href="http://t.cn/RfH7BWW" target="_blank" rel="external">Visual Dialog </a></h2><p>【多模态对话】多模态问答（VQA）是一个比较好玩的任务，本文在此基础上提出了一个更加复杂而且有意思的任务，即给定一张图像，给出若干个问和答的历史对话，提出一个新问题，要求给出正确答案。问题不仅仅需要理解图片，而且需要理解历史对话。新的任务意味着新的坑，文中给出了一些常见NN模型作为baseline，感兴趣的童鞋可以入坑。</p>
<h2 id="Neural-Machine-Translation-with-Latent-Semantic-of-Image-and-Text"><a href="#Neural-Machine-Translation-with-Latent-Semantic-of-Image-and-Text" class="headerlink" title="Neural Machine Translation with Latent Semantic of Image and Text "></a><a href="http://t.cn/RfjRQMP" target="_blank" rel="external">Neural Machine Translation with Latent Semantic of Image and Text </a></h2><p>【Visual NMT】就在NMT被讨论地如火如荼的时候，还有一部分工作是结合多模态（图片）来做机器翻译，因为人类获取信息不仅仅可以通过文字，图片也是一个重要的学习资源。</p>
<h2 id="Scalable-Bayesian-Learning-of-Recurrent-Neural-Networks-for-Language-Modeling"><a href="#Scalable-Bayesian-Learning-of-Recurrent-Neural-Networks-for-Language-Modeling" class="headerlink" title="Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling "></a><a href="http://t.cn/RfjELTY" target="_blank" rel="external">Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling </a></h2><p>【贝叶斯学习】通过BPTT来训练的RNN在解决问题上会存在过拟合的问题，一个主要原因是随机优化训练无法给出模型权重的概率估计，本文通过最近stochastic gradient Markov Chain Monte Carlo的研究来试着学习模型权重的概率。语言模型的实验结果和其他的相关实验结果表明本文所用的方法确实有效。</p>
<h2 id="Learning-Python-Code-Suggestion-with-a-Sparse-Pointer-Network"><a href="#Learning-Python-Code-Suggestion-with-a-Sparse-Pointer-Network" class="headerlink" title="Learning Python Code Suggestion with a Sparse Pointer Network "></a><a href="http://t.cn/RfjEjY5" target="_blank" rel="external">Learning Python Code Suggestion with a Sparse Pointer Network </a></h2><p>【代码补全】本文研究的问题非常有意思，就是大家常见的IDE代码补全功能。现有的IDE对静态编程语言支持的比较好，对于动态编程语言支持的一般，而且一般都是补全某个函数或者方法之类的，而不能给出更复杂的代码。本文针对这个问题，构造了一个大型的python code数据集，并且用了比较流行的Pointer Network模型来做端到端的训练，取得了不错的效果。代码补全在实际应用中非常有用，但想做到很复杂、很智能的补全还有很长的路。不过这个topic还是一个非常有意思的东西。</p>
<h2 id="Joint-Copying-and-Restricted-Generation-for-Paraphrase"><a href="#Joint-Copying-and-Restricted-Generation-for-Paraphrase" class="headerlink" title="Joint Copying and Restricted Generation for Paraphrase "></a><a href="http://t.cn/RfHAsim" target="_blank" rel="external">Joint Copying and Restricted Generation for Paraphrase </a></h2><p>【NLG】本文的思路与Pointer Network或者Copynet类似，在用seq2seq做自然语言生成时，增加一个判断的环节，来决定接下来的这个词是从source来copy还是用decoder来rewrite。</p>
<h2 id="Context-aware-Natural-Language-Generation-with-Recurrent-Neural-Networks"><a href="#Context-aware-Natural-Language-Generation-with-Recurrent-Neural-Networks" class="headerlink" title="Context-aware Natural Language Generation with Recurrent Neural Networks "></a><a href="http://t.cn/RfEClfC" target="_blank" rel="external">Context-aware Natural Language Generation with Recurrent Neural Networks </a></h2><p>【NLG】论文的方法、模型没有太多的值得说的地方，倒是应用的点非常有意思，根据商品的上下文来伪造评论，人工评判时有50%以上的伪造评论都通过了，90%以上骗过了现有的识别算法。有点道高一尺魔高一丈的感觉，如果这篇paper的结果确实这么牛的话，确实很有意思，值得研究一下。</p>
<h2 id="MS-MARCO-A-Human-Generated-MAchine-Reading-COmprehension-Dataset"><a href="#MS-MARCO-A-Human-Generated-MAchine-Reading-COmprehension-Dataset" class="headerlink" title="MS MARCO: A Human Generated MAchine Reading COmprehension Dataset "></a><a href="http://t.cn/RfH2eXu" target="_blank" rel="external">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset </a></h2><p>【机器阅读理解】【数据福利】微软放出了一个100k规模的机器阅读理解数据集，数据来源于真实的Bing搜索query。数据包括：query、10个相关的passage和query对应的answer。</p>
<h2 id="NewsQA-A-Machine-Comprehension-Dataset"><a href="#NewsQA-A-Machine-Comprehension-Dataset" class="headerlink" title="NewsQA: A Machine Comprehension Dataset "></a><a href="http://t.cn/Rf8MPnf" target="_blank" rel="external">NewsQA: A Machine Comprehension Dataset </a></h2><p>【机器阅读理解】【数据福利】Maluuba公司放出一个新的机器阅读理解的数据集，规模在100k左右，数据来源为CNN新闻。通过用多个之前表现比较好的NN模型和人工结果对比，发现F1指标存在25.3%的差距，说明本数据集需要更好的模型来进行研究。数据集已公开，地址是：<a href="http://datasets.maluuba.com/NewsQA" target="_blank" rel="external">http://datasets.maluuba.com/NewsQA</a></p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="中国人工智能学会通讯"><a href="#中国人工智能学会通讯" class="headerlink" title="中国人工智能学会通讯"></a><a href="http://t.cn/Rf8Yvwn" target="_blank" rel="external">中国人工智能学会通讯</a></h2><p>《中国人工智能学会通讯》，本期为学会优秀博士论文专刊</p>
<h2 id="C-wrapper"><a href="#C-wrapper" class="headerlink" title="C++ wrapper"></a><a href="http://t.cn/RfEIAdZ" target="_blank" rel="external">C++ wrapper</a></h2><p>TensorFlow使用swig作为C++ wrapper，最近Google又推出了pyclif，宣称“it’s much cleaner and easier” </p>
<h2 id="智能时代的自然语言处理"><a href="#智能时代的自然语言处理" class="headerlink" title="智能时代的自然语言处理"></a><a href="http://t.cn/Rfm4hJb" target="_blank" rel="external">智能时代的自然语言处理</a></h2><p>今天ADL前沿讲习班《智能时代的自然语言处理》Zhengdong Lu的报告，题目Recent Progress on Deep Learning for NLP。</p>
<h2 id="自然语言处理中深度学习活跃领域的课程讲义"><a href="#自然语言处理中深度学习活跃领域的课程讲义" class="headerlink" title="自然语言处理中深度学习活跃领域的课程讲义"></a><a href="http://www.zishu010.com/z/newdetail/9404521.html" target="_blank" rel="external">自然语言处理中深度学习活跃领域的课程讲义</a></h2><p>本文是纽约大学助理教授 Sam Bowman 关于自然语言处理中深度学习活跃领域的课程讲义PPT。对深度学习NLP领域最近较为活跃的研究进行了综述，其中包括Attention 模型、结构化记忆、词水平以上的无监督学习等等。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读&quot;&gt;&lt;a href=&quot;#一周值得读&quot; class=&quot;headerlink&quot; title=&quot;一周值得读&quot;&gt;&lt;/a&gt;一周值得读&lt;/h1&gt;&lt;h2 id=&quot;A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-G
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第十六期</title>
    <link href="http://rsarxiv.github.io/2016/12/03/PaperWeekly-%E7%AC%AC%E5%8D%81%E5%85%AD%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/12/03/PaperWeekly-第十六期/</id>
    <published>2016-12-03T18:08:45.000Z</published>
    <updated>2016-12-03T18:36:46.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>本期PaperWeekly将带着大家来看一下ICLR 2017的六篇paper，其中包括当下非常火热的GAN在NLP中的应用，开放域聊天机器人如何生成更长更丰富的回答，如何用强化学习来构建树结构的神经网络和层次化的记忆网络等内容。六篇paper分别是：</p>
<p>1、A SELF-ATTENTIVE SENTENCE EMBEDDING<br>2、Adversarial Training Methods for Semi-Supervised Text Classification<br>3、GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS<br>4、Hierarchical Memory Networks<br>5、Mode Regularized Generative Adversarial Networks<br>6、Learning to compose words into sentences with reinforcement learning</p>
<h1 id="A-SELF-ATTENTIVE-SENTENCE-EMBEDDING"><a href="#A-SELF-ATTENTIVE-SENTENCE-EMBEDDING" class="headerlink" title="A SELF-ATTENTIVE SENTENCE EMBEDDING"></a><a href="http://openreview.net/pdf?id=BJC_jUqxe" target="_blank" rel="external">A SELF-ATTENTIVE SENTENCE EMBEDDING</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou &amp; Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>IBM Watson<br>Universit´e de Montr´eal</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>self-attention, sentence embedding, author profiling, sentiment classification, textual entailment</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文提出一种在没有额外输入的情况下如何利用attention来提高模型表现的句子表示方法。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本文提出的模型结构分为两部分，</p>
<ol>
<li>BLSTM<br>这部分采用双向LSTM对输入的文本进行处理，最后得到BLSTM的所有隐层状态H。</li>
<li>Self-attention mechanism<br>同attention机制类似，我们需要计算一个权重向量a，然后通过对隐层状态H加权求和得到句子的表示向量。这个过程如下公式所示：<br><img src="media/equation1.png" alt="equation1"><br>但是实际任务中，我们通常可能会对一个句子语义的多个方面感兴趣，因此我们可以通过下面的公式，获得多个权重向量组成的矩阵A。<br><img src="media/equation2.png" alt="equation2"><br>然后每一个权重向量a都可以得到一个句子表示向量v，所有句子表示向量组合在一起就可以获得句子表示矩阵M。<br><img src="media/equation3.png" alt="equation3"><br>本文的模型在author profiling, sentiment classification和textual entailment三个任务上进行验证，都取得了较好的效果。</li>
</ol>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>1、[Yelp]<br>(<a href="https://www.yelp.com/dataset" target="_blank" rel="external">https://www.yelp.com/dataset</a> challenge)<br>2、 [SNLI]<br>(<a href="http://nlp.stanford.edu/projects/snli/" target="_blank" rel="external">http://nlp.stanford.edu/projects/snli/</a>)</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>A large annotated<br>corpus for learning natural language inference</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文提出的self-attention方法用一个matrix表示一个句子，并且matrix中的每一个vector都是句子语义某一方面的表示，增强了sentence embedding的可解释性。</p>
<h1 id="Adversarial-Training-Methods-for-Semi-Supervised-Text-Classification"><a href="#Adversarial-Training-Methods-for-Semi-Supervised-Text-Classification" class="headerlink" title="Adversarial Training Methods for Semi-Supervised Text Classification"></a><a href="https://arxiv.org/abs/1605.07725" target="_blank" rel="external">Adversarial Training Methods for Semi-Supervised Text Classification</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Takeru Miyato, Andrew M. Dai, Ian Goodfellow</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Google Brain, Kyoto University和OpenAI</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Adversarial training, text classification, semi-supervised learning</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>Adversarial training和virtual adversarial training都需要对输入的数字形式做小的perturbation，不适用于高维稀疏输入，比如one-hot word representations。文章扩展图像领域流行的这两种方法到文本领域，对word embedding进行perturbation来作为LSTM的输入，取代原本的输入向量。可以把这两种方法看做是正则化的方法，为输入加入噪声，可以用来实现semi-supervised的任务。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>以adversarial training为例，文章对word embeddings进行adversarial perturbation，而不是直接应用在输入上。假设normalized之后的输入序列为s，给定s，y的条件概率为p(y|s;theta)，其中theta为模型参数，则s上的adversarial perturbation r_adv为：<br><img src="media/16-1-1.png" alt="16-1"></p>
<p>应用在LSTM上，如下图(b)所示。定义其adversarial loss如下：</p>
<p><img src="media/adversarial1.png" alt="adversaria"></p>
<p><img src="media/16-2.png" alt="16-2"></p>
<p>其中N为labeled的例子的数目。通过随机梯度下降来进行training。</p>
<p>文章也提供了virtual adversarial training的方法。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>1、<a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="external">IMDB</a><br>2、<a href="http://riejohnson.com/cnn_data.html" target="_blank" rel="external">Elec</a><br>3、<a href="http://snap.stanford.edu/data/web-Amazon.html" target="_blank" rel="external">Rotten Tomatoes</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>主要列三篇work：<br>1、2015年NIPS, SA-LSTM。Semi-supervised sequence learning<br>2、2015年NIPS，One-hot CNN。Semi-supervised convolutional neural networks for text categorization via region<br>embedding<br>3、2016年ICML，One-hot bi-LSTM。Supervised and semi-supervised text categorization using LSTM for region<br>embeddings</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>作者将图像领域的adversarial training应用在了文本领域，改善了word embedding。传统的word embedding被语法结构影响，即使两个完全相反的词（比如”good”和”bad”）在表示形式上也是相近的，没有表示出词本身的意思。Adversarial training使得有相近语法结构但是不同意义的词能够被分开，可以用来做情感分类和sequence model等。</p>
<h1 id="GENERATING-LONG-AND-DIVERSE-RESPONSES-WITH-NEURAL-CONVERSATION-MODELS"><a href="#GENERATING-LONG-AND-DIVERSE-RESPONSES-WITH-NEURAL-CONVERSATION-MODELS" class="headerlink" title="GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS"></a><a href="http://openreview.net/pdf?id=HJDdiT9gl" target="_blank" rel="external">GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Louis Shao, Stephan Gouws, Denny Britz, Anna Goldie, Brian Strope, Ray Kurzweil1</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Google Research, Google Brain</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Long and Diverse Responses</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>开放域聊天机器人如何生成更长且较为丰富的回答？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文模型是基于经典的seq2seq+attention框架，在其基础上进行了若干修改，得到了满意的效果。不同于之前模型的地方有两点：</p>
<p>1、encoder不仅仅包括整个source，还包括一部分target，这样attention不仅仅考虑了source，而且考虑了部分target。</p>
<p><img src="media/16-3.png" alt="16-3"></p>
<p>经典的seq2seq+attention在decoding部分会将source中的每个token都考虑到attention中来，之前有一种做法是将整个target部分也加入到attention中，效果上虽然有一定的提升，但随着数据规模地增加，内存代价太大。本文正是针对这一个问题，提出了所谓的“glimpse”模型，如上图所示，在encoder部分加入了target的前几个token，相当于是上面两种方案的一种折中。</p>
<p>2、提出了一种基于sampling的beam search decoding方案。</p>
<p>经典的beam search在decoding部分，是基于MAP（最大后验概率）进行贪婪解码的，这种方案生成的responses具有简短、无信息量以及高频的特点，通俗地讲会生成很多的类似“呵呵”的话，没有太多营养和价值。(Jiwei Li,2015)在解决这个问题时，在decoding部分通过MMI（互信息）对N-best结果进行重排序，这种方法对于生成短文本效果显著，但对于生成长文本效果不佳。因为，基于MAP的beam search天然存在这样的问题，N-best和重排序都解决不了根本性的问题。针对这一问题，本文提出了一种基于sampling的beam search解码方案，sampling即在每一步解码时都sample出D个token作为候选，搜索完毕或达到预设的长度之后，生成B个候选responses，然后进行重排序。</p>
<p>本文的另外一大亮点是用了大量的对话数据，用了很大规模参数的模型进行了实验。实验评价标准，在自动评价这部分，设计了一个N选1的实验，给定一个输入，将正确输出和错误输出混在一起，模型需要从中选择正确的输出，用选择准确率来作为自动评价指标。本文没有用到经典的BLEU指标，因为这个指标确实不适合评价对话的生成质量。为了更有说服力，本文用人工对结果进行评价。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>本文用到的对话数据：<br>1、<a href="https://redd.it/3bxlg7" target="_blank" rel="external">Reddit Data</a><br>2、<a href="http://opus.lingfil.uu.se/OpenSubtitles.php" target="_blank" rel="external">2009 Open Subtitles data</a><br>3、<a href="https://data.stackexchange.com/" target="_blank" rel="external">Stack Exchange data</a><br>4、本文作者从Web抽取的对话数据（待公开）</p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>用seq2seq方法研究生成对话的质量（包括长度、多样性）的工作并不多，具有代表性的有下面两个工作：<br>1、Wu,2016 提出了用length-normalization的方案来生成更长的对话<br>2、Jiwei Li,2015 提出了在解码阶段用MMI（互信息）对N-best结果进行重排序，旨在获得信息量更大的对话。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文模型部分并没有太多的创新，因为是工业部门的paper，所以更多的是考虑实用性，即能否在大规模数据集上应用该模型，集中体现在glimpse模型上。为了生成更加长、更加多样性的对话，在原有beam search + 重排序的基础上，引入了sampling机制，给生成过程增加了更多的可能性，也是工程上的trick。对话效果的评价是一件很难的事情，人类希望bot可以生成类人的对话，回复的长度可以定量描述，但多样性、生动性、拟人化等等都难以定量描述，所以在探索生成对话的这个方向上还有很长的路要走。</p>
<h1 id="Hierarchical-Memory-Networks"><a href="#Hierarchical-Memory-Networks" class="headerlink" title="Hierarchical Memory Networks"></a><a href="https://arxiv.org/pdf/1605.07427v1.pdf" target="_blank" rel="external">Hierarchical Memory Networks</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Sarath Chandar, Sungjin Ahn, Hugo Larochelle, Pascal Vincent, Gerald Tesauro, Yoshua Bengio</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>1、Université de Montréal, Canada.<br>2、Twitter Cortex, USA.<br>3、IBM Watson Research Center, USA.<br>4、CIFAR, Canada.  </p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Hierarchical Memory Networks，Maximum Inner Product Search (MIPS)</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>记忆网络主要包括hard attention和soft attenion两种，然而hard不能用于反向传播算法进行端到端训练，所以只能使用强化学习的方法进行训练；soft所涉及的计算参数又很大，只适合于少量Memory。本文提出Hierarchical Memory Networks(HMN)模型，算是soft和hard的一个混合模型，计算量减少且训练更加容易，<br>实验结果也很好。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>soft attention是对所有的memory都要进行attention的计算，对全集计算使计算量很大。HMN利用层次化结构使得attention的集合缩小，利用MaximumInner Product Search(MIPS)的方法从全集中获得一个最优子集，在子集上面去做attention就大大降低计算量。这样的方式又和hard attention预测关注点的方法有些类似，将注意力放在最相关的那部分，这个的做法也更接近于人的注意力思维。  文章的核心部分在于如何获取与query最相近的子集。</p>
<p>主实验主要包括两个:<br>1、Exact K-MIPS：计算复杂度依然和soft attention差不多。<br>2、Approximate K-MIPS：利用Maximum Cosine Similarity Search(MCSS)的方法代替MIPS的方法，牺牲一些精确度，降低复杂度和加快训练速度。  </p>
<p>MIPS有三种方法，分别是基于hash,基于tree,基于clustering，基于上述三种方法文中又做了几组组对比实验，最后实验结果显示基于clustering的效果是最好的。</p>
<p>文章得到的实验结果如下：<br><img src="media/HMN_Result.png" alt="HMN_Result"></p>
<h2 id="资源-（可选）"><a href="#资源-（可选）" class="headerlink" title="资源 （可选）"></a>资源 （可选）</h2><p>1、<a href="https://www.dropbox.com/s/tohrsllcfy7rch4/SimpleQuestions_v2.tgz" target="_blank" rel="external">The SimpleQuestions dataset</a>(使用的是Large-scale simple question answering with memory networks文章中的数据集)<br>2、<a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">babi</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、arXiv 2014, soft attention,《Neural turing machines》<br>2、CoRR 2015, hard attention,《Reinforcement learning neural turing machine》<br>3、ICLR 2015, memory network,《Memory networks》<br>4、arXiv 2015,《End-to-end memory networks》,引入半监督记忆网络可以自学所需要的facts。<br>5、CoRR 2016, DMN, 《Dynamic memory networks for visual and textual question<br>answering》,增加了一个episodic memory 使得可以动态更新memory里面的内容。</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>文章的创新主要在于修改了两个模块：Memory和Reader。<br>1、将memory的结构从a flat of array变成了hierarchical memory structure。将memory分成若干groups,这些groups又可以在进行更高级别的组合。<br>2、reader是从MIPS选出的子集中使用soft attention。MIPS从memory中选出一<br>个group子集作为最相关的子集。</p>
<h1 id="Mode-Regularized-Generative-Adversarial-Networks"><a href="#Mode-Regularized-Generative-Adversarial-Networks" class="headerlink" title="Mode Regularized Generative Adversarial Networks "></a><a href="http://openreview.net/pdf?id=HJKkY35le" target="_blank" rel="external">Mode Regularized Generative Adversarial Networks </a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p>Tong Che; Yanran Li</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>Montreal Institute for Learning Algorithms;<br>Department of Computing, The Hong Kong Polytechnic University</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>GAN, Regularizers</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>本文针对的问题是：1、GAN 的训练过程很不稳定 2、GAN 生成的样本局限于训练样本中的大 model 上，不能平衡数据的分布（missing model problem）。<br>两个问题互相影响，导致训练结果不好。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>针对上面的问题，作者提出了两种 regularizers 去控制 GAN 的训练过程。<br>第一个 regularizer 也被作者称为 Regularized-GAN。作者认为可以从 generator 入手，给 generator 增加 regularizer，使得其具有更好的 gradient ，这样 G 和 D 都能稳定训练。<br>具体的方法是增加一个 encoder E(x) : X → Z.即把原先的 noise vector z 改为 z = encoder(X) ，即然后再 G(encoder(X))。如下图：<br><img src="media/16-5.png" alt="16-5"></p>
<p>这样做有两个好处。第一，原始的模型很容易出现梯度消失的情况，因为 discriminator D 特别容易区分真实数据和生成数据导致 generator 就得不到 D 的梯度。作者的模型多了一个 reconstruction 的部分，这样生成出来数据不再那样容易被 D 识别出来。所以 D 和 G 就都能一直有 gradient 去训练，从而提高稳定性。第二，对于 x ，G(E(x)) 会尽量去生成 x 原本所属的类，从而一定程度解决了 missing model problem。<br>第二个 regularizer 基于第一个 regularizer 旨在改进训练的方法，也被作者称为 manifold-diffusion GAN。分为两步，第一步 manifold step 训练 discriminator D1 ，目的是减少 G(Enc(X)) 和 X 的的差别；第二步 diffusion 就是训练 D2 让 G(Enc(X)) 和 G(z) 分布的距离接近。如下图：</p>
<p><img src="media/16-6.png" alt="16-6"></p>
<p>最后，作者把 GAN 的网络训练坍塌的情况考虑进去，提出了新的 evaluation metric。</p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>本篇文章的作者李嫣然写过一篇非常棒的<a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650325352&amp;idx=1&amp;sn=90fb15cee44fa7175a804418259d352e&amp;mpshare=1&amp;scene=1&amp;srcid=0829ixEhnGChNKAl5kgz6b9V#rd" target="_blank" rel="external">综述</a> ,在这里就不累赘阐述了。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>当下 GAN 的研究非常火爆，出现了许许多多对 GAN 的改进，本篇文章的提出的两种 regularizers 非常有效的提高了 GAN 的稳定性（其中 regularizer 的思想也受到了监督学习的启发），值得对 GAN 感兴趣的同学研读。</p>
<h2 id="完成人信息"><a href="#完成人信息" class="headerlink" title="完成人信息"></a>完成人信息</h2><p>professorshui@gmail.com</p>
<h1 id="Learning-to-compose-words-into-sentences-with-reinforcement-learning"><a href="#Learning-to-compose-words-into-sentences-with-reinforcement-learning" class="headerlink" title="Learning to compose words into sentences with reinforcement learning"></a><a href="https://openreview.net/forum?id=Skvgqgqxe" target="_blank" rel="external">Learning to compose words into sentences with reinforcement learning</a></h1><h2 id="作者-5"><a href="#作者-5" class="headerlink" title="作者"></a>作者</h2><p>Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling</p>
<h2 id="单位-5"><a href="#单位-5" class="headerlink" title="单位"></a>单位</h2><p>Google</p>
<h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Tree-LSTM, Reinforcement Learning</p>
<h2 id="文章来源-5"><a href="#文章来源-5" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2017</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>使用强化学习来构建树结构的神经网络Tree-LSTM，学习自然语言的句子表示</p>
<h2 id="模型-5"><a href="#模型-5" class="headerlink" title="模型"></a>模型</h2><p>模型分为两部分：Tree-LSTM和强化学习模型<br>应用Tree-LSTM(可以通过LSTM的忘记门机制，跳过整棵对结果影响不大的子树)，并结合{SHIFT，REDUCE}操作，SHIFT操作对应将一个节点压入栈，REDUCE对应将两个元素组合，从而建立树结构</p>
<p>强化学习用来寻找最佳的节点组合情况，RL模型中的状态s即当前构建的树结构，a为{SHIFT，REDUCE}操作，reward对应不同downstream<br> task(例：若是用该句子表示进行分类任务，则r对应从策略网络中采样得到句子表示的分类准确性的概率)</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>作者将该工作进行了四组实验，情感分类，语义相关性判断，自然语言推理，句子生成<br>分别应用Stanford Sentiment Treebank，Sentences Involving Compositional Knowledge corpus，Stanford Natural Language Inference corpus，IMDB movie review corpus</p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>与Socher等人之前提出的Recursive NN,MV-RNN,RNTN，Tree-LSTM等工作一脉相承，本文又加入了RL方式构建树形结构</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>将强化学习引入句子表示学习之中，学习构建树的不同方式，从左向右，从右向左，双向，有监督、半监督、预先无结构等方式去构建树结构，但是训练时间较长，在几个任务上效果提升不是特别明显。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>GAN是当下的研究热点之一，在图像领域中研究较多，本期的两篇paper探讨了GAN在NLP中的应用，值得关注和期待。最后感谢@destinwang、@gcyydxf、@chunhualiu、@tonya、@suhui和@zhangjun六位童鞋的辛勤工作。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;本期PaperWeekly将带着大家来看一下ICLR 2017的六篇paper，其中包括当下非常火热的GAN在NLP中的应用，开放域聊天机器
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>中文分词工具测评</title>
    <link href="http://rsarxiv.github.io/2016/11/29/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E6%B5%8B%E8%AF%84/"/>
    <id>http://rsarxiv.github.io/2016/11/29/中文分词工具测评/</id>
    <published>2016-11-29T17:49:50.000Z</published>
    <updated>2016-11-29T19:07:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>分词对于研究和应用中文自然语言处理的童鞋来说，都是一个非常非常基础的部件，分词的质量直接影响到后续词性标注、命名实体识别、句法分析等部件的准确性。作为一个基础部件，学术界对分词的研究已经非常久了，市面上流行的几大开源分词工具也被工业界的各大公司应用很多年了。最近，中文分词随着一篇博文的发表被推到了风口浪尖，引发众多大牛在微博、微信群里的激烈讨论。本文并不想对这篇博文进行过多评论，只是想用公开的数据集对各大分词工具进行一个客观地测评，以供大家在选择工具时有所依据。</p>
<h1 id="中文分词工具"><a href="#中文分词工具" class="headerlink" title="中文分词工具"></a>中文分词工具</h1><p>本文选择了4个常见的分词工具，分别是：哈工大LTP、中科院计算所NLPIR、清华大学THULAC和jieba，为了对比分词速度，选择了这四个工具的c++版本进行评测。</p>
<p>1、LTP <a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="external">https://github.com/HIT-SCIR/ltp</a><br>2、NLPIR <a href="https://github.com/NLPIR-team/NLPIR" target="_blank" rel="external">https://github.com/NLPIR-team/NLPIR</a><br>3、THULAC <a href="https://github.com/thunlp/THULAC" target="_blank" rel="external">https://github.com/thunlp/THULAC</a><br>4、jieba <a href="https://github.com/yanyiwu/cppjieba" target="_blank" rel="external">https://github.com/yanyiwu/cppjieba</a></p>
<h1 id="测试数据集"><a href="#测试数据集" class="headerlink" title="测试数据集"></a>测试数据集</h1><p>1、SIGHAN Bakeoff 2005 MSR, 560KB  <a href="http://sighan.cs.uchicago.edu/bakeoff2005/" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/</a><br>2、SIGHAN Bakeoff 2005 PKU, 510KB  <a href="http://sighan.cs.uchicago.edu/bakeoff2005/" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/</a><br>3、人民日报 2014, 65MB  <a href="https://pan.baidu.com/s/1hq3KKXe" target="_blank" rel="external">https://pan.baidu.com/s/1hq3KKXe</a></p>
<p>前两个数据集是SIGHAN于2005年组织的中文分词比赛所用的数据集，也是学术界测试分词工具的标准数据集，本文用于测试各大分词工具的准确性，而最后一个数据集规模较大，用于测试分词速度。</p>
<h1 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h1><p>用SIGHAN Bakeoff 2005比赛中所自带的score脚本、test gold数据和training words数据对4个工具进行准确性测试，具体使用方法可参考：<a href="http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip</a> 中的readme文件。</p>
<h1 id="测试硬件"><a href="#测试硬件" class="headerlink" title="测试硬件"></a>测试硬件</h1><p>Intel Core i7-6700 CPU@3.40GHz*8</p>
<h1 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h1><p>1、MSR测试结果<br><img src="media/1.png" alt="1"></p>
<p>2、PKU测试结果<br><img src="media/2.png" alt="2"></p>
<p>3、人民日报测试结果<br><img src="media/3.png" alt="3"></p>
<h1 id="测试结论"><a href="#测试结论" class="headerlink" title="测试结论"></a>测试结论</h1><p>1、一个好的分词工具不应该只能在一个数据集上得到不错的指标，而应该在各个数据集都有很不错的表现。从这一点来看，thulac和ltp都表现非常不错。</p>
<p>2、因为分词是个基础部件，分词速度对于一个分词工具来说也至关重要。从这一点来看，thulac和jieba表现的不错。</p>
<p>3、大家都知道，基本的分词依赖模型，但真正想用分词工具来解决应用层面上的问题，都需要借助于词库，本文测试的4个工具均支持用户自定义词库。</p>
<p>4、特别需要强调的一点是，哈工大的ltp支持分词模型的在线训练，即在系统自带模型的基础上可以不断地增加训练数据，来得到更加丰富、更加个性化的分词模型。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>争论是一个好的事情，尤其是不同背景的人站在不同的角度对同一个事情进行争论，常常会碰撞出知识的火花，对于这个领域的发展有更好地推动作用。希望类似的争论可以多一些，让刚刚入门的或者准备入门的童鞋可以更加客观地看到一个领域的发展现状，而不是盲目地被一些热门的词蒙蔽双眼，失去判断。对于分词来说，最近几年大热的深度学习模型，并不会比之前传统的crf模型有多大性能上的突破，所以大家应该理性地看待深度学习以及人工智能，捧得越高可能摔得越惨。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>1、Zhongguo Li, Maosong Sun. Punctuation as Implicit Annotations for Chinese Word Segmentation. Computational Linguistics, vol. 35, no. 4, pp. 505-512, 2009.<br>2、Meishan Zhang, Yue Zhang, Guohong Fu. Transition-Based Neural Word Segmentation<br><a href="http://www.aclweb.org/anthology/P/P16/P16-1040.pdf" target="_blank" rel="external">http://www.aclweb.org/anthology/P/P16/P16-1040.pdf</a><br>3、Meishan Zhang, Zhilong Deng，Wanxiang Che, and Ting Liu. Combining Statistical Model and Dictionary for Domain Adaption of Chinese Word Segmentation. Journal of Chinese Information Processing. 2012, 26 (2) : 8-12 (in Chinese)<br>4、Wanxiang Che, Zhenghua Li, and Ting Liu. LTP: A Chinese Language Technology Platform. In Proceedings of the Coling 2010:Demonstrations. 2010.08, pp13-16, Beijing, China.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;分词对于研究和应用中文自然语言处理的童鞋来说，都是一个非常非常基础的部件，分词的质量直接影响到后续词性标注、命名实体识别、句法分析等部件的准
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>本周值得读(2016.11.21-2016.11.25)</title>
    <link href="http://rsarxiv.github.io/2016/11/26/%E6%9C%AC%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB-2016-11-21-2016-11-25/"/>
    <id>http://rsarxiv.github.io/2016/11/26/本周值得读-2016-11-21-2016-11-25/</id>
    <published>2016-11-27T06:12:34.000Z</published>
    <updated>2016-11-27T06:31:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review"><a href="#Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review" class="headerlink" title="Generative Deep Neural Networks for Dialogue: A Short Review"></a><a href="http://t.cn/RfX2bms" target="_blank" rel="external">Generative Deep Neural Networks for Dialogue: A Short Review</a></h2><p>【对话系统】本文对seq2seq方法在对话系统中的应用做了一个简短的对比和综述，主要是针对几位作者提出的三种深度学习模型：HRED、VHRED和MrRNN，实验数据用了Ubuntu Dialogue Corpus和Twitter Corpus。不管是用seq2seq生成也好，还是套用模板也罢，对话系统的难点仍是上下文的理解和如何输出一些高质量的对话，有些应用场景对response的要求没那么高，只要可以达到一定实际效果即可，而有的则需要生成更加接近人类的对话。本文适合研究深度seq2seq的童鞋以及想看看各种seq2seq效果如何的童鞋来读。本文总结的三个模型原文链接：</p>
<p>(a) MrRNN: <a href="https://arxiv.org/pdf/1606.00776.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1606.00776.pdf</a><br>(b) VHRED: <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1605.06069v3.pdf</a><br>(c) HRED: <a href="https://arxiv.org/pdf/1507.04808v3.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1507.04808v3.pdf</a></p>
<h2 id="Coherent-Dialogue-with-Attention-based-Language-Models"><a href="#Coherent-Dialogue-with-Attention-based-Language-Models" class="headerlink" title="Coherent Dialogue with Attention-based Language Models"></a><a href="http://t.cn/Rfag1Jx" target="_blank" rel="external">Coherent Dialogue with Attention-based Language Models</a></h2><p>【对话系统】考虑并理解上下文是Chatbot的一大难点，也是目前绝大多数chatbot不智能的主要原因之一。本文提出了一种动态的attention模型，在理解用户请求的时候，动态地考虑历史信息。本文用到了两个开放数据集，分别是MovieTriples和Ubuntu Troubleshoot dataset。建议对chatbot感兴趣的同学可以精读此文。</p>
<h2 id="Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks"><a href="#Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks" class="headerlink" title="Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks"></a><a href="http://t.cn/RfXLHIP" target="_blank" rel="external">Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks</a></h2><p>【课程学习】Curriculum Learning是一类模拟小孩子学习过程的学习算法，简单地说是指在训练模型是从简单的样本开始，逐渐增加学习样本的难度。本文以情感分析为研究对象，对Curriculum Learning如何提升LSTM模型在情感分析任务上的效果进行了实验研究，并给出了可视化的结果。本文适合研究Curriculum Learning的童鞋以及在训练模型中想尝试下Curriculum Learning思路的童鞋研读。</p>
<h2 id="Variable-Computation-in-Recurrent-Neural-Networks"><a href="#Variable-Computation-in-Recurrent-Neural-Networks" class="headerlink" title="Variable Computation in Recurrent Neural Networks"></a><a href="http://t.cn/RfXUmyN" target="_blank" rel="external">Variable Computation in Recurrent Neural Networks</a></h2><p>【RNN研究】RNN在解决序列建模问题有着天然的优势，但有些序列数据存在周期性的变化，或者短时间内变化并不明显，比如视频数据，因此固定不变的RNN训练方案会浪费计算资源，本文针对这一问题，提出了一种RNN变计算训练方案，即在计算下一个time step的hidden state时，不需要上一个time step所有的维度，只取一部分来计算，其他的维度复制过来即可。这篇工作的相关的前人研究包括：2014年的A Clockwork RNN，链接如下：<a href="https://arxiv.org/pdf/1402.3511.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1402.3511.pdf</a></p>
<h2 id="Learning-to-Distill-The-Essence-Vector-Modeling-Framework"><a href="#Learning-to-Distill-The-Essence-Vector-Modeling-Framework" class="headerlink" title="Learning to Distill: The Essence Vector Modeling Framework"></a><a href="http://t.cn/RfoWk0K" target="_blank" rel="external">Learning to Distill: The Essence Vector Modeling Framework</a></h2><p>【表示学习】本文研究的内容包括两个点，一个是无监督学习，一个是文档表示。词表示、句子表示都有比较多的解决方案，但实际应用中文档级别的表示非常重要，比如情感分析、文本摘要等任务。本文提出了一种无监督的方法对文档以及背后所蕴藏的背景知识进行低维表示。自然语言随着元素级别地提升（从字、词、短语、句子到文档），研究的难度随之增加，实用程度随之减少。建议想从无监督学习方法有所突破以及想试试文档表示的童鞋可以来读本文。</p>
<h2 id="Unsupervised-Learning-of-Sentence-Representations-using-Convolutional-Neural-Networks"><a href="#Unsupervised-Learning-of-Sentence-Representations-using-Convolutional-Neural-Networks" class="headerlink" title="Unsupervised Learning of Sentence Representations using Convolutional Neural Networks"></a><a href="http://t.cn/Rf9VNdk" target="_blank" rel="external">Unsupervised Learning of Sentence Representations using Convolutional Neural Networks</a></h2><p>【句子表示】本文的贡献在于提出了一种新的CNN-LSTM auto-encoder，作为一种无监督的句子学习模型。</p>
<h2 id="Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers"><a href="#Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers" class="headerlink" title="Emergent Logical Structure in Vector Representations of Neural Readers"></a><a href="http://t.cn/Rf9Vwi7" target="_blank" rel="external">Emergent Logical Structure in Vector Representations of Neural Readers</a></h2><p>【问答系统】针对最近提出的各种各样的attention based reader models,本文作者做了一个比较全面的总结和分析，并且通过数学分析和实验展示了模型之间的相关性。PaperWeekly第十四期的文章有相关的paper note可以参考<a href="http://rsarxiv.github.io/2016/11/19/PaperWeekly-%E7%AC%AC%E5%8D%81%E5%9B%9B%E6%9C%9F/">地址</a></p>
<h1 id="公益广告"><a href="#公益广告" class="headerlink" title="公益广告"></a>公益广告</h1><p>美国国立卫生研究院招博士后，研究领域包括：NLP、text mining和machine learning，感兴趣的童鞋可以看过来，详情请戳<a href="https://www.stat.washington.edu/jobs/archive/2013/may/05.20.13_NIH_E_B_NLP_Post_Doc_Ad_PDF_May_20_2013.pdf" target="_blank" rel="external">这里</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读&quot;&gt;&lt;a href=&quot;#一周值得读&quot; class=&quot;headerlink&quot; title=&quot;一周值得读&quot;&gt;&lt;/a&gt;一周值得读&lt;/h1&gt;&lt;h2 id=&quot;Generative-Deep-Neural-Networks-for-Dialogue-A-Short-
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第十五期</title>
    <link href="http://rsarxiv.github.io/2016/11/26/PaperWeekly-%E7%AC%AC%E5%8D%81%E4%BA%94%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/11/26/PaperWeekly-第十五期/</id>
    <published>2016-11-26T18:37:08.000Z</published>
    <updated>2016-11-26T18:37:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>NMT是热门研究领域之一，尤其是Google和百度都推出了自己的NMT翻译系统，在工业界、学术界和翻译界都引起了轩然大波，一时间对NMT技术的研究和讨论达到了顶峰。Attention模型在NLP中最早的使用正是在NMT领域出现的，包括横扫很多领域的seq2seq+attention解决方案，都是在NMT模型的基础上进行相应的一些小改动而成的。所以，本期PaperWeekly带大家看一看最近两年Attention模型在NMT领域中的研究进展，本文包括以下paper：</p>
<p>1、Neural Machine Translation by Jointly Learning to Align and Translate, 2015<br>2、Effective approaches to attention-based neural machine translation, 2015<br>3、Modeling Coverage for Neural Machine Translation,  2016<br>4、Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation, 2016<br>5、Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation, 2016</p>
<h1 id="Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate"><a href="#Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate" class="headerlink" title="Neural Machine Translation by Jointly Learning to Align and Translate"></a><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural Machine Translation by Jointly Learning to Align and Translate</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Dzmitry Bahdanau, KyungHyun Cho and Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Jacobs University Bremen, Germany<br><br>Universite ́ de Montre ́al</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>NMT, attention</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2015</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>这篇论文首次提出在NMT中使用attention的机制，可以使模型自动确定源句子中和目标词语最相关的部分，相比于基本的encoder-decoder方法提高了翻译效果。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>该论文使用的基本模型是一个双向RNN的encoder-decoder的结构。在这篇论文之前，encoder部分都是直接把输入句子encode成一个固定长度的上下文向量c，然后decoder再根据该向量来产生翻译。但是由于句子长度不定，这种做法对长句子的效果不理想。<br><img src="media/model.png" alt="mode"></p>
<p>上图是这篇论文提出的模型结构，作者首次提出了在decoder中加入一种attention的机制。直观上理解，就是decoder可以决定更多地注意原句子中的某些部分，从而不必把原句子中的所有信息都encode成一个固定的向量。具体来讲，上下文向量ci由下式计算得出：<br><img src="media/ci.png" alt="ci"></p>
<p>其中，<br><img src="media/aij.png" alt="aij"></p>
<p>其中，<br><img src="media/eij.png" alt="eij"></p>
<p>上式中的a便是alignment model，可以用来估计位置j附近的输入和位置i的输出之间的匹配程度。本论文中的alignment model是一个前馈神经网络，它和模型中的其它部分一起进行训练。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>1、英法翻译数据集 <a href="http://www.statmt.org/wmt14/translation-task.html" target="_blank" rel="external">ACL WMT ’14</a></p>
<p>2、一个基本的RNN encoder-decoder模型的实现 <a href="https://github.com/lisa-groundhog/GroundHog." target="_blank" rel="external">GroundHog</a></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、2013年，一个类似的aligning的方法被提出用于手写体生成。论文：Graves(2013) Generating sequences with recurrent neural networks<br>2、2014年，seq2seq的神经网络模型用于机器翻译。论文：Sutskever(2014) Sequence to sequence learning with neural networks</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本论文创新性地在NMT中提出了attention的机制，可以使模型在每一步注意到源句子中不同的部分，从而提高了NMT的效果，该效果的提升对于长句子的翻译尤其明显。</p>
<h1 id="Effective-approaches-to-attention-based-neural-machine-translation"><a href="#Effective-approaches-to-attention-based-neural-machine-translation" class="headerlink" title="Effective approaches to attention-based neural machine translation"></a><a href="https://arxiv.org/abs/1508.04025" target="_blank" rel="external">Effective approaches to attention-based neural machine translation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Minh-Thang Luong, Hieu Pham, Christopher D. Manning</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Computer Science Department, Stanford University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>NMT;Global Attention;Local Attention</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>EMNLP 2015</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>Attention机制引入极大提升了NMT的翻译质量，但对于Attention实现架构的讨论还很少，尤其是全局Attention的计算效率问题。本文就是讨论各种优化策略，包括Global Attention, Local Attention，Input-feeding方法等。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>Global Attenion，生成上下文向量c_t时，考虑原文编码过程中的所有隐状态。<br>  <img src="media/1GlobalAttention.png" alt="1GlobalAttention"></p>
<p>Local Attention，对于每个正在生成的译词，预测一个原文对齐的位置，只考虑该位置前后一个窗口范围内的原文编码隐状态。  </p>
<p><img src="media/2LocalAttention.png" alt="2LocalAttention"></p>
<p>Input-feeding，用一个额外的向量，来记住哪些词是已经翻译过的，即考虑了coverage的问题。  </p>
<p><img src="media/3Input-Feeding.png" alt="3Input-Feeding"></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>1、训练数据：WMT14 (4.5M句对，116M 英文词，110M德文词)<br>2、开发集：newstest2013 (3000句)<br>3、测试集：newstest2014(2737句)和newstest2015(2169句)<br>4、代码和模型共享在：<a href="http://nlp.stanford.edu/projects/nmt/" target="_blank" rel="external">http://nlp.stanford.edu/projects/nmt/</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>主要是follow了(Bahdanau et al., 2015; Jean et al., 2015)的工作，对Attention的机制进行了探讨和改进。  </p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>English-German的实验结果，较不用attention的方法提升了5个多点BLEU，充分证明了attention的有效性。<br>实验结果的表格详细列出了各种改进方法带来的收益，跟进者不妨仔细看看（以及第5节的分析），可以很快了解各种折腾的方向。</p>
<p><img src="media/4ExperimentResult.png" alt="4ExperimentResult"></p>
<h2 id="完成人信息"><a href="#完成人信息" class="headerlink" title="完成人信息"></a>完成人信息</h2><p>微博 @MyGod9，语智云帆创始人，机器翻译老兵，NMT追随者，weiyongpeng@lingosail.com </p>
<h1 id="Modeling-Coverage-for-Neural-Machine-Translation"><a href="#Modeling-Coverage-for-Neural-Machine-Translation" class="headerlink" title="Modeling Coverage for Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1601.04811v6.pdf" target="_blank" rel="external">Modeling Coverage for Neural Machine Translation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, Hang Li</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>诺亚方舟实验室，清华大学</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NMT</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>解决经典神经机器翻译模型中存在的over-translation（过度翻译）和under-translation(翻译不足）的问题。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>在传统NMT模型中，加入统计机器翻译策略中的coverage方法，来追踪、判断原始句子是否被翻译，如下图、公式所示。<br><img src="media/pic1.png" alt="pi"><br><img src="media/pic2.png" alt="pi"><br><img src="media/pic3.png" alt="pi"><br>其中，C为新引入的coverage向量。</p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>前序文章：Neural Machine Translation by Jointly Learning to Align and Translate</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>该文是基于Neural Machine Translation by Jointly Learning to Align and Translate之上的工作，引入了统计机器翻译中的Coverage方法来尝试避免NMT中的一些问题。根据文章的试验结果，这种方法能够提升翻译效果。由于写作此文时笔者未作实验，因此实际效果有待进一步衡量。</p>
<h1 id="Agreement-based-Joint-Training-for-Bidirectional-Attention-based-Neural-Machine-Translation"><a href="#Agreement-based-Joint-Training-for-Bidirectional-Attention-based-Neural-Machine-Translation" class="headerlink" title="Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation"></a><a href="https://arxiv.org/abs/1512.04650" target="_blank" rel="external">Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Yong Cheng, Shiqi Shen, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Tsinghua University</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Bidirectional NMT; Attention</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>IJCAI 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>由于自然语言错综复杂的结构，单向的注意力模型只能引入注意力机制的部分regulization。文章提出了联合训练双向的注意力模型，尽可能使注意力在两个方向上保持一致。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>模型的中心思想就是对于相同的training data，使source-to-target和target-to-source两个模型在alignment matrices上保持一致。这样能够去掉一些注意力噪声，使注意力更加集中、准确。更确切地说，作者引入了一个新的目标函数：</p>
<p><img src="media/1.png" alt="1"></p>
<p>其中<br><img src="media/2.png" alt="2">表示source-to-target基于注意力的翻译模型，而<img src="media/3.png" alt="3">表示target-to-source的模型。<img src="media/4.png" alt="4">表示对于句子s source-to-target的alignment matrix，而<img src="media/5.png" alt="5">表示target-to-source的。<img src="media/6.png" alt="6">是损失函数，可以衡量两个alignment matrix之间的disagree程度。</p>
<p>对于<img src="media/6.png" alt="6">,有几种不同的定义方法：<br>1、Square of addition(SOA)<br><img src="media/7.png" alt="7"></p>
<p>2、Square of subtraction(SOS)<br><img src="media/9.png" alt="9"></p>
<p>3、Multiplication(MUL)<br><img src="media/10.png" alt="10"></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p>作者文中说的是bidirectional translation的alignment matrices要一致；还有另外一篇文章“Agreement on Target-bidirectional Neural Machine Translation”是说decoding的时候可以正向或者反向产生目标句子，把这二者进行联合训练。另外，最近也有很多关于bidirectional training或者类似思想的文章，比如“Dual Learning for Machine Translation. Computation and Language”将reinforcement的概念引入了bidirectional training当中，“Neural Machine Translation with Reconstruction” 希望能从target hidden state恢复出source sentence</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>这篇文章胜在idea,很巧妙地想到了让正反向的注意力一致来改进attention。</p>
<h1 id="Improving-Attention-Modeling-with-Implicit-Distortion-and-Fertility-for-Machine-Translation"><a href="#Improving-Attention-Modeling-with-Implicit-Distortion-and-Fertility-for-Machine-Translation" class="headerlink" title="Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation"></a><a href="https://arxiv.org/abs/1601.03317" target="_blank" rel="external">Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p>Shi Feng, Shujie Liu, Nan Yang, Mu Li, Ming Zhou, Kenny Q.Zhu</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>Shanghai Jiao Tong University, Microsoft Research</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>NMT, Attention, Fertility, Distortion</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>COLING 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>使用attention机制解决NMT中调序和繁衍率的问题。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>模型非常简单，即在attention机制中将前一时刻的context vector c作为输入传入当前时刻attention中（命名为RecAtt）。如图：</p>
<p><img src="media/coling.jpg" alt="coling"></p>
<p>通过这样的RecAtt机制，attention部分的网络相当于记忆了之前时刻的context。</p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>ACL 2016李航老师组的工作 Modeling Coverage for Neural Machine Translation利用了attention机制来解决了NMT中“欠翻译”和“过翻译”的问题。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>该文章的创新之处在于提出将attention计算得到的context vector c作为attention的输入，这样就是的attention机制带有一种recurrent的意味。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本期PaperWeekly精选了5篇Attention模型在NMT任务上的研究工作，Attention模型的发展不仅仅推动着NMT的进步，同时也可以借鉴于其他的任务中，比如QA，比如chatbot。感谢@MyGod9 @雨神 @susie-nmt @李争 @magic282 五位童鞋的辛勤付出。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;NMT是热门研究领域之一，尤其是Google和百度都推出了自己的NMT翻译系统，在工业界、学术界和翻译界都引起了轩然大波，一时间对NMT技术
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
</feed>
