<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>PaperWeekly</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://rsarxiv.github.io/"/>
  <updated>2016-10-21T06:36:53.000Z</updated>
  <id>http://rsarxiv.github.io/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PaperWeekly 第十期</title>
    <link href="http://rsarxiv.github.io/2016/10/20/PaperWeekly-%E7%AC%AC%E5%8D%81%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/10/20/PaperWeekly-第十期/</id>
    <published>2016-10-21T06:30:26.000Z</published>
    <updated>2016-10-21T06:36:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引"><a href="#引" class="headerlink" title="引"></a>引</h2><p>本期PaperWeekly的主题是基于翻译模型(Trans系列)的知识表示学习，主要用来解决知识表示和推理的问题。表示学习旨在将研究对象的语义信息表示为稠密低维实值向量，知识表示学习主要是面向知识图谱中的实体和关系进行表示学习。使用建模方法将实体和向量表示在低维稠密向量空间中，然后进行计算和推理。一般而言的应用任务为triplet classification 和link prediction.自从2013年TransE模型提出后，产生了一系列模型对TransE模型进行改进和补充,比如TransH、TransG等等。本期PaperWeekly主要提供了Trans系列的7篇文章供大家赏读。</p>
<p>paper目录：<br>（1）TransE，NIPS2013，Translating embeddings for modeling multi-relational data。<br>（2）TransH，AAAI2014，Knowledge graph embedding by translating on hyperplanes。<br>（3）TransD，ACL2015，Knowledge graph embedding via dynamic mapping matrix。<br>（4）TransA，arXiv2015，An adaptive approach for knowledge graph embedding。<br>（5）TransG，arxiv2015，A Generative Mixture Model for Knowledge Graph Embedding)<br>（6）KG2E，CIKM2015，Learning to represent knowledge graphs with gaussian embedding。<br>（7）TranSparse，AAAI2016，Knowledge graph completion with adaptive sparse transfer matrix。 </p>
<h1 id="TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data"><a href="#TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data" class="headerlink" title="TransE:Translating Embeddings for Modeling Multi-relational Data"></a><a href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" target="_blank" rel="external">TransE:Translating Embeddings for Modeling Multi-relational Data</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>CNRS, Google inc.</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Embedding entities and relationships, Multi-relational data, link prediction</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>NIPS 2013/12</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何建立简单且易拓展的模型把知识库中的实体和关系映射到低维向量空间中，从而计算出隐含的关系？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>传统训练知识库中三元组(head,relation,tail)建模的方法参数特别多，导致模型太复杂难以解释，并且需要很大的计算代价，很容易出现过拟合或欠拟合问题。而简单的模型在表现上与复杂的模型几乎一样，但更易拓展。TransE的训练过程如下图：</p>
<p><img src="media/TransE_1.png" alt=""></p>
<p>TransE模型的训练中，第12步是损失函数，对E和L做uniform初始化之后，让正确的h+l-t结果趋近于0，让错误的h‘+l-t’的结果变大，损失函数结果大于0取原值，小于0则取0，这种hinge loss function可以尽可能的将对和错分开，模型使用SGD训练，每次更新可以只更新这个batch里的三元组的向量，因为参数之间并没有冲突。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code: <a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文提出了一种将实体与关系嵌入到低维向量空间中的简单模型，弥补了传统方法训练复杂、不易拓展的缺点。尽管现在还不清楚是否所有的关系种类都可以被本方法建模，但目前这种方法相对于其他方法表现不错。TransE更是作为知识库vector化的基础，衍生出来了很多变体。</p>
<h1 id="TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes"><a href="#TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes" class="headerlink" title="TransH:Knowledge Graph Embedding by Translating on Hyperplanes"></a><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531" target="_blank" rel="external">TransH:Knowledge Graph Embedding by Translating on Hyperplanes</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Zhen Wang1, Jianwen Zhang2, Jianlin Feng1, Zheng Chen2</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Sun Yat-sen University<br>microsoft</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, Multi-relational data</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>AAAI 2014</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>对知识库中的实体关系建模,特别是一对多,多对一,多对多的关系。设计更好的建立负类的办法用于训练。 </p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>过去指示图库建模的方法参数过多, TransE在一定程度上解决了这个问题, 但是TransE过于简单，很难对一对多,多对一和多对多关系建模。所以为了平衡模型复杂度和建模效果，TransH将把关系映射到另一个空间（如下图 ）。 注意: 这种想法和Distant Model (Bordes et al. 2011)很相似，但是TransH用了更少的参数， 因为TransH假设关系是向量而不是距离。<br><img src="media/TransH_1.png" alt="TransH_1"></p>
<p>这个模型的一个亮点就是用尽量少的参数对复杂的关系建模。 下图罗列了相关工作的模型以及复杂度。图中可以看到从TransE到TransH并没有添加太多的参数（Unstructured只是TransE简化版）。Bilinear，Single Layer， NTN对关系或者实体进行了非线性的转换，作者认为是没有必要的（增加了模型复杂度）。</p>
<p><img src="media/TransH_2.png" alt="TransH_2"></p>
<p>TransH模型的训练和TransE类似 （SGD优化） ，下面是损失函数（因为一些限制，后面加入了拉格朗日乘数）。论文另一个亮点是设计了一种负类抽样的方法，即一对多的时候，给head更多的抽样概率， 同样的多对一的时候，给tail更多抽样概率。<br><img src="media/TransH_3.png" alt="TransH_3"></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet:<a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase:  <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code:<a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）TransE (Bordes et al. 2013b): 和TransH相比，它没有将关系映射到另一个空间，关系由一个向量r表示。<br>（2）Unstructured Model：简化版的TransE，假设r = 0。<br>（3）Structured Embedding：  使用了两个关系相关的矩阵，分别用于头h和尾t，评估函数为:<br><img src="media/TransH_4.PNG" alt=""><br>该方法并没有抓住实体和关系之间的关系。<br>（4）Single Layer Model(SLM)：使用了神经网络，评估函数为:<br><img src="media/TransH_5.PNG" alt=""><br>（5）Distant Model (Bordes et al. 2011)：它将实体映射到另一个空间，然后假定关系是距离而不是向量（因为用了2个不同矩阵映射实体，所以对实体关系建模并不是很好）。<br>（6）Bilinear Model (Jenatton et al. 2012; Sutskever, Tenen- baum, and Salakhutdinov 2009)，Single Layer Model (Socher et al. 2013)，NTN (Socher et al. 2013)：他们都是使用非线性函数映射实体，这样模型表达能力虽然好但是太多参数也太复杂了（容易过拟合）。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>论文提出的TransH模型，为了解决TransE对一对多，多对一，多对多关系建模的难题。它权衡模型复杂度和模型表达能力。而且还设计了复杂取样的办法用于训练。</p>
<h1 id="TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix"><a href="#TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix" class="headerlink" title="TransD: knowledge graph embedding via dynamic mapping matrix"></a><a href="http://www.aclweb.org/anthology/P15-1067.pdf" target="_blank" rel="external">TransD: knowledge graph embedding via dynamic mapping matrix</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu and Jun Zhao</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>中国科学院自动化研究所  National Laboratory of Pattern Recognition (NLPR)</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, link prediction.</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL2015</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>知识图谱中的link prediction。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>在link prediction上的TransE扩展模型，函数仍然为:   </p>
<p> <img src="meida/TransD_1.PNG" alt=""> </p>
<p>但h丄和t丄为entity向量h和entity向量t在该relation r上的投影表示。投影定义为：</p>
<p> <img src="media/TransD_2.PNG" alt=""></p>
<p>其中(h_p)^T为某entity的投影向量，h为该entity的表示向量。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>数据集 FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>如果TransD的所有投影向量为0，TransD就是TransE。类似的还有TransR/CTransR，他们对每个relation定义了一个mapping矩阵，参数更多计算复杂度更大。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>模型只涉及vector的相乘，因此计算复杂度较小，效果也取得了state-of-the-art，适合用于规模很大的知识图谱。</p>
<h1 id="TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding"><a href="#TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding" class="headerlink" title="TransA:An Adaptive Approach for Knowledge Graph Embedding"></a><a href="https://arxiv.org/pdf/1509.05490v2.pdf" target="_blank" rel="external">TransA:An Adaptive Approach for Knowledge Graph Embedding</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Hao Xian, Minlin  Huang,  Hao Yu,  Xiaoyan  Zhu</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位:"></a>单位:</h2><p> 清华大学  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="关键词："><a href="#关键词：" class="headerlink" title="关键词："></a>关键词：</h2><p>knowledge graph embedding,  elliptical equipotential hypersurfaces,  metric learning.</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何解决了translation-based 知识表示方法存在的过于简化损失度量，没有足够竞争力去度量知识库中实体/关系的多样性和复杂性问题。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>知识图谱在AI搜索和应用中扮演着越来越重要的角色，但是它是符号表示，有一定的逻辑性的，因此如何表示这些关系就成了一个很大的挑战，为了解决这个挑战，很多模型如TransE, TransH, TransR纷纷被提出来，在这些模型中，基于几何关系的方法是很重要的一个分支，而基于几何关系的方法是使用K维的向量表示实体或者关系，然后利用一个函数f_r(h,t)来度量三元组(h, r, t)，而他们都是基于一个准则h+r=t。<br>因此就使用了同一个损失度量h+r=t，这种损失度量其实是利用了在一个球形等价超平面，越接近中心，三元组的可信度越高，因此从未匹配的t中寻找合适的t就变得很苦难，同时这种方法也很难处理一对多，多对一，多对多的关系。因此这些方法不够灵活。<br>具体可以从图1(a)看出。同时这种方法将等价对待向量中的每一维，但实际上各个维度的重要性是不同的，只有一些维度是有效的，其他维度可以认为是噪音，会降低效果，具体见图2(a).</p>
<p>因此作者提出了另一种损失度量函数</p>
<p><img src="media/TransA-2.PNG" alt=""></p>
<p>通过增加一个矩阵Wr​，首先利用了一个椭圆等价超平面，解决了上述问题1，具体见图1(b)；同时利用LDL分解，公式变为:</p>
<p><img src="media/TransA-3.PNG" alt=""></p>
<p>其中D_r就是一个对角阵，而对角阵中的每个值的大小，正好说明了每一维的不同重要程度，也就解决了上述问题2，具体减图2(b)。</p>
<p><img src="meida/TransA-4.JPG" alt="figure 1"><br>图1<br><img src="media/TransA-5.JPG" alt="figure 2"><br>图2</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>数据集 Wordnet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>数据集 FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>如模型部分介绍的，当前的一些现有模型都是基于一个准则h+r=t，因此就使用了同一个损失度量h_r+r=t_r，只是在h_r和t_r的表示上有不同：</p>
<p>（1）TransE  h_r = h, t_r = t<br>（2）TransH  h_r = h - (w_r)^T.h.w_r,  t_r = t - (w_r)^T.t.w_r<br>（3）TransR  h_r = M_r.h,  t_r = M_r.t<br>（4）TransM则是预先计算了出每一个训练三元组的直接权重</p>
<p>还有很多类似的模型，这里就不再介绍了。</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>感觉这篇文章的思路比较简单，就是针对当前模型的一些不足，更换了一个损失度量函数。但是几点还是值得学习的，首先通过图像来描述不同的损失度量函数，给人一个更直观的感觉；其次针对向量表示中的区别对待，感觉很有attention mechanism的感觉，对不同的triple关注向量表示的不同维度，以取得最好的效果，这点是非常值得借鉴参考的。</p>
<h1 id="TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding"><a href="#TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding" class="headerlink" title="TransG : A Generative Mixture Model for Knowledge Graph Embedding"></a><a href="https://arxiv.org/abs/1509.05488" target="_blank" rel="external">TransG : A Generative Mixture Model for Knowledge Graph Embedding</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p> Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>清华大学  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, generative mixture model, multiple relration semantics.</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv2015</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>解决多关系语义(multiple relation semantics)的问题。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>传统的基于翻译的模型采用h_r+r= t_r(其中，h_r为头部实体，t_r为尾部实体，r为头部<br>实体跟尾部实体的关系)，仅仅对一个关系赋予一种翻译向量。<br>它们不能细分多关系语义，比如，(Atlantics, HasPart, NewYorkBay)和(Table, HasPart, Leg)两个的关系都是HasPart，但是这两个的关系在语义上不同，第一个是“部件”的关系，第二个是“位置”的关系。TransG能够解决关系的多语义问题。如图所示，多关系语义分析可以提高三元组的分类准确度。</p>
<p><img src="media/TransG.png" alt="figure 1"></p>
<p>TransG利用贝叶斯非参数无限混合模型对一个关系生成多个翻译部分，根据三元组的特定语义得到当中的最佳部分。最大数据相似度原理用来训练，优化采用SGD。实验结果在link prediction和triple classification这两种任务上都优于目前最好的结果，运行速度与TransE(最快的方法)成正相关，系数为关系语义部分的数目。</p>
<h2 id="资源-4"><a href="#资源-4" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p>大多数都已介绍，这里就只说明CTransR，其中关系的实体对被分类到不同的组，同一组的实体对共享一个关系向量。相比较而言，TransG不需要对聚类的预处理。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>这篇文章的idea比较重要，考虑到一种关系存在的多语义问题，相当于对关系进行了细化，就是找到关系的隐形含义，最终从细化的结果中选出一个最佳的关系语义。这个在应用中很有意义，不同的语义可能需要不同的应对方法，可以借鉴。</p>
<h1 id="KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding"><a href="#KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding" class="headerlink" title="KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding"></a><a href="http://dl.acm.org/citation.cfm?id=2806502" target="_blank" rel="external">KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding</a></h1><h2 id="作者-5"><a href="#作者-5" class="headerlink" title="作者"></a>作者</h2><p>Shizhu He, Kang Liu, Guoliang Ji and Jun Zhao</p>
<h2 id="单位-5"><a href="#单位-5" class="headerlink" title="单位"></a>单位</h2><p>National Laboratory of Pattern Recognition<br>Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Distributed Representation, Gaussian Embedding, Knowledge Graph</p>
<h2 id="文章来源-5"><a href="#文章来源-5" class="headerlink" title="文章来源"></a>文章来源</h2><p>CIKM 2015</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>本文所解决的问题是知识图谱的表示问题（即将知识图谱表示为低维连续向量空间），本文使用Gaussian Distribution 来表示实体和关系，提出了用Gaussian Distribution的协方差来表示实体和关系的不确定度的新思想，提升了已有模型在link prediction和triplet classification问题上的准确率。</p>
<h2 id="模型-5"><a href="#模型-5" class="headerlink" title="模型"></a>模型</h2><p>传统的表示学习的表示学习的方法和计算比较复杂，自TransE模型诞生后，很多模型都是在TransE的基本思想上加以改进，KG2E模型也是一样。<br>KG2E模型使用高斯分布来表示实体和关系。<br>模型实例见下图：<br><img src="media/KG2E_example.png" alt="model example"></p>
<p>每个圆圈代表不同实体与关系的表示，它们分别于“Bill Clinton”构成三元组关系，圆圈大小表示的是不同实体或关系的不确定度。</p>
<p>模型算法流程图如下：<br><img src="media/KG2E_Algorithm.png" alt="model algorithm"></p>
<p>算法解读：<br>输入：训练集三元组，KG中所有的实体和关系，以及其它的一些参数。<br>输出：KG中所有实体和关系建模后生成的Gaussian Embeddings.（主要包含两个部分，均值（向量）和协方差（矩阵））<br>line 1到line 4主要是数据的归一化<br>line 5到line 15是算法实现部分：模型采用的是minibatch的训练方法，每一个minibatch的训练中都会进行负采样，并将负采样的样例和正例样例混合在一起学习，然后使用评分函数进行评估，要达到的目的是正例三元组的得分比负例三元组高或者低（高低取决于具体的评分而函数的设定）。在一次一次的迭代中不断更新结果，最后将得到的means和covariance进行正则化。</p>
<p>文章核心公式：<br>（1）评分函数<br><img src="media/KG2E_Score_function.png" alt="score function"></p>
<p>（2）KL散度的能量函数</p>
<p><img src="media/KG2E_KL_function.png" alt="KL energy function"></p>
<p>（3）期望概率能量函数<br><img src="media/KG2E_EL_function.png" alt="EL energy function"></p>
<h2 id="资源-5"><a href="#资源-5" class="headerlink" title="资源"></a>资源</h2><p>数据集：<br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">WN18</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Wordnet" target="_blank" rel="external">WN11</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Freebase" target="_blank" rel="external">FB13K</a><br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">FB15K</a></p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）TransR，2015年AAAI，Learning entity and relation embeddings for knowledgh completition。</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>创新点：<br>    （1）以前的文章是属于point-based，KG2E是属于density-based的。<br>    （2）提出了(un)certainty的概念，在建模过程中融入了关系和实体语义本身的不确定性的知识，使用高斯分布的协方差表示该实体或关系的不确定度，高斯分布的均值表示实体或关系在语义空间中的中心值。<br>    （3）使用了新的score funciton：KL-divergence和expected likelihood<br>应用场景：link prediction，triplet classification,knowledge reasoning<br>不足之处：本文提出的方法在link prediction的many-to-many relations上的预测性能不是很好，主要原因是KG2E模型没有考虑实体的类型和粒度。</p>
<p>7.TranSparse</p>
<h1 id="Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix"><a href="#Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix" class="headerlink" title="Knowledge Graph Completion with Adaptive Sparse Transfer Matrix"></a><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693" target="_blank" rel="external">Knowledge Graph Completion with Adaptive Sparse Transfer Matrix</a></h1><h2 id="作者-6"><a href="#作者-6" class="headerlink" title="作者"></a>作者</h2><p>Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao</p>
<h2 id="单位-6"><a href="#单位-6" class="headerlink" title="单位"></a>单位</h2><p>中科院模式识别国家重点实验室</p>
<h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Knowledge Graph Embedding,Sparse Matrix</p>
<h2 id="文章来源-6"><a href="#文章来源-6" class="headerlink" title="文章来源"></a>文章来源</h2><p>AAAI 2016</p>
<h2 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h2><p>针对不同难度的实体间关系，使用不同稀疏程度的矩阵（不同数量的参数）来进行表征，从而防止对复杂关系欠拟合或者对简单关系过拟合。</p>
<h2 id="模型-6"><a href="#模型-6" class="headerlink" title="模型"></a>模型</h2><p>本文的模型与TransR类似，即对每一个关系r学习一个转换矩阵M_r,将h和t的向量映射到关系向量所在的空间。</p>
<p>不过本文注意到knowledge graph中面临两个问题，分别是heterogeneous（有的实体关系十分复杂，连接许多不同的实体）和unbalanced（很多关系连接的head和tail数目很不对等）。如果只使用一个模型应对所有情况的话可能会导致对复杂关系underfit，对简单关系overfit。因此本文认为需要对症下药，复杂的关系就需要下猛药（用有更多的参数的复杂模型），简单关系就简单处理（较少的参数）。</p>
<p>但是怎么实现这样灵活的建模？在方法上本文借用了SparseMatrix，如果关系比较复杂就用比较稠密的矩阵，如果关系简单则用稀疏矩阵进行表达。文章假设关系的复杂程度正比于包含该关系的triplet数目，并根据两类问题提出了对应的稀疏矩阵初始化方法。不过并没有提出同时解决两类问题的统一方案。</p>
<ul>
<li>针对heterogeneity问题的模型叫做TranSparse(share)，模型参数sparse degree，theta_r，是由下列公式确定:</li>
</ul>
<p><img src="media/TranSparse_equation1.png" alt="alt text"><br>其中N_r是该关系r所连接的triplet数目，N_r*是数据集中最大的关系triplet数目。通过这个sparse degree我们就可以确定参数矩阵的稀疏程度了。entity的向量通过下式进行转换：<br><img src="media/TranSparse_equation2.png" alt="alt text"></p>
<ul>
<li>针对imbalance问题提出的TranSparse(separate)方法也十分类似，即在关系的head和tail两端使用不同复杂度的matrix。sparse degree的公式与上面TranSparse(share)的几乎一样，只不过N_r和N_r*替换成了entity的个数。如果某一端要连接更多不同的entity，那么这一端就需要更复杂的模型来表征（matrix有更多非零参数）。</li>
</ul>
<p>确定这个sparse degree之后，我们就可以初始化对应的稀疏参数矩阵了（原文中提到了Structured与Unstructured两种矩阵形式）。目标函数以及训练过程与其他工作一致，只不过在进行训练时我们只对矩阵中的非零部分进行更新。</p>
<p>最后模型在triplet分类和链接预测任务上进行实验，相比于先前模型取得了更好的成绩，不过相比于TranD优势并不十分明显。提出的两个模型中TranSparse(separate)的表现更好。</p>
<h2 id="资源-6"><a href="#资源-6" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>上面的相关工作已经介绍差不多了，这里不再赘述。</p>
<h2 id="简评-6"><a href="#简评-6" class="headerlink" title="简评"></a>简评</h2><p>TranSparse模型主要是为了解决关系和实体的异质性和不平衡性而提出，问题针对性强。</p>
<h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>最近几年人们对知识表示方法的探究一直都在进行，知识表示学习对于计算机如何理解和计算知识的意义是重大的。在2013年embedding的思想出现之前，人们基本采用one-hot的表示方法来表示实体，近几年知识表示的核心思想就是如何找到合适的方法来将知识图谱emmbedding到向量空间，从而在向量空间中进行计算，并且也在这方面取得了不错的进展。</p>
<p>但知识表示学习仍然面临着挑战，主要包括以下几个方面：（1）对于多源知识融合的表示学习，如何将知识库中的文本等信息加入到学习中。（2）如何进行更加复杂的知识推理。（3）对于知识图谱无法表达的信息，应该进行如何表示和推理。（4）如何在知识库中融入常识信息。<br>参考文献说明：本文主要参考清华大学刘知远老师的《知识表示学习研究进展》这篇综述。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h2&gt;&lt;p&gt;本期PaperWeekly的主题是基于翻译模型(Trans系列)的知识表示学习，主要用来解决知识表示和推理的问题。表示学习旨在将研究对象的语义信息表
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.10.10-2016.10.14</title>
    <link href="http://rsarxiv.github.io/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/"/>
    <id>http://rsarxiv.github.io/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/</id>
    <published>2016-10-15T17:39:35.000Z</published>
    <updated>2016-10-15T17:57:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Learning"></a><a href="https://arxiv.org/pdf/1610.02891v1.pdf" target="_blank" rel="external">Personalizing a Dialogue System with Transfer Learning</a></h2><p>【对话系统】【迁移学习】面向具体任务的对话系统由于数据不充分，面临难以训练的尴尬境地。解决这一问题的方法之一是用迁移学习来做，本文提出了一种基于POMDP的迁移学习框架。并且在购买咖啡的实际场景中得到了应用，取得了不错的效果。港科大杨强老师是迁移学习领域的专家，而迁移学习是解决机器学习中领域数据过小问题的一种有效方法，现有的特有对话系统面临着这个问题，尤其是要求对话系统具有个性化的特点时。本文对于研究语音对话系统和聊天机器人都有一定的启发性。</p>
<h2 id="Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling"><a href="#Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling" class="headerlink" title="Dialogue Session Segmentation by Embedding-Enhanced TextTiling"></a><a href="https://arxiv.org/pdf/1610.03955v1.pdf" target="_blank" rel="external">Dialogue Session Segmentation by Embedding-Enhanced TextTiling</a></h2><p>【chatbot】【上下文处理】本文研究的内容是开放域聊天机器人context处理的问题，当前聊天的内容很大程度上都会与之前的聊天内容有相关，但并不是每一句都相关，因此算好相关度很有必要。</p>
<h2 id="Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding"><a href="#Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding" class="headerlink" title="Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding"></a><a href="https://arxiv.org/pdf/1610.04120v1.pdf" target="_blank" rel="external">Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding</a></h2><p>【对话系统】【深度学习】本文是steve young组的一篇新文，旨在探索CNN表示对话句子和LSTM表示上下文信息在对话理解问题上的效果，相比于传统方法，DNN方法鲁棒性更强。</p>
<h2 id="Latent-Sequence-Decompositions"><a href="#Latent-Sequence-Decompositions" class="headerlink" title="Latent Sequence Decompositions"></a><a href="https://arxiv.org/pdf/1610.03035v1.pdf" target="_blank" rel="external">Latent Sequence Decompositions</a></h2><p>【seq2seq】本文研究的内容是对seq2seq框架中输入和输出序列进行有意义分解的问题，而不是简单地分解为char，提出了一种Latent Sequence Decompositions框架，在语音识别问题上取得了不错的效果。其实不仅仅是语音识别问题，在用seq2seq框架时总会遇到OOV的问题，char是一种方法，但信息量太少，如果能够将word sequence分解为更加有意义的子序列，既兼顾了信息量，又降低了词表维度。对英文系的语言效果好一些，中文效果应该不会那么明显。</p>
<h2 id="Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models"><a href="#Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models" class="headerlink" title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models"></a><a href="https://arxiv.org/pdf/1610.02424v1.pdf" target="_blank" rel="external">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models</a></h2><p>【seq2seq】seq2seq框架中在解码阶段，常常会用beam search来从左至右、贪心地生成N个最好的输出，不仅仅效率低下，而且在很多复杂任务中效果不好。本文提出了一种新的搜索算法。算法会在解空间内exploration和exploitation，通过设定diverse的目标进行训练，得到结果。相比之下，本文的方法更加高效。并且在image  caption、VQA和MT等任务中进行了验证。</p>
<h2 id="Gated-End-to-End-Memory-Networks"><a href="#Gated-End-to-End-Memory-Networks" class="headerlink" title="Gated End-to-End Memory Networks"></a><a href="https://arxiv.org/pdf/1610.04211v1.pdf" target="_blank" rel="external">Gated End-to-End Memory Networks</a></h2><p>【seq2seq】【memory networks】端到端的记忆网络在简单的机器阅读理解任务上取得了不错的效果，但复杂的事实问答和对话理解相关的任务处理的并不好，原因在于记忆单元与模型之间交互复杂。本文针对该问题，提出了一种Gated记忆网络，取得了不错的效果。本文模型在机器阅读理解bAbI dataset和task-oriented 对话系统任务DSTC2中均取得了非常好的结果。</p>
<h2 id="Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks"><a href="#Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks" class="headerlink" title="Neural Paraphrase Generation with Stacked Residual LSTM Networks"></a><a href="https://arxiv.org/pdf/1610.03098v3.pdf" target="_blank" rel="external">Neural Paraphrase Generation with Stacked Residual LSTM Networks</a></h2><p>【paraphrase】本文提出用多层残差LSTM网络来做paraphrase的任务，得到了比之前seq2seq以及seq2seq+attention更好的效果。转述在某个角度上和标题生成（句子level摘要）类似，方法可借鉴。</p>
<h2 id="SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods"><a href="#SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods" class="headerlink" title="SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"></a><a href="https://arxiv.org/pdf/1610.03771v1.pdf" target="_blank" rel="external">SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods</a></h2><p>【观点挖掘】【数据集】本文给出了一个观点挖掘的数据集，数据源来自Yahoo问答中与London相关的提问。这个数据集适合这样的场景，一段评论中包含了多个entity的多个aspect的观点，相互之间有一些比较。</p>
<h2 id="Domain-specific-Question-Generation-from-a-Knowledge-Base"><a href="#Domain-specific-Question-Generation-from-a-Knowledge-Base" class="headerlink" title="Domain-specific Question Generation from a Knowledge Base"></a><a href="https://arxiv.org/pdf/1610.03807v1.pdf" target="_blank" rel="external">Domain-specific Question Generation from a Knowledge Base</a></h2><p>【问题生成】问答系统是一个热门研究领域，其关注点在于如何理解问题然后选择或者生成相应的答案。而本文研究的问题是如何根据知识图谱生成高质量的问题。提出高质量的问题难度很大，且看本文内容。</p>
<h2 id="Compressing-Neural-Language-Models-by-Sparse-Word-Representations"><a href="#Compressing-Neural-Language-Models-by-Sparse-Word-Representations" class="headerlink" title="Compressing Neural Language Models by Sparse Word Representations"></a><a href="https://arxiv.org/pdf/1610.03950v1.pdf" target="_blank" rel="external">Compressing Neural Language Models by Sparse Word Representations</a></h2><p>【语言模型】【提升效率】本文解决的是在学习语言模型时输出层词表过大的问题，词表过大导致效率过低，本文针对这一问题，提出了一种压缩方法，常见词用dense向量来表示，而罕见词用常见词的线性组合来表示。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="CCL-amp-NLP-NABD-2016论文集"><a href="#CCL-amp-NLP-NABD-2016论文集" class="headerlink" title="CCL &amp; NLP-NABD 2016论文集"></a><a href="http://www.cips-cl.org/static/CCL2016/index.html" target="_blank" rel="external">CCL &amp; NLP-NABD 2016论文集</a></h2><p>由Springer出版的CCL &amp; NLP-NABD 2016论文集已经公布，并在10月10日-11月10日期间可以免费下载。免费下载方式如下：（1）访问会议首页；（2）点击该页面最新“会议论文下载”中的链接；（3）点击新页面的“Download Book (PDF, 35547KB)”按钮。</p>
<h2 id="北京大学万小军老师组开源自动摘要小工具PKUSUMSUM"><a href="#北京大学万小军老师组开源自动摘要小工具PKUSUMSUM" class="headerlink" title="北京大学万小军老师组开源自动摘要小工具PKUSUMSUM"></a><a href="http://www.icst.pku.edu.cn/lcwm/wanxj/pkusumsum.htm" target="_blank" rel="external">北京大学万小军老师组开源自动摘要小工具PKUSUMSUM</a></h2><p>本组推出文档自动摘要小工具PKUSUMSUM，集成多种无监督摘要提取算法，支持多种摘要任务与多种语言，采用Java编写，代码完全开源，欢迎批评指正，也欢迎同行一起完善该工具。</p>
<h2 id="斯坦福大学NLP组2016年秋季paper阅读周计划"><a href="#斯坦福大学NLP组2016年秋季paper阅读周计划" class="headerlink" title="斯坦福大学NLP组2016年秋季paper阅读周计划"></a><a href="http://nlp.stanford.edu/read/" target="_blank" rel="external">斯坦福大学NLP组2016年秋季paper阅读周计划</a></h2><p>斯坦福大学NLP组2016年秋季paper阅读周计划，挺多篇都是对话系统相关的。 </p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读&quot;&gt;&lt;a href=&quot;#一周值得读&quot; class=&quot;headerlink&quot; title=&quot;一周值得读&quot;&gt;&lt;/a&gt;一周值得读&lt;/h1&gt;&lt;h2 id=&quot;Personalizing-a-Dialogue-System-with-Transfer-Learnin
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第九期</title>
    <link href="http://rsarxiv.github.io/2016/10/13/PaperWeekly-%E7%AC%AC%E4%B9%9D%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/10/13/PaperWeekly-第九期/</id>
    <published>2016-10-14T04:09:21.000Z</published>
    <updated>2016-10-14T16:54:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>深度生成模型基本都是以某种方式寻找并表达（多变量）数据的概率分布。有基于无向图模型（马尔可夫模型）的联合概率分布模型，另外就是基于有向图模型（贝叶斯模型）的条件概率分布。前者的模型是构建隐含层(latent)和显示层（visible)的联合概率，然后去采样。基于有向图的则是寻找latent和visible之间的条件概率分布，也就是给定一个随机采样的隐含层，模型可以生成数据。</p>
<p>生成模型的训练是一个非监督过程，输入只需要无标签的数据。除了可以生成数据，还可以用于半监督的学习。比如，先利用大量无标签数据训练好模型，然后利用模型去提取数据特征（即从数据层到隐含层的编码过程），之后用数据特征结合标签去训练最终的网络模型。另一种方法是利用生成模型网络中的参数去初始化监督训练中的网络模型，当然，两个模型需要结构一致。</p>
<p>由于实际中，更多的数据是无标签的，因此非监督和半监督学习非常重要，因此生成模型也非常重要。本篇主要介绍一种基于对抗模式的生成模型，GAN － 从第一篇提出此模型的论文开始，之后紧接着两篇基于它的实现以及改进。三篇文章一脉相承，可以看到结合这种模型的研究进展及方向。</p>
<h1 id="Generative-Adversarial-Nets"><a href="#Generative-Adversarial-Nets" class="headerlink" title="Generative Adversarial Nets"></a><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="external">Generative Adversarial Nets</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Universite of Montreal</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>生成模型 （Generative model）</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>NIPS 2014</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>通过模拟对抗过程，提出一种新的生成模型框架</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ul>
<li>建模</li>
</ul>
<p>在对抗生成模型中，同时训练两个网络，第一个网络是生成网络，G(z)，输入z一般是来自常见概率分布函数的样本向量，维度一般比较低，比如100。生成网络输入向量z，输出图片样例，如果使用卷机网实现的话，整个网络可以看过一个反向的CNN，其中的卷积层替换成 transposed convolution layer。第二个网络是识别网络discriminator net - D(x)，输入为一张图片x，而输出为一个标量，用来代表x来自真实图片的概率。</p>
<ul>
<li>训练</li>
</ul>
<p>整个网络的loss定义为</p>
<p>V = E’[log D(x)] + E’’[log (1 - D(G(z)) )]<br>E’ - 当x来自真实数据的期望<br>E’’ - 当x来自生成网络的期望</p>
<p>很显然，在对抗网络中，生成模型希望能够增大D(G(z))，即，希望生成的图片越真实而让识别模型“误以为”是来自真实的图片集。</p>
<p>如果生成网络G的参数用theta表示，识别模型的参数用theta_d表示，在使用SGD训练的时候，两组参数分别进行训练，对于D来说，需要对上面的公式求Gradient，但是只更新自己的参数。对G来说，只有第二项是相关的，而且可以等效的转换为maximize log D(G(z))。两个网络的参数更新交替进行。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>网上有很多实现，比如:</p>
<p><a href="https://github.com/goodfeli/adversarial" target="_blank" rel="external">goodfeli/adversarial</a>: Theano GAN implementation released by the authors of the GAN paper.<br><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="external">Newmu/dcgan_code</a>: Theano DCGAN implementation released by the authors of the DCGAN paper.<br><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="external">carpedm20/DCGAN-tensorflow</a>: Unofficial TensorFlow DCGAN implementation.</p>
<p>这些实现一般都会包含MNIST测试集。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>其他的生成模型包括restricted Boltzmann machine (RBM), deep Boltzmann machine (DBM) 以及 variational autoencoder</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>其他生成模型中训练过程涉及intractable的计算，在实际实现时往往采取马尔可夫链模特卡洛采样(MCMC)。对抗生成模型(GAN)则不需要，整个网络的训练可以使用backpropagation来实现。</p>
<p>缺点包括训练不稳定，生成网络会塌陷到某些数据点（比如这些数据点目前看最像真实数据，生成网络会不停生成这些数据点），接下来的几篇中将提及如何改进。</p>
<h1 id="Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434"><a href="#Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434" class="headerlink" title="[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (https://arxiv.org/abs/1511.06434)"></a>[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (<a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="external">https://arxiv.org/abs/1511.06434</a>)</h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Alec Radford, Luke Metz, Soumith Chintala</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>facebook</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>DCGAN, Representation Learning</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>基于深度卷积网络的生成对抗模型(DCGAN)实现</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>在GAN的论文中提出的对抗模型的原型，但是对抗模型是一个大的框架，并不局限于某种网络实现。本文给出了基于卷机网的实现。</p>
<p>生成网络<br><img src="media/gen-architecture-1.png" alt="gen-architecture"></p>
<p>其中反卷积的过程是</p>
<p><img src="media/padding_strides_transposed-1.gif" alt="padding_strides_transposed"></p>
<p>识别网络是传统的CNN</p>
<p><img src="media/discrim-architecture.png" alt="discrim-architecture"></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文紧密承接上篇论文，描述了实现过程中的细节，比如参数设置。也提到了解决GAN中训练不稳定的措施，但是并非完全解决。文中还提到利用对抗生成网络来做半监督学习。在训练结束后，识别网络可以用来提取图片特征，输入有标签的训练图片，可以将卷基层的输出特征作为X，标签作为y做训练。</p>
<h1 id="Improved-Techniques-for-Training-GANs"><a href="#Improved-Techniques-for-Training-GANs" class="headerlink" title="Improved Techniques for Training GANs"></a><a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="external">Improved Techniques for Training GANs</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>OpenAI</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>DCGAN</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>提出改进DCGAN的措施</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>这篇论文同样跟前文非常紧密，具体针对DCGAN中的问题，提出了改进方法。具体有</p>
<ul>
<li>feature matching 解决训练不稳定instability的问题</li>
<li>minibatch discrimination 解决生成网络生成图片集中的问题，原理是让识别网络一次看一组图片，而不是一张图片</li>
<li>如果对实现感兴趣，其他改进细节可以参见论文</li>
</ul>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>对抗生成网络的模型很有意思，Bengio, Hinton等都表达了很高的评价。相对其他生成模式而言，对抗生成模式模型清晰简单，目前来看效果也比较不错。但是目前对抗生成网络也有很多问题，比如生成模型是通过来自概率分布的向量生成样本，而不是直接表示输入的概率分布，因此，生成的图片可能不稳定之类。此外，希望能看到GAN在语言模型中的应用。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>GAN这种模型非常新颖，从论文中的结果来看，在图像生成上取得了不错的效果，对于MNIST这种简单的图形数据集，生成的图片已经可以“以假乱真”。对于另外的图片，比如在第二篇论文中的LSUN bedroom图片集以及人脸图片集上，生成的图片效果也不错（分辨率64×64）。<br>GAN目前来看已经卷积网络图像生成中取得了不错的效果，但是还有很多问题需要继续研究改进， 比如<br>如何生成高像素高质量的图片。目前一般像素不超过64。<br>如何提高复杂图片的质量。目前在CIFAR，ILSVRC等图片集上训练生成的图片还是很糟糕。<br>如何提高整个模型的稳定性。在实际中，尤其对于复杂图形，生成器经常很快收敛到某些单个数据集，使得整个模型的训练陷入僵局。<br>如何在其他领域，比如NLP使用GAN，如何将GAN和LSTM结合的。目前来看，还没有成功的应用。原文作者在reddit上回答内容来看，由于GAN的输入是采样自连续分布，而NLP中，每个单词的表达往往是离散的，作者提到NLP可以用增强训练的方法替代。但是也不排除可以有其他方法将GAN和LSTM结合起来的，这也是以后的一个研究点。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;深度生成模型基本都是以某种方式寻找并表达（多变量）数据的概率分布。有基于无向图模型（马尔可夫模型）的联合概率分布模型，另外就是基于有向图模型
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.10.03-2016.10.07</title>
    <link href="http://rsarxiv.github.io/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/"/>
    <id>http://rsarxiv.github.io/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/</id>
    <published>2016-10-08T02:06:28.000Z</published>
    <updated>2016-10-08T02:18:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读（偏学术）"><a href="#一周值得读（偏学术）" class="headerlink" title="一周值得读（偏学术）"></a>一周值得读（偏学术）</h1><h2 id="Controlling-Output-Length-in-Neural-Encoder-Decoders"><a href="#Controlling-Output-Length-in-Neural-Encoder-Decoders" class="headerlink" title="Controlling Output Length in Neural Encoder-Decoders"></a><a href="https://arxiv.org/pdf/1609.09552v1.pdf" target="_blank" rel="external">Controlling Output Length in Neural Encoder-Decoders</a></h2><p>本文针对encoder-decoder框架在应用时无法控制生成序列长度（比如文本摘要）的问题，作者提出了一种基于学习的模型来解决这个问题。encoder-decoder框架已经被成功应用于各大任务中，加上attention，不同变种的attention，研究的人很多。本文也是属于变种之一，考虑了在实际应用中文本摘要长度需要被控制的问题，提出了本文的模型。</p>
<h2 id="Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension"><a href="#Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension" class="headerlink" title="Embracing data abundance: BookTest Dataset for Reading Comprehension"></a><a href="https://arxiv.org/pdf/1610.00956v1.pdf" target="_blank" rel="external">Embracing data abundance: BookTest Dataset for Reading Comprehension</a></h2><p>【数据福利】本文发布了一个新的机器阅读理解数据集BookTest，该数据集最大的亮点是规模大，是Facebook发布的Children’s Book Test的60倍之大。</p>
<h2 id="Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges"><a href="#Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges" class="headerlink" title="Visual Question Answering: Datasets, Algorithms, and Future Challenges"></a><a href="https://arxiv.org/pdf/1610.01465v1.pdf" target="_blank" rel="external">Visual Question Answering: Datasets, Algorithms, and Future Challenges</a></h2><p>【综述】这是一篇Visual Question Answer任务的综述性文章，系统地总结、讨论和对比了近几年该领域的数据集和算法，并给出了一些该领域未来的研究方向。</p>
<h2 id="Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods"><a href="#Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods" class="headerlink" title="Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods"></a><a href="https://arxiv.org/pdf/1610.01206v1.pdf" target="_blank" rel="external">Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods</a></h2><p>【综述】本文是一篇2015年出版的多模态表示学习的综述文章，非常适合刚刚了解或者准备进入这个领域的童鞋来读。 </p>
<h2 id="Neural-based-Noise-Filtering-from-Word-Embeddings"><a href="#Neural-based-Noise-Filtering-from-Word-Embeddings" class="headerlink" title="Neural-based Noise Filtering from Word Embeddings"></a><a href="https://arxiv.org/pdf/1610.01874v1.pdf" target="_blank" rel="external">Neural-based Noise Filtering from Word Embeddings</a></h2><p>词向量已经是NLP中各任务的基础部件，对词向量的研究工作也非常多。本文研究的切入点是从语料中的噪声入手，提出了两种无监督去噪模型，取得了不错的效果。</p>
<h1 id="一周值得读（偏应用）"><a href="#一周值得读（偏应用）" class="headerlink" title="一周值得读（偏应用）"></a>一周值得读（偏应用）</h1><h2 id="Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation"><a href="#Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation" class="headerlink" title="Learning to Translate in Real-time with Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1610.00388v2.pdf" target="_blank" rel="external">Learning to Translate in Real-time with Neural Machine Translation</a></h2><p>本文研究的内容实时机器翻译，与传统的翻译问题不同，该任务需要在翻译质量和速度两个方面寻找一个平衡点，NMT已经证明了其强大的实<br>力，在此基础上用增强学习做训练，以满足两个方面的需求。</p>
<h2 id="A-Tour-of-TensorFlow"><a href="#A-Tour-of-TensorFlow" class="headerlink" title="A Tour of TensorFlow"></a><a href="https://arxiv.org/pdf/1610.01178v1.pdf" target="_blank" rel="external">A Tour of TensorFlow</a></h2><p>本文系统的剖析了TensorFlow的计算图架构和分布式执行模型，并且系统地对比了TF和其他框架的性能。本文的结论对于框架选择困难的童鞋有一定参考意义，内容对于有志于深挖TF原理和想开发框架的童鞋具有较强的指导意义。对于立志于成为一名TFBoys（TensorFlow）的童鞋，本文是一篇不错的文章。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="Chatbots-–-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog"><a href="#Chatbots-–-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog" class="headerlink" title="Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog"></a><a href="https://pan.baidu.com/s/1nuT9qnZ" target="_blank" rel="external">Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog</a></h2><p>研究chatbot的童鞋，这本电子书值得一看，或许会有一些思考和启发！ </p>
<h2 id="王威廉老师关于如何做科研的微博"><a href="#王威廉老师关于如何做科研的微博" class="headerlink" title="王威廉老师关于如何做科研的微博"></a><a href="http://weibo.com/1657470871/EbJnqBBJ5?type=comment#_rnd1475892970397" target="_blank" rel="external">王威廉老师关于如何做科研的微博</a></h2><p>“什么是研究？本科生如何做好研究？我今天在组会上简单地给组里的本科生介绍了一点个人做研究的经验，与大家分享一下。”</p>
<h2 id="Configuring-Eclipse-with-Torch-–-Lighting-Torch"><a href="#Configuring-Eclipse-with-Torch-–-Lighting-Torch" class="headerlink" title="Configuring Eclipse with Torch – Lighting Torch"></a><a href="http://www.lighting-torch.com/2015/07/27/configuring-eclipse-with-torch/" target="_blank" rel="external">Configuring Eclipse with Torch – Lighting Torch</a></h2><p>将Torch配置到Eclipse中进行开发和调试。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读（偏学术）&quot;&gt;&lt;a href=&quot;#一周值得读（偏学术）&quot; class=&quot;headerlink&quot; title=&quot;一周值得读（偏学术）&quot;&gt;&lt;/a&gt;一周值得读（偏学术）&lt;/h1&gt;&lt;h2 id=&quot;Controlling-Output-Length-in-Neur
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第八期</title>
    <link href="http://rsarxiv.github.io/2016/10/07/PaperWeekly-%E7%AC%AC%E5%85%AB%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/10/07/PaperWeekly-第八期/</id>
    <published>2016-10-07T18:22:30.000Z</published>
    <updated>2016-10-07T19:08:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>SIGDIAL是ACL所属的关于对话系统的兴趣小组，SIG的文章针对性比较强，但文章的质量良莠不齐，本期给大家精心挑选了4篇SIGDIAL 2016的文章，带着大家一起来看看对话系统最新的研究成果。4篇文章分别是：</p>
<p>1、Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks, 2016<br>2、Neural Utterance Ranking Model for Conversational Dialogue Systems, 2016<br>3、A Context-aware Natural Language Generator for Dialogue Systems, 2016<br>4、Task Lineages: Dialog State Tracking for Flexible Interaction, 2016</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Bing Liu, Ian Lane</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Carnegie Mellon University, Electrical and Computer Engineering</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Spoken Language Understanding, RNN</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何将自然语言理解的两大问题和语言模型结合在同一个模型中进行训练，以达到实时理解语言的目的？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>特定任务下的Chatbot在理解人类语言时需要重点解决好两个问题：意图识别(Intent Detection)和槽填充(Slot Filling)，本文提出一种融合Intent Detection、Slot Filling和Language Model的模型，相比于之前的模型，本文模型的一大优势在于做自然语言理解的时候不需要等待整个word sequence完整展现，而是可以在线处理每一个arrived word。如下图：<br><img src="media/3.png" alt="3"></p>
<p>意图识别是个典型的多分类任务，而槽填充是个典型的序列标注任务。RNN的每个step都以当前word作为输入，输出是意图class、该word的label和下一个word，每个step的隐层都包含了之前所有的word、class、label信息。此模型为基本模型，在此基础上做了一些变形，得到下面四个变种：</p>
<p><img src="media/4.png" alt="4"></p>
<p>文章在Airline Travel Information Systems(ATIS)数据集上进行了实验，在语言模型评测指标和意图识别分类准确率上相比之前的模型都得到了一定地提升。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>本文Code: <a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">http://speech.sv.cmu.edu/software.html</a><br>ATIS Dataset: <a href="https://github.com/mesnilgr/is13" target="_blank" rel="external">https://github.com/mesnilgr/is13</a></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于将意图分类、槽填充和语言模型三者合一，相比之前的独立模型来说，每一步产生的信息更多，在预测下一步的时候context内容更加丰富，从而提高了识别的准确率和降低了语言模型的混乱度。</p>
<p>NLP中的很多任务都可以归纳为根据context来预测某一个word、label或者class这种范式，解决的思路也都基本类似，RNN或者GRU、LSTM作为encoder和decoder，配上attention机制来提升结果，context的信息量和质量直接影响着预测的效果，user information、user profile等等都可能作为context来构建模型，得到更好的结果。</p>
<h1 id="Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems"><a href="#Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems" class="headerlink" title="Neural Utterance Ranking Model for Conversational Dialogue Systems"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL48.pdf" target="_blank" rel="external">Neural Utterance Ranking Model for Conversational Dialogue Systems</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Michimasa Inaba, Kenichi Takahashi</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Hiroshima City University, 3-4-1 Ozukahigashi, Asaminami-ku</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Ranking Model, Utterance Selection</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>在做检索式对话时，对话语句该怎样表示，context信息该怎样引入到模型中？</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>本文实现的是一个检索式的对话模型，模型分为两部分，分别是：<br>1、Utterance Encoding<br>检索式对话，对话语句的encoding是很重要的一部分，文中使用了RNN encoder模型来实现对语句的encoding。在训练过程中，作者把encoder生成的向量，在decode成一个目标语句，即通过一个完整的seq2seq模型来训练encoder。<br>2、Ranking Candidate Utterances<br>在对候选语句排序时，作者考虑到了context的问题，他把前几次说的语句分别encode成向量，并依次输入到LSTM。如下图所示：</p>
<p><img src="media/5.png" alt="5"></p>
<p>图中u1到un是整个对话中的前n句话，ai是第i个候选语句。模型中，分别把u1…un以及ai分成用户说的和系统本身输出的，在输入到各自的RNN encoder中，得到向量vu1…vu和vai。最后将向量依次输入到RNN中，得到yai作为候选语句ai在当前context中的得分。<br>因为本文是一个ranking model，更关注的是候选语句的排序，最后候选集分数列表会转换成TOP 1的概率分布。并使用cross-entropy作为loss function。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文有两个创新点，首先通过单独训练seq2seq模型，来学习对话语句的encoder，从而降低了整个模型的学习成本，减少了需要标注的数据量。然后在排序模型中将对话的前几句语句有序输入到LSTM，达到融入了context信息的目的。</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="https://arxiv.org/pdf/1608.07076" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Ondrej Dusek, Filip Jurcicek</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Charles University</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Context-aware, Seq2seq</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何使得task-oriented的对话生成系统中生成更加自然的回复？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文是ACL2016 short paper Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings一文的拓展。原文提出基于seq2seq模型的将DA(dialogue acts)生成response的方案，其中输入是三元组(DA type,slot,value)的one-hot representation，输出是对应的response。如下图：</p>
<p><img src="media/6.png" alt="6"></p>
<p>延续原文的工作，作者为了使得生成的回复更加自然，将前面用户的提问也encode进来，具体是在原来模型的基础上加了两个encode的部分。Prepending context是把用户的问题和DA三元组前后拼接成新的表示再feed into encoder（这里要注意问题的dictionary和DA是不一样的）。Context encoder则是把单独把问题encode成和Prepending context相同大小的向量，再将两个encoder得到的向量拼接就得到最后的hidden states。最后decode部分仍然沿用lstm+attention的方法。如下图：</p>
<p><img src="media/7.png" alt="7"></p>
<p>文章在Alex Context NLG Dataset数据集上进行了实验，在BLEU/NIST scores和人工评价两方面成绩都得到了一定地提升。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>本文Code: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a><br>Alex Context NLG Dataset: <a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675" target="_blank" rel="external">https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675</a></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于将用户的问题也就是context显式的加入到模型中，相比之前的模型来说，生成的回复会更符合语境。先前的工作旨在将rule-based符号和seq2seq模型结合自动生成回复，本文的改进让一部分context得到保留，使得生成的回复内容更加丰富，从而显得自然不突兀。</p>
<h1 id="Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction"><a href="#Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction" class="headerlink" title="Task Lineages: Dialog State Tracking for Flexible Interaction"></a><a href="http://aclweb.org/anthology/W16-3602" target="_blank" rel="external">Task Lineages: Dialog State Tracking for Flexible Interaction</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Sungjin Lee, Amanda Stent</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Yahoo Research</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>complex interactions in spoken dialog system, Task Lineage-based Dialog State Tracking</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>​如何将复杂的判别式模型来做DST，并且应用于复杂场景对话系统？</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>本文在之前Dialog State Tracking方法的基础上提出了Task Lineage-based Dialog State Tracking（TL—DST）。本模型包括三个组成部分：<br>1、Task Frame Parsing，返回K-best task frame parses， task frame parses结构如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>2、Context Fetching，在不同的phenomena中，根据不同的conversation history返回不同的相关信息。<br>3、Task State Update，可以通过调节context window参数选择使用不同的dialog state tracking方法。  </p>
<p>本文模型（TL-DST）处理流程如下图所示：<br><img src="media/2.png" alt="2"></p>
<p>在t轮，给定句子u，利用task frame parsing生成K-best task frame parses H，给定task frame f，task lineage l， agent output m，利用context features返回相关信息c。</p>
<p>本文在Dialog State Tracking Challenge 的DSTC2和DSTC3数据集上进行了实验，均取得了较baseline好的结果。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>Dialog State Tracking Challenge比赛介绍: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf</a></p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>本文基于DST的方法来处理口语对话系统中的多任务，跨领域，复杂目标的问题，由于缺乏多任务，跨领域，复杂目标的口语对话系统的数据集，本文实验在DSTC2和DSTC3上进行， 并取得了比baseline好的效果。将来的工作是要将TL-DST方法应用于真实环境中的多领域对话评估。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对话系统(Dialogue Systems)是当前工业界最热门的方向之一，去掉语音部分，该问题退化为聊天机器人(chatbot)问题，两者虽然在输入处理中存在一定的差异，但自然语言理解、对话管理和自然语言生成等核心部件都是一样的，面临的很多问题都是共同的，所以相关的研究或多或少都会有参考意义。上下文(context)的理解和处理是一个重要的环节，直接决定了该bot是智能还是智障，挺多的paper都是针对这一问题进行研究的，但在实际应用当中，context的处理仍然不尽如人意，过多依赖人工设置，更像是一种触发开关，存在大量的if…else…。</p>
<p>seq2seq生成式的解决方案初见效果，但离真正应用还有很长的路要走，template-based和rule-based仍是主流解决方案，尤其是在面向具体任务的bot情景中。那么，直接生成回答很难的话，退一步来想这个问题，能否将seq2seq用在template或者rule的自动生成上？能否将paper中多信息融合（比如：user profile、dialogue context）的成果应用在当前bot的某一个阶段？能否训练一个bot simulator来丰富训练数据？每一篇paper都会有一些创新点，可能有的创新点是为了创新而创新，但总归会带来一定的思考和借鉴，尤其是针对某一个细节问题，我想这是paper对于工业界的参考意义，而不是说从paper中完全抠出一个成熟的解决方案来套，甚至把dataset和code都release出来，典型的“拿来主义”。</p>
<p>以上为本期Paperweekly的主要内容，感谢lshowway、zhangjun、zhangboyu和suhui四位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;SIGDIAL是ACL所属的关于对话系统的兴趣小组，SIG的文章针对性比较强，但文章的质量良莠不齐，本期给大家精心挑选了4篇SIGDIAL 
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.09.26-2016.09.30</title>
    <link href="http://rsarxiv.github.io/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/"/>
    <id>http://rsarxiv.github.io/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/</id>
    <published>2016-09-30T23:11:04.000Z</published>
    <updated>2016-10-01T01:23:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读（偏学术）"><a href="#一周值得读（偏学术）" class="headerlink" title="一周值得读（偏学术）"></a>一周值得读（偏学术）</h1><h2 id="HyperNetworks"><a href="#HyperNetworks" class="headerlink" title="HyperNetworks"></a><a href="https://arxiv.org/pdf/1609.09106v1.pdf" target="_blank" rel="external">HyperNetworks</a></h2><p>an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. 工作来自Google Brain。介绍HyperNetworks的博客：<a href="http://blog.otoro.net/2016/09/28/hyper-networks/" target="_blank" rel="external">http://blog.otoro.net/2016/09/28/hyper-networks/</a></p>
<h2 id="Incorporating-Relation-Paths-in-Neural-Relation-Extraction"><a href="#Incorporating-Relation-Paths-in-Neural-Relation-Extraction" class="headerlink" title="Incorporating Relation Paths in Neural Relation Extraction"></a><a href="https://arxiv.org/pdf/1609.07479v1.pdf" target="_blank" rel="external">Incorporating Relation Paths in Neural Relation Extraction</a></h2><p>本文研究内容为实体关系抽取，传统方法往往只利用同时包含两个目标实体的句子，而忽略包含单目标实体的句子，本文针对这一问题，在俩目标实体之间构建了一个用于推理的中间实体，并提出一种基于路径的关系抽取模型，实验结果表明该模型很好地利用了包含单目标实体的句子信息。本工作来自于刘知远老师组里。</p>
<h2 id="Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression"><a href="#Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression" class="headerlink" title="Language as a Latent Variable: Discrete Generative Models for Sentence Compression"></a><a href="https://arxiv.org/pdf/1609.07317v1.pdf" target="_blank" rel="external">Language as a Latent Variable: Discrete Generative Models for Sentence Compression</a></h2><p>本文研究内容为句子压缩，作者提出了一种VAE模型，先根据背景语言模型生成一个latent摘要句子，然后根据latent句子生成目标句子。实验中用到了抽取式和摘要式两种监督方法，并在最后探索出半监督方法的效果可能会好于监督学习的方法。句子压缩任务可以看做是sentence-level的文本摘要任务，本文的方法同样可以启发文本摘要任务的研究。本文工作来自deepmind，并且是EMNLP 2016 Accepted。</p>
<h2 id="Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems"><a href="#Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems" class="headerlink" title="Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems"></a><a href="https://arxiv.org/pdf/1609.07197v1.pdf" target="_blank" rel="external">Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems</a></h2><p>本文研究的内容很有意思，是algebra word problems，是自动求解代数问题的基础，这个问题可以等同为一个semantic parsing的问题，模型通过读入一段文本，理解其意思，然后构造出一个方程，最后给出方程的解。作者还给出了一个新的dataset和评价标准，本文工作来自伊大香槟分校和微软研究院。这个task本身非常有意思，也很有难度。</p>
<h2 id="Online-Segment-to-Segment-Neural-Transduction"><a href="#Online-Segment-to-Segment-Neural-Transduction" class="headerlink" title="Online Segment to Segment Neural Transduction"></a><a href="https://arxiv.org/pdf/1609.08194v1.pdf" target="_blank" rel="external">Online Segment to Segment Neural Transduction</a></h2><p>本文针对之前encoder-decoder模型面临的一个瓶颈，即将输入全部读入并保存为一个固定大小的hidden states，作者提出了一种新的attention机制，将attention权重作为一种隐变量，在句子摘要上证明了效果，本文工作来自deepmind。</p>
<h1 id="一周值得读（偏应用）"><a href="#一周值得读（偏应用）" class="headerlink" title="一周值得读（偏应用）"></a>一周值得读（偏应用）</h1><h2 id="Google’s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation"><a href="#Google’s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation" class="headerlink" title="Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"></a><a href="https://arxiv.org/pdf/1609.08144.pdf" target="_blank" rel="external">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a></h2><p>本周最受关注，也备受争议的一篇paper，Google放出了他们最新一代的机器翻译系统，一种神经网络翻译系统。指标上的提升，说明了效果确实有提升，但不代表具体到每一句话都能令人满意。</p>
<h2 id="UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS"><a href="#UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS" class="headerlink" title="UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS"></a><a href="https://arxiv.org/pdf/1609.08524v1.pdf" target="_blank" rel="external">UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS</a></h2><p>本文给出了一个Ubuntu系统问题咨询和错误排查的bot，可以在bash terminal中运行，通过增强学习进行训练，可以回答一些基本的问题和错误排查。demo bot被封装成一个python package，即插即用。回答问题的数据来自于Ask Ubuntu。测试了DQN在特定领域bot中的效果，定义了几组简单的命令作为action，open/close，install/remove等等，technical support是客户服务中难度非常大的一类，本文尝试了用一种完全端到端+增强学习的方案来探索解决此类问题。</p>
<h2 id="Character-Sequence-Models-for-ColorfulWords"><a href="#Character-Sequence-Models-for-ColorfulWords" class="headerlink" title="Character Sequence Models for ColorfulWords"></a><a href="https://arxiv.org/pdf/1609.08777v1.pdf" target="_blank" rel="external">Character Sequence Models for ColorfulWords</a></h2><p>本文研究的内容非常有意思，输入一个word，输出这个word对应的color并着色。作者构建了一组大型的color-name对数据集，来做一个color图灵测试。该系统的demo地址：<a href="http://colorlab.us./" target="_blank" rel="external">http://colorlab.us./</a></p>
<h2 id="Equation-Parsing-Mapping-Sentences-to-Grounded-Equations"><a href="#Equation-Parsing-Mapping-Sentences-to-Grounded-Equations" class="headerlink" title="Equation Parsing: Mapping Sentences to Grounded Equations"></a><a href="https://arxiv.org/pdf/1609.08824v1.pdf" target="_blank" rel="external">Equation Parsing: Mapping Sentences to Grounded Equations</a></h2><p>本文研究的内容非常有趣也很有实际意义，即从文本中抽取出数学关系，作者将该任务定义如下：给定一句话，抽取出其中的变量和数学关系，并用方程表示。这个研究可以被应用在新闻机器人上，财经、体育等。</p>
<h2 id="Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks"><a href="#Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks" class="headerlink" title="Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1609.09382v1.pdf" target="_blank" rel="external">Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks</a></h2><p>资源稀缺语言的标注问题是一个经典的问题，一般的做法是将资源丰富的语音对齐映射过去进行标注，自动词对齐的错误会影响最终的效果。本文针对这个问题，提出了一种BiRNN模型，并且融合外部信息解决问题。该模型具有以下特点：1、不需要词对齐信息；2、不限定语言，可用于多种资源少的语言；3、提供一种真正的多语言tagger。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="THULAC"><a href="#THULAC" class="headerlink" title="THULAC"></a><a href="https://github.com/thunlp/THULAC.so" target="_blank" rel="external">THULAC</a></h2><p>THULAC.so：一个高效的中文词法分析工具包，为了满足Python下分词对速度的要求，发布了一个产生.so文件的THULAC版本，并且提供Python调用的示例代码。这样THULAC在Python下的分词速度得到大幅度提高。</p>
<h2 id="tinyflow"><a href="#tinyflow" class="headerlink" title="tinyflow"></a><a href="https://github.com/tqchen/tinyflow" target="_blank" rel="external">tinyflow</a></h2><p>DMLC陈天奇开放了一个两千行代码的样例项目，教你如何从头开始打造一个和TensorFlow一样API的深度学习系统。其中涉及到一个非常重要的开源库NNVM，地址： <a href="https://github.com/dmlc/nnvm" target="_blank" rel="external">https://github.com/dmlc/nnvm</a> 。博客介绍：<a href="http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html" target="_blank" rel="external">http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html</a> ，中文版：<a href="http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0" target="_blank" rel="external">http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0</a></p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/paperweekly" target="_blank" rel="external">http://weibo.com/u/paperweekly</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读（偏学术）&quot;&gt;&lt;a href=&quot;#一周值得读（偏学术）&quot; class=&quot;headerlink&quot; title=&quot;一周值得读（偏学术）&quot;&gt;&lt;/a&gt;一周值得读（偏学术）&lt;/h1&gt;&lt;h2 id=&quot;HyperNetworks&quot;&gt;&lt;a href=&quot;#HyperNet
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第七期</title>
    <link href="http://rsarxiv.github.io/2016/09/29/PaperWeekly-%E7%AC%AC%E4%B8%83%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/09/29/PaperWeekly-第七期/</id>
    <published>2016-09-30T00:58:47.000Z</published>
    <updated>2016-09-30T01:57:39.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不断改进seq2seq模型，包括引入注意力模型、使用外部记忆机制、使用半监督学习和修改训练准则等方法，在短短2年时间内使得NMT的性能超过了传统的基于词组的机器翻译方法。在27号谷歌宣布推出谷歌神经网络机器翻译系统，实现了NMT的首个商业化部署，使得NMT真正从高校实验室走向了实际应用。本期Paperweekly的主题是神经网络机器翻译下的字符级方法，主要用来解决NMT中的out-of-vocabulary词问题，分别是：</p>
<ol>
<li>A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation，2016</li>
<li>Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models，2016</li>
<li>Character-based Neural Machine Translation，Costa-Jussa, 2016</li>
<li>Character-based Neural Machine Translation，Ling, 2016</li>
<li>Neural Machine Translation of Rare Words with Subword Units，2016</li>
</ol>
<h1 id="A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation"><a href="#A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation" class="headerlink" title="A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation"></a><a href="https://arxiv.org/abs/1603.06147" target="_blank" rel="external">A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Junyoung Chung, Kyunghyun Cho, Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Universite de Montreal</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Segmentation, Character-level, Bi-scale recurrent network</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>能否在不需要分词的前提下直接在字符级进行神经机器翻译。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>在讲模型之前，本文花了大量篇幅论证为何需要在不分词的前提下进行字符级翻译，首先作者总结了词级翻译的缺点。</p>
<p>词级翻译的缺点包括：</p>
<ol>
<li>任何一个语言都没有完美的分词算法，完美的分词算法应该能够将任意句子划分为lexemes和morphemes组成的序列</li>
<li>导致的问题就是在词典中经常充斥着许多共享一个lexeme但有着不同morphology的词，比如run,runs,ran,running可能都存在于词典中，每个词都对应一个词向量，但是它们明显共享相同的lexeme——run</li>
<li>存在unknown word问题和rare word问题，rare word问题是指某些词典中词在训练集中出现次数过少，导致无法训练得到很好的词向量；unknown word问题是指不在词典中的词被标记为UNK（OOV词）</li>
</ol>
<p>接着作者指出使用字符集翻译可以解决上述问题：</p>
<ol>
<li>使用LSTM或GRU可以解决长时依赖问题</li>
<li>使用字符级建模可以避免许多词态变形词出现在词典中</li>
</ol>
<p>然而上述字符级方法依然需要进行分词，然后对每个词的字符序列进行编码，因此引出了本文的motivation，即是否能直接在不分词的字符序列上进行翻译。</p>
<p>本文使用的模型同样是经典的seq2seq模型，其创新点主要在decoder端，引入了一种新的网络结构biscale RNN，来捕获字符和词两个timescale上的信息。具体来说，主要分为faster层和slower层，faster层的gated激活值取决于上一步的faster和slower层的激活值，faster层要想影响slower层，则必须要是faster层处理完当前数据，并且进行重置。换句话说，slower层无法接受faster层输入，直到faster层处理完其数据，因此比faster层要慢，而这样的层次结构也对应字符和词在timescale上的关系。下图为网络结构示意图。</p>
<p> <img src="media/1-figure1.png" alt="1-figure1"></p>
<p>在4种语言翻译任务上的实验显示完全可以在不分词的情况下进行字符级翻译，性能优于state-of-the-art的非神经翻译系统</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Sennrich ACL2016提出使用BPE算法对subword建模。Kim AAAI2016中提出直接对字符进行encode，Costa-jussa ICLR2016中将该模型用在了NMT任务中。Ling ICLR2016的工作中使用Bi-RNN来编码字符序列。以上工作基于字符级展开，但它们都依赖于知道如何将字符分为词，即分词。本文研究能否在不分词的情况下进行字符级翻译。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文是Bengio组工作，Bi-scale RNN受启发于该组之前提出的GF-RNN，本文创新点主要是提出了一种新的RNN结构，可以在字符和词两个timescales上进行处理，输出字符序列不需要进行分词。不足是未考虑encoder端是否也可以直接使用未分词的字符序列，而是仅仅使用了分词后的BPE序列。</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="https://arxiv.org/pdf/1604.00788v2.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Minh-Thang Luong and Christopher D. Manning</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Stanford University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>OOV, hybrid word-character models, NMT</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>机器翻译里面的OOV问题, 如何处理UNK</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>提出了一种混合word-character的NMT模型.在训练难度和复杂度不是很高的情况下,同时解决源语言和目标语言的OOV问题.<br><img src="media/2-1.png" alt="2-1"></p>
<p>这个图表达了模型的整体思路. 大多数情况下,模型在word-level进行translation. 当出现unk的时候,则会启用character-level的模型. 对source unk, 由character-level模型来得到它的representation; 对target unk, 用character-level模型来产生word.</p>
<ol>
<li>整体上采用他们组以前提出的基于global attention的encoder-decoder模型. RNN采用的是deep LSTM. </li>
<li>源语言端和目标语言端的character-level模型都是基于character的deep LSTM. 对源语言端来说, 它的character-level模型是context independent的. 隐层状态全部初始化为0, 因此在训练时可以预先计算mini-batch里的每一个rare word的representation. 而对于目标语言端来说, 它的character-level模型是context dependent的.它的第一层的hidden state要根据当前context来初始化, 其它部分都初始化为0.训练时, 在目标语言的decoder阶段, 首先用word-level的decoder产生句子, 这时句子里包含了一些unk. 接着对这些unk, 用character-level模型以batch mode来产生rare word.</li>
<li>对于目标语言端character-level模型的初始化问题, 作者提出了两种方法来表示当前的context. 一种叫做same-path, 用预测<unk>的softmax层之前的ht来表达. 但是因为ht是用来预测<unk>的, 所以所有ht的值都会比较相似,这样很难用来产生不同的目标rare word. 因此作者提出了第二种表达叫做separate-path, 用ht’来表达context. ht’不用预测unk, 是专门作为context在character-level的输入的. 它的计算方法和ht’相同,只是用了一个不一样的矩阵.</unk></unk></li>
<li>模型训练的目标函数是cross-entropy loss, 同时考虑了word level和character level的loss. </li>
</ol>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>NMT的模型分为word-level和character-level的. 对于word-level模型,要解决OOV问题, 之前的工作提出了unk replacement(Luong et al. 2015b), 使用大字典并在softmax时进行采样(Jean et al. 2015), 对unk进行Huffman编码(Chitnis et al. 2015)等方法. 而对于character-level的模型, 本身可以处理OOV词, 但是训练难度和复杂度会增加.</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文的创新之处在于提出了混合word-character model的NMT模型. 这个混合模型结合了二者的优点, 在保证模型复杂度较低的同时,实现了很好的效果.因为加入了character, 特别适合单词有丰富变形的语言. </p>
<h1 id="Character-based-Neural-Machine-Translation"><a href="#Character-based-Neural-Machine-Translation" class="headerlink" title="Character-based Neural Machine Translation"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">Character-based Neural Machine Translation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Marta R. Costa-jussa and Jose A. R. Fonollosa </p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>TALP Research Center<br>Universitat Politecnica de Catalunya, Barcelona</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NMT，character-based word embeddings，CNN</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>本文提出使用character-based word embeddings的NMT，可以在一定程度上克服机器翻译中OOV问题。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p><img src="media/3-encoder_decoder.png" alt="3-encoder_decode"></p>
<p>如上图所示，这篇论文使用的基本模型架构是一个带attention机制的seq2seq的encoder-decoder的架构，使用的神经网络单元是GRU。encoder把源句子转化成一个向量（双向），使用attention的机制来捕获context信息，decoder把context解码成目标句子。网络的输入仍然使用word embedding，但是作者在获取word embedding的时候使用的方法不同。本文是基于词中的character来生成word embedding的，具体方法如下图所示。<br><img src="media/3-embedding.png" alt="3-embedding"></p>
<p>上图中，最底层是一个character-based embedding组成的序列，对应的是每个词中的字母。然后这个序列被送入一个由不同长度的一维卷积过滤器组成的集合中进行处理，不同的长度对应单词中不同数量的字母（从1到7）。对于每个卷积过滤器，只取最大的值作为输出。然后把每个卷积过滤器输出的最大值连接起来组成一个向量。最后这个向量再通过两层Highway layer的处理作为最终的word embeddings。这个方法的详细信息可以参考Kim的论文<a href="http://arxiv.org/abs/1508.06615" target="_blank" rel="external">Character-Aware Neural Language Models</a>(2016)。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><ol>
<li>本文数据集[German-English WMT data] (<a href="http://www.statmt.org/wmt15/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt15/translation-task.html</a>) <br></li>
<li>建立对比模型使用的软件包<a href="http://dl4mt.computing.dcu.ie/" target="_blank" rel="external">DL4MT</a> </li>
</ol>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）2003年，基于短语的统计机器翻译模型。Statistical Phrase-Based Translation <br><br>（2）2013年，基于神经网络的机器翻译模型。Recurrent continuous translation models <br><br>（3）2014年，seq2seq的神经网络模型用于机器翻译。Sequence to sequence learning with neural networks </p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文作者将基于character来产生word embedding的方法应用于机器翻译，可以在一定程度上克服OOV的问题。同时，由于利用了单词内部的信息，这篇论文提出的方法对于词形变化丰富的语言的翻译也产生了更好的效果。但是，作者只是在source side使用了上述方法，对于target side，仍然面临词典大小的限制。</p>
<h1 id="CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION"><a href="#CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION" class="headerlink" title="CHARACTER-BASED NEURAL MACHINE TRANSLATION"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">CHARACTER-BASED NEURAL MACHINE TRANSLATION</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者:"></a>作者:</h2><p>Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><ol>
<li>LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal</li>
<li>Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA</li>
</ol>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>NMT, Character-Based</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>尝试在字符级别上应用神经机器学习方法</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>在带注意力机制的神经机器学习模型的前后端增加字符到词（C2W)和词向量到字符（V2C）的模块。</p>
<p><img src="media/4-C2W.png" alt="4-C2"></p>
<p>图中，小矩形是一个双向LSTM，双向LSTM的前向和后向的最终状态以及bias之和为词的向量表示。</p>
<p><img src="media/4-V2C-1.png" alt="4-V2"></p>
<p>这个模块主要由三个步骤组成：</p>
<ol>
<li>将字符转换为向量表示。</li>
<li>将字符向量和之前模型产生注意力向量的a和目标词在前向LSTM中产生的向量表示做拼接并输入到LSTM。</li>
<li>将得到的向量输入到softmax层得到结果。</li>
</ol>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><ol>
<li>Neural machine translation by jointly learning to align and translate. </li>
</ol>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>这篇文章在基于注意力机制的机器翻译模型上增加了两个模块。由于是基于字符集别的模型，该模型自然可以学得一些语言中的前后缀在翻译中的关系。此外，基于字符级别的模型在翻译未知词时有灵活性。可是，文中也提到，该模型为能够准确的翻译未知词。并且该文也没有明确表明该模型和其他模型相比具有哪些明显的优势。从实际上来说，该模型在V2C部分的训练速度慢是一个很大的弱点，因此若仅根据文章的表述，该模型的实际应用价值应该有限。</p>
<h1 id="Neural-Machine-Translation-of-Rare-Words-with-Subword-Units"><a href="#Neural-Machine-Translation-of-Rare-Words-with-Subword-Units" class="headerlink" title="Neural Machine Translation of Rare Words with Subword Units"></a><a href="https://arxiv.org/abs/1508.07909" target="_blank" rel="external">Neural Machine Translation of Rare Words with Subword Units</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p>Rico Sennrich and Barry Haddow and Alexandra Birch</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>School of Informatics, University of Edinburgh</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>NMT;Rare Words;Subword Units;BPE</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>NMT中的OOV（集外词）和罕见词（Rare Words）问题通常用back-off 词典的方式来解决，本文尝试用一种更简单有效的方式（Subword Units）来表示开放词表。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>本文从命名实体、同根词、外来语、组合词（罕见词有相当大比例是上述几种）的翻译策略中得到启发，认为把这些罕见词拆分为“子词单元”(subword units)的组合，可以有效的缓解NMT的OOV和罕见词翻译的问题。<br>子词单元的拆分策略，则是借鉴了一种数据压缩算法：Byte Pair Encoding(BPE)(Gage,1994)算法。该算法的操作过程和示例如Figure1所示。<br><img src="media/5-Fig1.jpg" alt="5-Fig1"></p>
<p>不同于(Chitnis and DeNero,2015)提出的霍夫曼编码，这里的压缩算法不是针对于词做变长编码，而是对于子词来操作。这样，即使是训练语料里未见过的新词，也可以通过子词的拼接来生成翻译。<br>本文还探讨了BPE的两种编码方式：一种是源语言词汇和目标语言词汇分别编码，另一种是双语词汇联合编码。前者的优势是让词表和文本的表示更紧凑，后者则可以尽可能保证原文和译文的子词切分方式统一。从实验结果来看，在音译或简单复制较多的情形下（比如英德）翻译，联合编码的效果更佳。<br>实验结果分别在WMT15英德和英俄的任务上得到1.1和1.3个BLEU值的提升。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>本文提出的子词拆分算法代码在 <a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="external">https://github.com/rsennrich/subword-nmt</a><br>实验所用的NMT系统为Groundhog: github.com/sebastien-j/LV_groundhog<br>实验数据来自WMT 2015</p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>OOV的处理一直是机器翻译研究的重点。<br>基于字符的翻译在短语SMT模型中就已被提出，并在紧密相关的语种对上验证是成功的(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)。  此外还有各种形态素切分方法应用于短语模型，(Nießen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)。<br>对于NMT，也有很多基于字符或形态素的方法用于生成定长连续词向量(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)。与本文类似的一项工作 (Ling et al., 2015b)发现在基于词的方法上没有明显提升。其与本文的一个区别在于，attention机制仍然在词层级进行操作，而本文在子词层级上。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>这篇文章的创新点在于提出了一种介乎字符和单词之间，也不同于字符n-gram的文本表示单元，并借鉴BPE压缩算法，在词表大小和文本长度两个方面取得一个较为平衡的状态。应用在非同源/近源的语言对（如英汉）是否可以有类似的效果，尚待研究。在NMT模型的优化上，也还有探讨的空间。<br>本文的实验评价方法值得学习，单看BLEU值并不觉得有惊艳之处，但加上CHR F3和(对所有词、罕见词和集外词分别统计的)unigram F1这两个评价指标，尤其是Figure2和3画出来的效果，还是让人比较信服的。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>OOV词对于翻译性能和实用性的影响非常巨大，如何处理OOV词并达到open vocabulary一直是NMT的主要研究方向。传统方法基于单词级别来处理该问题，比如使用UNK替换、扩大词典规模等方法，往往治标不治本。因此最近一些研究者提出基于字符的NMT模型，取得了不错的成绩，字符级方法的主要优势包括不受语言的形态变化、能预测出词典中未出现的单词并降低词典大小等。值得一提的是，基于字符的模型不仅局限于NMT上，任何生成模型都面临OOV词问题，因此是否能够将字符级方法用在其他NLP任务，比如阅读理解或文本摘要上，让我们拭目以待。</p>
<p>以上为本期Paperweekly的主要内容，感谢EdwardHux、Mygod9、Jaylee1992、Susie和AllenCai五位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.09.19-2016.09.23</title>
    <link href="http://rsarxiv.github.io/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/"/>
    <id>http://rsarxiv.github.io/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/</id>
    <published>2016-09-24T16:57:50.000Z</published>
    <updated>2016-09-24T17:53:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence"><a href="#Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence" class="headerlink" title="Long-Term Trends in the Public Perception of Artificial Intelligence"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" target="_blank" rel="external">Long-Term Trends in the Public Perception of Artificial Intelligence</a></h2><p>本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。</p>
<h2 id="Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary"><a href="#Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary" class="headerlink" title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction beyond the Sentence Boundary</a></h2><p>本文研究的问题是非结构化文本中的关系抽取问题，针对传统方法在抽取关系时仅限于单个句子，本文提出了一种新的方法，从多个句子中进行关系抽取。</p>
<h2 id="What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler"><a href="#What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler" class="headerlink" title="What You Get Is What You See: A Visual Markup Decompiler"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" target="_blank" rel="external">What You Get Is What You See: A Visual Markup Decompiler</a></h2><p>【转发较多】本文研究的问题是如何从web页面中生成html代码，以及如何从公式图片中生成latex代码，为此作者构造了两个相关的大型数据集，用了完全数据驱动的端到端训练方法得到了不错的效果。本文工作来自Harvard。</p>
<p>Demo|Dataset|Code: <a href="http://lstm.seas.harvard.edu/latex/" target="_blank" rel="external">http://lstm.seas.harvard.edu/latex/</a></p>
<h2 id="Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis"><a href="#Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis" class="headerlink" title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" target="_blank" rel="external">Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis</a></h2><p>本文研究的内容是多模态情感分析，针对当前相关高质量数据集规模太小造成的情感依赖于个体特征的问题，提出了一种Select-Additive学习方法提高通用性。 </p>
<h2 id="Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning"><a href="#Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning" class="headerlink" title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" target="_blank" rel="external">Interactive Spoken Content Retrieval by Deep Reinforcement Learning</a></h2><p>本文研究的内容是DQN算法来做语音内容检索，通过人机交互来完成内容检索。DQN相比传统的RL模型明显的优势在于不依赖hand-crafted features。本文被Interspeech 2016录用。</p>
<h2 id="Graph-Structured-Representations-for-Visual-Question-Answering"><a href="#Graph-Structured-Representations-for-Visual-Question-Answering" class="headerlink" title="Graph-Structured Representations for Visual Question Answering"></a><a href="http://arxiv.org/pdf/1609.05600v1.pdf" target="_blank" rel="external">Graph-Structured Representations for Visual Question Answering</a></h2><p>本文研究内容为VQA，VQA的主要挑战在于对visual和text两个领域都需要理解。传统的模型中常常忽略场景中的结构和问题中的语言结构，本文针对这两个问题提出了一种图模型，取得了不错的效果。</p>
<h2 id="Context-aware-Sequential-Recommendation"><a href="#Context-aware-Sequential-Recommendation" class="headerlink" title="Context-aware Sequential Recommendation"></a><a href="http://arxiv.org/pdf/1609.05787v1.pdf" target="_blank" rel="external">Context-aware Sequential Recommendation</a></h2><p>用户行为建模是推荐系统中的一个关键部件，行为数据是序列数据，天然适合用RNN来建模。但实际应用中context信息(time,location,weahter)也很重要，本文针对这个问题提出了一种CA-RNN模型将context考虑在内，取得了不错效果。</p>
<h2 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h2><p>本文研究内容为机器阅读理解，之前效果不错的方法大多数停留在有限的几轮reasoning，本文用增强学习来动态地决定是否继续读下去或者停下来进行答案选择。本文工作来自微软研究院。</p>
<h2 id="Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference"><a href="#Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference" class="headerlink" title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" target="_blank" rel="external">Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference</a></h2><p>本文研究内容为自然语言推理，作者认为LSTM类的模型潜力并没有被充分挖掘，基于此，本文在传统LSTM模型的基础上增加了syntactic parse信息，得到了更好的效果。</p>
<h2 id="A-framework-for-mining-process-models-from-emails-logs"><a href="#A-framework-for-mining-process-models-from-emails-logs" class="headerlink" title="A framework for mining process models from emails logs"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" target="_blank" rel="external">A framework for mining process models from emails logs</a></h2><p>本文研究的内容是邮件日志的挖掘，作者提出了一种无监督的挖掘方法，并且提出了一种半自动化的邮件标注方法。</p>
<h2 id="Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution"><a href="#Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution" class="headerlink" title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" target="_blank" rel="external">Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution</a></h2><p>本文研究内容为authorship attribution，是一个典型的多分类任务。作者利用字符级别的多通道CNN模型对大规模dataset进行了建模，取得了不错的结果。作者之一来自aylien.com 公司，一家非常出色的NLP SaaS 公司。</p>
<h2 id="Minimally-Supervised-Written-to-Spoken-Text-Normalization"><a href="#Minimally-Supervised-Written-to-Spoken-Text-Normalization" class="headerlink" title="Minimally Supervised Written-to-Spoken Text Normalization"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" target="_blank" rel="external">Minimally Supervised Written-to-Spoken Text Normalization</a></h2><p>本文研究的内容是特定语言领域知识在构建text normalization system的时候应该如何做trade-off，本文作者来自Google。</p>
<h2 id="Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention"><a href="#Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention" class="headerlink" title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" target="_blank" rel="external">Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention</a></h2><p>本文研究内容是如何识别隐式的discourse关系，作者提出了一种多层注意力模型，联合注意力机制和外部memory来做关系识别。本文是EMNLP2016的长文。</p>
<h2 id="SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks"><a href="#SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks" class="headerlink" title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" target="_blank" rel="external">SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</a></h2><p>【转发较多】本文提出了一种新的正则化方法，通过在训练过程中调整label来实现，达到了和Dropout接近的效果。</p>
<h2 id="The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA"><a href="#The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA" class="headerlink" title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" target="_blank" rel="external">The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)</a></h2><p>本文提出了一个1 million的Visual Question Answer Dataset，数据地址：<a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" target="_blank" rel="external">http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/</a></p>
<h2 id="Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs"><a href="#Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs" class="headerlink" title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"></a><a href="http://arxiv.org/pdf/1609.07075v1.pdf" target="_blank" rel="external">Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs</a></h2><p>【转发较多】当前知识表示存在两个挑战：1、如何更好地利用entity的context；2、如何发现与entity相关的句子；针对这两个问题，本文提出了一种从多个句子中学习表示的模型。给定每个entity的参考句子，首先用带池化的RNN或LSTM来encode与该entity相关的句子，然后用attention模型来衡量每个句子的信息量，最后得到entity的表示。模型在triple classification和link prediction两个任务上都取得了满意的结果。本文工作来自@刘知远THU组。</p>
<p>刘知远：我觉得这个工作的最有意思的地方是，能够为实体找到最有信息量的句子，这些句子往往是该实体的定义或描述。这样，在构建知识图谱时，我们就可以自动为新增的实体构建对应的文本描述信息了。</p>
<h2 id="Semantic-Tagging-with-Deep-Residual-Networks"><a href="#Semantic-Tagging-with-Deep-Residual-Networks" class="headerlink" title="Semantic Tagging with Deep Residual Networks"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" target="_blank" rel="external">Semantic Tagging with Deep Residual Networks</a></h2><p>本文提出一种多语言智能tagger，模型采用了char-level和word-level的深度残差网络，在词性标注任务中取得了不错的效果，本文COLING 2016在审。</p>
<h2 id="Image-embodied-Knowledge-Representation-Learning"><a href="#Image-embodied-Knowledge-Representation-Learning" class="headerlink" title="Image-embodied Knowledge Representation Learning"></a><a href="http://arxiv.org/pdf/1609.07028v1.pdf" target="_blank" rel="external">Image-embodied Knowledge Representation Learning</a></h2><p>【转发较多】entity图像中包含丰富的信息，大多数传统方法并没有利用这一点，本文提出了一种知识表示模型，利用了triples和image信息，并在知识图谱补全和triple分类两个任务中取得了不错的效果。本文是一篇典型的多信息融合的文章，非常值得思考！工作同样来自@刘知远THU老师组。</p>
<h2 id="Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling"><a href="#Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling" class="headerlink" title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" target="_blank" rel="external">Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling</a></h2><p>推特上的推对于topic建模有以下缺点：1、短；2、非结构化；3、口语化；也有优点：1、作者；2、hashtags；3、粉丝网络。本文结合推特信息的优点提出了一种新模型。topic model是个老话题了，多源信息的融合是突破研究瓶颈一个不错的方向，本文的方法同样可借鉴于微博和其他社交网络。</p>
<h2 id="Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning"><a href="#Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning" class="headerlink" title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" target="_blank" rel="external">Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning</a></h2><p>【转发较多】Attention类模型在端到端语音识别领域取得了不错的效果，但当输入噪声非常大的的时候，识别长句子效果不是很好。CTC是另外一种不错的端到端模型，本文结合两者的优势构建模型。构建了联合模型之后，克服了之前的问题。大家都在用Attention，都说Attention好，但终究还是有些情境下attention并不能如人意。那么问题来了，到底哪些场景下attention表现不好，原因是什么？想清楚这个到底之后，改进的方法大概也就在路上了。#Attention Model的缺点#</p>
<h1 id="资源分享"><a href="#资源分享" class="headerlink" title="资源分享"></a>资源分享</h1><h2 id="Bots-Product-Hunt"><a href="#Bots-Product-Hunt" class="headerlink" title="Bots - Product Hunt"></a><a href="https://www.producthunt.com/topics/bots" target="_blank" rel="external">Bots - Product Hunt</a></h2><p>一个分享和点评各种好玩product的站点，其中一个栏目有各种各样的bot。</p>
<h2 id="Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go"><a href="#Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go" class="headerlink" title="Gorgonia is a library that helps facilitate machine learning in Go"></a><a href="https://github.com/chewxy/gorgonia" target="_blank" rel="external">Gorgonia is a library that helps facilitate machine learning in Go</a></h2><p>用Go写的机器学习开源框架。</p>
<h2 id="A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task"><a href="#A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task" class="headerlink" title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"></a><a href="https://github.com/danqi/rc-cnn-dailymail" target="_blank" rel="external">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a></h2><p>这篇paper的代码放出来了，同时包括CNN和Daily Mail的数据集。来自斯坦福Danqi Chen的工作。</p>
<h1 id="业界新闻"><a href="#业界新闻" class="headerlink" title="业界新闻"></a>业界新闻</h1><h2 id="API-AI-is-joining-Google"><a href="#API-AI-is-joining-Google" class="headerlink" title="API.AI is joining Google!"></a><a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" target="_blank" rel="external">API.AI is joining Google!</a></h2><p>chatbot构建平台api.ai被Google收购了</p>
<h2 id="Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch"><a href="#Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch" class="headerlink" title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch "></a><a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" target="_blank" rel="external">Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch </a></h2><p>TechCrunch报道称，继api.ai被google收购之后，一家做自然语言理解的公司angel.ai也几乎被Amazon收购。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一周值得读&quot;&gt;&lt;a href=&quot;#一周值得读&quot; class=&quot;headerlink&quot; title=&quot;一周值得读&quot;&gt;&lt;/a&gt;一周值得读&lt;/h1&gt;&lt;h2 id=&quot;Long-Term-Trends-in-the-Public-Perception-of-Artifici
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第六期</title>
    <link href="http://rsarxiv.github.io/2016/09/22/PaperWeekly-%E7%AC%AC%E5%85%AD%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/09/22/PaperWeekly-第六期/</id>
    <published>2016-09-23T03:51:47.000Z</published>
    <updated>2016-09-23T05:07:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>本期paperweekly的主题是Question Answering Models，解决这一类问题可以很好地展现AI理解人类自然语言的能力，通过解决此类dataset可以给AI理解人类语言很好的insights。问题的定义大致是，给定较长一段话的context和一个较短的问题，以及一些candidate answers，训练一些可以准确预测正确答案的模型。</p>
<p>此问题也存在一些变种，例如context可以是非常大块的knowledge base，可以不提供candidate answers而是在所有的vocabulary中搜索答案，或者是在context中提取答案。</p>
<p>基于(Recurrent) Neural Network的一些模型在这一类问题上给出了state of the art models，本期paperweekly就带领大家欣赏这一领域有趣的工作。</p>
<h1 id="Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="Attention-over-Attention Neural Networks for Reading Comprehension"></a><a href="https://arxiv.org/abs/1607.04423" target="_blank" rel="external">Attention-over-Attention Neural Networks for Reading Comprehension</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu and Guoping Hu</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>iFLYTEK Research, China<br>Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Question Answering, Attentive Readers</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201608</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文优化了attention机制，同时apply question-to-document and document-to-question attention，提升了已有模型在Cloze-Style Question Answering Task上的准确率。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本文解决的是Cloze-style question answering的问题，给定一个Document和一个Query，以及一个list的candidate answers，模型需要给出一个正确答案。</p>
<p>已有的模型大都通过比较每一个Query + candidate answer和context document的相似性来找出正确答案，这种相似性measure大都通过把query 投射到context document每个单词及所在context的相似性来获得。本文的不同之处在于模型还计算了context投射到每个query单词的相似度，进一步丰富了context和query相似度的计算。</p>
<p><img src="media/model_image.png" alt="model_image"></p>
<p>首先，document和query都会被model成biGRU。<br><img src="media/embedding_and_encoding.png" alt="embedding_and_encoding"></p>
<p>然后使用document biGRU和query biGRU的每一个position做inner product计算，可以得到一个similarity matrix。<br><img src="media/similarity_matrix.png" alt="similarity_matrix"></p>
<p>对这个matrix做一个column-wise softmax，可以得到每个query单词在每个document单词上的similarity。<br><img src="media/column_softmax.png" alt="column_softmax"></p>
<p>similarly，对这个matrix做一个row-wise softmax，可以得到每个document单词在每个query单词上的similarity。<br><img src="media/row_softmax.png" alt="row_softmax"></p>
<p>取个平均就得到了每个query单词在整个context document上的similarity。<br><img src="media/average.png" alt="average"></p>
<p>然后把alpha和beta做个inner product就得到了每个context document word的probability。<br><img src="media/context_word_probability.png" alt="context_word_probability"></p>
<p>每个candidate answer的probability就是它出现在上述s中的probability之和。<br><img src="media/attention_sum.png" alt="attention_su"></p>
<p>Loss Function可以定义为正确答案的log probability之和。<br><img src="media/loss_function.png" alt="loss_function"></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">cnn和daily mail datasets</a></li>
<li><a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">Children’s book test</a></li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>利用attentive readers解决question answering问题最早出自deep mind: teaching machines to read and comprehend。后来又有Bhuwan Dhingra: Gated-Attention Readers for Text Comprehension和Danqi Chen: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task，以及其他相关工作，在此不一一赘述。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文很好地完善了attentive reader的工作，同时考虑了query to document and document to query attentions，在几个data set上都取得了state of the art效果，思路非常清晰，在question answering问题上很有参考价值。</p>
<h1 id="MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER"><a href="#MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER" class="headerlink" title="MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Shuohang Wang, Jing Jiang</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Singapore Management University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Machine comprehension, Match-LSTM, Pointer Net</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv，201608</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>提出一种结合match-LSTM和Pointer Net的端到端神经网络结构，来解决SQuAD数据集这类没有候选项且答案可能是多个词的machine comprehension问题。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>本文提出的模型结合了match-LSTM(mLSTM)和Pointer Net(Ptr-Net)两种网络结构。</p>
<p>1、match-LSTM</p>
<p>mLSTM是由Wang和Jiang提出的一种解决文本蕴含识别（RTE）问题的一种神经网络结构。模型结构见下图，该模型首先将premise和hypothesis两句话分别输入到两个LSTM中，用对应LSTM的隐层输出作为premise和hypothesis中每个位置对应上下文信息的一种表示（分别对应图中的Hs和Ht）。对于hypothesis中的某个词的表示ht_i，与premise中的每个词的表示Hs计算得到一个权重向量，然后再对premise中的词表示进行加权求和，得到hti对应的上下文向量a_i（attention过程）。最后把hypothesis中该词的表示ht_i和其对应的context向量a_i拼接在一起，输入到一个新的LSTM中。该模型将两个句子的文本蕴含任务拆分成词和短语级别的蕴含识别，因此可以更好地识别词之间的匹配关系。<br><img src="media/mLSTM.png" alt="mLST"></p>
<p>2、 Pointer networks</p>
<p>该模型与基于attention的生成模型类似。区别之处在于，pointer networks生成的结果都在输入序列中，因此pointer networks可以直接将attention得到的align向量中的每个权重直接作为预测下一个词对应的概率值。</p>
<p>3、 Sequence Model &amp; Boundary Model</p>
<p>本文提出的模型结构见下图，具体到本文的神经网络结构，可以简单分为下面两部分：<br><img src="media/Seq_Bound.png" alt="Seq_Bound"><br>（1）Match-LSTM层：该部分将machine comprehension任务中的question作为premise，而passage作为hypothesis。直接套用上述的mLSTM模型得到关于passage每个位置的一种表示。为了将前后方向的上下文信息全部编码进来，还用相同的方法得到一个反向mLSTM表示，将两个正反方向的表示拼接在一起作为最终passage的表示。</p>
<p>（2）生成答案序列部分，论文中提出了两种生成方法：</p>
<ul>
<li><p>Sequence方法与Pointer Net相同，即根据每一个时刻attention的align向量生成一个词位置，直到生成终止符为止。</p>
</li>
<li><p>Boundary方法则是利用SQuAD数据集的答案均是出现在passage中连续的序列这一特点，该方法仅生成首尾两个位置，依据起始位置和终止位置来截取passage的一部分作为最终的答案。</p>
</li>
</ul>
<p>本文在SQuAD数据集上进行实验，两种方法实验结果较之传统LR方法均有大幅度提升。其中Boundary方法比Sequence方法效果更好。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="external">SQuAD</a></li>
</ul>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>数据集相关论文<br>SQuAD: 100,000+ Questions for Machine Comprehension of Text<br>模型相关论文<br>Learning Natural Language Inference with LSTM<br>Pointer networks</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本篇论文提出的模型是第一个在SQuAD语料上应用端到端神经网络的模型，该模型将Match-LSTM和Pointer Networks结合在一起，利用了文本之间的蕴含关系更好地预测答案。<br>本文提出了两种方法来生成答案，其中Boundary方法巧妙地利用SQuAD数据集的答案均是文本中出现过的连续序列这一特点，只生成答案的起始和终止位置，有效地提升了模型的效果。</p>
<h1 id="Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering"><a href="#Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering" class="headerlink" title="Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"></a><a href="https://arxiv.org/pdf/1607.06275v2.pdf" target="_blank" rel="external">Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Baidu IDL</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Question Answering, Sequence Labeling, CRF</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201609</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>作者给出了一个新的中文的QA数据集, 并且提出了一个非常有意思的baseline model.</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>1、WebQA Dataset</p>
<p>作者来自百度IDL, 他们利用百度知道和一些其他的资源, 构建了这个中文的QA数据集. 这个数据集里所有的问题都是factoid类型的问题, 并且问题的答案都只包含一个entity (但是一个entity可能会包含多个单词). 对于每个问题, 数据集提供了若干个’evidence’, 这些evidence是利用搜索引擎在网络中检索的.</p>
<p>2、Recurrent Sequence Labeling Model</p>
<p>作者把QA类型的问题看做sequence labeling问题, 给出的模型大概分三部分:<br><img src="media/ericyuan_graph.png" alt="ericyuan_graph"></p>
<p>（1）Question LSTM<br>这部分很简单, 就是普通的单向LSTM, 对整个Question sequence进行encoding, 之后计算self-attention, 并用attention对question encoding求加权平均作为问题的representation.</p>
<p>（2）Evidence LSTMs<br>这部分比较有意思, 首先, 作者从数据中提取出两种feature: 每个词是否在question和evidence中共同出现, 以及每个词是否同时在多个evidence中出现. 之后, 模型用一个三层的单向LSTM对evidence/quesiton/feature进行编码. </p>
<ul>
<li>第一层: 将evidence/question representation/feature进行连接, 放进一个正向LSTM.</li>
<li>第二层: 将第一层的结果放入一个反向LSTM.</li>
<li>第三层: 将第一层和第二层的结果进行连接, 放进一个正向LSTM.</li>
</ul>
<p>（3）CRF<br>经过evidence LSTMs, question和evidence的representation已经揉在一起, 所以并不需要其他QA模型(主要是Attention Sum Reader)广泛用的, 用question representation和story representation进行dot product, 求cosine similarity. 这时候只需要对evidence representation的每一个time step进行分类就可以了, 这也是为什么作者将数据标注成IOB tagging的格式, 我们可以直接用一个CRF层对数据进行预测. 在一些实验中, 作者将答案之前的词用O1, 答案之后的词用O2进行标注, 这又给了模型关于非答案词的位置信息(正确答案是在这个词的前面还是后面). </p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="http://idl.baidu.com/webqa.html" target="_blank" rel="external">WebQA dataset</a></li>
<li><a href="https://github.com/baidu/Paddle" target="_blank" rel="external">Baidu Paddle</a></li>
</ul>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li>关于CRF进行序列标注的问题, 可以参考这篇文章.<br>Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv:1508.01991v1.</li>
<li>关于multi-word答案选择在SQuAD dataset上的模型, 可以参考这篇.<br>Shuohang Wang, Jing Jiang. 2016. Machine Comprehension Using Match_LSTM and Answer Pointer. arXiv: 1608.07905v1.</li>
</ul>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>首先对所有release数据集的人表示感谢.<br>关于dataset部分, 百度利用了自己庞大的资源收集数据. 第一, 百度知道里的问题都是人类问的问题, 这一点相比于今年前半年比较流行的CNN/CBT等等cloze style的问题, 要强很多. 第二, 数据集中包含了很多由多个词组成的答案, 这也使数据集的难度大于CNN/CBT这种单个词作为答案的数据. 第三, 对于每个问题, 并没有给出备选答案, 这使得对于答案的搜索空间变大(可以把整个evidence看做是备选答案). 第四, 对于每一个问题, dataset中可能有多个supporting evidence, 这也迎合了最近multi-supporting story的趋势, 因为对于有些问题, 答案并不只在某一个单一的文章中(对于百度来说, 如果搜索一个问题, 那么答案并不一定在单一的搜索结果网页中), 那么一个好的model需要在有限的时间内对尽可能多的搜索结果进行检索. </p>
<p>关于model部分, 本文尝试将QA问题看做是序列标注问题, 某种意义上解决了multiword answer的难点. 熟悉前半年QA paper的人都会对Attention Sum Reader以及延伸出来的诸多模型比较熟悉, 由于用了类似Pointer Network的机制, 一般的模型只能从文中选择story和question的cosine similarity最高的词作为答案, 这使得multiple word answer很难处理, 尤其是当multiple answer word不连续的时候, 更难处理. 而CRF是大家都熟知的简单高效的序列标注工具, 把它做成可训练的, 并且放在end to end模型中, 看起来是非常实用的. 在Evidence LSTM的部分, 加入的两个feature据作者说非常有帮助, 看起来在deep learning 模型中加入一些精心设计的feature, 或者IR的要素, 有可能能够对模型的performance给予一定的提升. 在entropy的角度, 虽然不一定是entropy reduction, 因为这些信息其实本来已经包含在question/evidence中了, 但是有可能因为你提供给模型这些信息, 它就可以把更多精力用在一些其他的特征上?</p>
<p>另外值得一提的是, 最近Singapore Management University的Wang and Jiang也有所突破, 在SQuAD dataset(也是multiple word answer)上一度取得了state of the art的结果, 他们用的mLSTM模型也十分有趣. </p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这一类model都大量使用了Recurrent Neural Network(LSTM或者GRU)对text进行encoding，得到一个sequence的hidden state vector。然后通过inner product或者bilinear term比较不同位置hidden state vector之间的similarity来计算它们是正确答案的可能性。可见Recurrent Neural Network以及对于Similarity的定义依旧是解决此类问题的关键所在，更好地改良这一类模型也是提升准确率的主流方法。笔者认为，similarity的计算给了模型从原文中搜索答案的能力，然而模型非常缺乏的是推理和思考的能力（其实也有相关工作<a href="http://arxiv.org/abs/1508.05508" target="_blank" rel="external">Towards Neural Network-based Reasoning</a>），如果模型能够配备逻辑思考能力，那么解决问题的能力会大大增强。非常期待有新的思路能够出现在这一领域中，令AI能够更好地理解人类语言。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;本期paperweekly的主题是Question Answering Models，解决这一类问题可以很好地展现AI理解人类自然语言的能力，通过解
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>paperweekly用户投票总结</title>
    <link href="http://rsarxiv.github.io/2016/09/17/paperweekly%E7%94%A8%E6%88%B7%E6%8A%95%E7%A5%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://rsarxiv.github.io/2016/09/17/paperweekly用户投票总结/</id>
    <published>2016-09-18T05:05:11.000Z</published>
    <updated>2016-09-18T06:02:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>参与投票131人，远超我个人的预期，证明了发红包是一个非常有效的手段，感谢各位的参与。</p>
<p><img src="media/1.png" alt="1"></p>
<p>从第一个问题的回答来看，群里的童鞋基本上都喜欢读paper，并且大多数一周内可以读1-3篇，更有甚者可以读到6篇以上。关于读paper，以及从最开始做paperweekly，也是受了Ng一次采访内容的启发，他大概的意思是说，每天坚持读篇paper是一种长期投资，坚持做一年、两年之后会有显著地提高。（虽然不确定这话是不是Ng本人说的，但我比较认同这个观点）</p>
<p><img src="media/2.png" alt="2"></p>
<p>第二个问题是关于paper类型的，是一个多选题。群里的童鞋有的是学生，有的是工业界的朋友，有的大厂的工程师，有的是创业公司的大拿，不同的背景决定了导向不同。从结果分布来看，工程性强、热门的paper更受欢迎，这个结果可以也比较好理解，毕竟大众化的东西是更受大家欢迎，工程性强的文章一般来说可操作性都比较强，适合复现，并且可以有选择地应用在生产环境中；热门的文章是大家热议的话题，AlphaGo热炒那会，出门不聊几句增强学习都不好意思和人打招呼，甚至这个PR行为带动了一大批人开始学习下围棋，热门、话题性是是媒体感兴趣的，也是大众喜欢津津乐道的；理论性强的paper通常来说不好读，因为很难，需要很深的基础在那儿，不是一句、两句说得清的，但正是这些理论性强的paper真正地推动着AI在往前走；每个人的兴趣点可能都不是很相同，所以有28个童鞋选择了最后一个选项，也符合小众这个词的特点。</p>
<p>chatbot是当下可能最火的方向之一，但说句实话，10年前paper提出的方法可能在现在的系统中仍然是非常好用的，记得微博上看到过一个人说用正则可以解决大多数的问题，仔细想想rule-based是一个多么神通广大的事情啊。既然rule-based这么好，干嘛还研究那么多新东西、新概念呢？不就是因为人工智能太偏重于人工一词，离智能太远，离智障太近嘛。我一直是这么看待paper这个事儿的，paper针对的可能不是当下的问题，而是未来的问题，但不意味着当下的paper对于当下的问题没有参考和借鉴的意义。paperweekly的一个初衷是希望大家可以通过简单、清晰地描述来看看某一篇或者某几篇paper到底解决了什么问题，用了什么方法，结果如何，当然结果的可信度是另外一回事，但终究是会有启发的。</p>
<p><img src="media/3.png" alt="3"></p>
<p>这个问题少打两个字，但是感觉根据上下文大家应该是理解了我提的问题。我想了解，到底paperweekly写的文章有没有真正地解决了一点点需求，或者给大家带来那么一点点启发。答案告诉了我，确实有，某些细节或者思路确实很有借鉴意义，这件事情值得做。谢谢。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这是一个多选题，初衷是想了解下哪种方式或者哪几种方式可以让交流变得更加高效率。毫无疑问，微信群是最多的答案，说句实话，微信群排第一是因为大家对微信的依赖强，黏性大，bbs排第二，其实bbs是更加好的讨论方式，但是黏性很差，讨论起来操作会麻烦一些，所以我这边有个非常naive的想法，就是想将bbs和微信群打通，群里有几个技术大牛也愿意一起来做这件事情，希望可以有一个方便大家的东西出来。</p>
<p><img src="media/5.png" alt="5"></p>
<p>复现别人paper这个事儿，我个人会选一般有。原因如下：1、首先paper的结果可能没有那么地好，只是说写的或者选的比较好而已；2、paper里的算法不见得适合你的问题；3、paper中的实验在实现过程中可能有很多的trick，并没有写明在paper中，这都是一个又一个的坑啊；4、有些paper有开源的code，可以拿来跑一跑看看效果再说。</p>
<p><img src="media/6.png" alt="6"></p>
<p>这个答案也是我预想之中的，摘要就是为了解决信息过载问题的。群里每天会产生一定数量的消息（不是很多其实），但没有赶上实时聊天的话，很容易错过一些精彩的对话或者干货分享。从这个角度来看，做digest这件事情就显得很有意义了。关于如何做，群里之前也有过不错的讨论，我也尝试标注了下数据，感觉难度不小，现在的想法是，我每天晚上花点时间手工摘要出来，分享在bbs和群里。（日后有机会可以将这个事情自动化）</p>
<p><img src="media/7.png" alt="7"></p>
<p>这个问题的结果基本上和我上面的想法吻合了。</p>
<p><img src="media/8.png" alt="8"></p>
<p>目前paperweekly运营团队里有四个活跃的小组，分别是chatbot、NMT、QA和representation，每个组每周负责出一期文章，包括3-5篇paper，KG这个组建立了，但是一直不够活跃，需要大牛的加入，来写KG方面的文章。</p>
<p>投票的结果和总结基本是这样的情况，投票可能设计的不科学也有些仓促，但基本达到了预期的目的，得到了充分的反馈，这里感谢各位的支持。谢谢大家！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参与投票131人，远超我个人的预期，证明了发红包是一个非常有效的手段，感谢各位的参与。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/1.png&quot; alt=&quot;1&quot;&gt;&lt;/p&gt;
&lt;p&gt;从第一个问题的回答来看，群里的童鞋基本上都喜欢读paper，并且大多数一周内可以读1-3篇，更
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="paperweekly" scheme="http://rsarxiv.github.io/tags/paperweekly/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.09.12-2016.09.16</title>
    <link href="http://rsarxiv.github.io/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/"/>
    <id>http://rsarxiv.github.io/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/</id>
    <published>2016-09-17T04:34:58.000Z</published>
    <updated>2016-09-17T04:49:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>本周（2016.09.12-2016.09.16）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning"><a href="#Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning" class="headerlink" title="Dialogue manager domain adaptation using Gaussian process reinforcement learning"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.02846v1.pdf" target="_blank" rel="external">Dialogue manager domain adaptation using Gaussian process reinforcement learning</a></h1><p>本文是Steve Young组的一篇大作，文中详细介绍了Gaussian process reinforcement learning框架的思路和优势，并且在多个对话领域中进行了实验并得到更好的结果。</p>
<h1 id="A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis"><a href="#A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis" class="headerlink" title="A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.02745v1.pdf" target="_blank" rel="external">A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis</a></h1><p>本文提出用分层双向LSTM模型对网站评论数据进行观点挖掘，发表在EMNLP 2016。该作者今天在arxiv上提交了三篇同类问题不同解决方案的paper，对评论观点和情感挖掘的童鞋可作参考。</p>
<h1 id="Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks"><a href="#Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks" class="headerlink" title="Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03286v1.pdf" target="_blank" rel="external">Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks</a></h1><p>本文提出了用先验知识+attention network的模型，用来解决了自然语言理解存在问题：通过从少量训练数据中捕获重要子结构，来缓解测试集中的unseen data问题，同时提高理解能力。</p>
<h1 id="Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System"><a href="#Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System" class="headerlink" title="Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03193v2.pdf" target="_blank" rel="external">Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</a></h1><p>本文提出了一种语音识别的端到端模型，基于CNN和graph decoding，在不依赖因素对齐的前提下，输出letters。本文工作来自Facebook AI。</p>
<h1 id="Multimodal-Attention-for-Neural-Machine-Translation"><a href="#Multimodal-Attention-for-Neural-Machine-Translation" class="headerlink" title="Multimodal Attention for Neural Machine Translation "></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03976v1.pdf" target="_blank" rel="external">Multimodal Attention for Neural Machine Translation </a></h1><p>本文通过利用image caption的多模态、多语言数据构建了一个NMT模型，模型的输入不仅是source language，还有所描述的图像，输出是target language。通过输入更多的信息，得到了更好的效果。</p>
<h1 id="Joint-Extraction-of-Events-and-Entities-within-a-Document-Context"><a href="#Joint-Extraction-of-Events-and-Entities-within-a-Document-Context" class="headerlink" title="Joint Extraction of Events and Entities within a Document Context"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03632v1.pdf" target="_blank" rel="external">Joint Extraction of Events and Entities within a Document Context</a></h1><p>本文针对传统信息抽取方法将event和entity分开考虑的问题，提出了在docuemnt-level context下考虑event和entity之间关系进行信息抽取的新方法，取得了非常好的结果。本文发表在NAACL2016.</p>
<h1 id="Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks"><a href="#Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks" class="headerlink" title="Character-Level Language Modeling with Hierarchical Recurrent Neural Networks"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.03777v1.pdf" target="_blank" rel="external">Character-Level Language Modeling with Hierarchical Recurrent Neural Networks</a></h1><p>语言模型问题上，char-level可以很好地解决OOV的问题，但效果不如word-level，本文针对该问题提出了一种分层模型，同时兼顾word-level和char-level的优势。本文发表在nips2016。</p>
<h1 id="Neural-Machine-Translation-with-Supervised-Attention"><a href="#Neural-Machine-Translation-with-Supervised-Attention" class="headerlink" title="Neural Machine Translation with Supervised Attention"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04186v1.pdf" target="_blank" rel="external">Neural Machine Translation with Supervised Attention</a></h1><p>attention机制可以动态地对齐source和target words，但准确率不如传统方法。本文提出了用传统方法作为teacher，来“教”model学习alignment，模型称为supervised attention。本文已投稿COLING2016，在审。</p>
<h1 id="Efficient-softmax-approximation-for-GPUs"><a href="#Efficient-softmax-approximation-for-GPUs" class="headerlink" title="Efficient softmax approximation for GPUs"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.04309v1.pdf" target="_blank" rel="external">Efficient softmax approximation for GPUs</a></h1><p>本文提出了一种高效的softmax近似方法，并且可以方便地进行并行计算。本文称之为adaptive softmax，根据词分布进行聚类，极大地提高了计算效率并保证了不错的准确率。本文工作来自Facebook AI Research。</p>
<p>在自然语言生成任务中常常面临word vocabulary size太大的困境，softmax的效率非常低，本文给出了一种快速计算的方法。Tomas Mikolov之前也提到过类似的思路。</p>
<h1 id="Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception"><a href="#Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception" class="headerlink" title="Characterizing the Language of Online Communities and its Relation to Community Reception"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04779v1.pdf" target="_blank" rel="external">Characterizing the Language of Online Communities and its Relation to Community Reception</a></h1><p>本文研究了在线社区语言的style和topic哪个更具代表性，这里style用复合语言模型来表示，topic用LDA来表示，通过Reddit Forum实验得到style比topic更有代表性。</p>
<h1 id="Factored-Neural-Machine-Translation"><a href="#Factored-Neural-Machine-Translation" class="headerlink" title="Factored Neural Machine Translation"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04621v1.pdf" target="_blank" rel="external">Factored Neural Machine Translation</a></h1><p>针对机器翻译领域中两个常见的问题：1、目标语言词汇表过大；2、OOV问题；利用了单词的词形和语法分解，提出了一种新的NMT模型，并取得了满意的效果。</p>
<h1 id="Context-Aware-Nonnegative-Matrix-Factorization-Clustering"><a href="#Context-Aware-Nonnegative-Matrix-Factorization-Clustering" class="headerlink" title="Context Aware Nonnegative Matrix Factorization Clustering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04628v1.pdf" target="_blank" rel="external">Context Aware Nonnegative Matrix Factorization Clustering</a></h1><p>大多数paper都在研究NMF在聚类中的初始化和优化部分，而本文关注的点在于最后的聚类分配上。本文被 ICPR 2016全文收录。</p>
<p>以下内容为arXiv外的优质内容：</p>
<h1 id="SIGDIAL-2016-Accepted-Paper"><a href="#SIGDIAL-2016-Accepted-Paper" class="headerlink" title="SIGDIAL 2016 Accepted Paper"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/SIGDIAL-2016.pdf" target="_blank" rel="external">SIGDIAL 2016 Accepted Paper</a></h1><p>SIGdial是ACL下面的一个关于对话系统地特别兴趣小组，每年开一次会。今年的会议最近正在开，会议录用的所有paper都已经放出。</p>
<h1 id="CMU-SPEECH-Team-Homepage"><a href="#CMU-SPEECH-Team-Homepage" class="headerlink" title="CMU SPEECH Team Homepage"></a><a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">CMU SPEECH Team Homepage</a></h1><p>CMU SPEECH Team的主页，包括他们的开源软件Yoda和publication及其开源实现。</p>
<h1 id="Machine-Learning-WAYR-What-Are-You-Reading"><a href="#Machine-Learning-WAYR-What-Are-You-Reading" class="headerlink" title="Machine Learning - WAYR (What Are You Reading)"></a><a href="https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/?st=ISZ6YT6D&amp;sh=02bd0722" target="_blank" rel="external">Machine Learning - WAYR (What Are You Reading)</a></h1><p>reddit上的这个帖子很有意思，和paperweekly想做的一个事情非常像，就是可以让读类似或者同一篇paper的童鞋得到充分交流。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周（2016.09.12-2016.09.16）质量较高的arXiv cs.CL的paper如下：&lt;br&gt;（点击标题可看原文）&lt;/p&gt;
&lt;h1 id=&quot;Dialogue-manager-domain-adaptation-using-Gaussian-process-re
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第五期</title>
    <link href="http://rsarxiv.github.io/2016/09/16/PaperWeekly-%E7%AC%AC%E4%BA%94%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/09/16/PaperWeekly-第五期/</id>
    <published>2016-09-16T18:14:40.000Z</published>
    <updated>2016-09-16T19:44:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用word2vec来做word-level的embedding。Word2Vec的作者Tomas Mikolov是一位产出多篇高质量paper的学者，从RNNLM、Word2Vec再到最近流行的FastText都与他息息相关。一个人对同一个问题的研究可能会持续很多年，而每一年的研究成果都可能会给同行带来新的启发，本期的PaperWeekly将会分享其中三篇代表作，分别是：</p>
<p>1、Efficient Estimation of Word Representation in Vector Space, 2013<br>2、Distributed Representations of Sentences and Documents, 2014<br>3、Enriching Word Vectors with Subword Information, 2016</p>
<h1 id="Efficient-Estimation-of-Word-Representation-in-Vector-Space"><a href="#Efficient-Estimation-of-Word-Representation-in-Vector-Space" class="headerlink" title="Efficient Estimation of Word Representation in Vector Space"></a><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="external">Efficient Estimation of Word Representation in Vector Space</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Google Inc., Mountain View, CA</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201309</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何在一个大型数据集上快速、准确地学习出词表示？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。</p>
<p>本文提出的两个模型CBOW (Continuous Bag-of-Words Model)和Skip-gram (Continuous Skip-gram Model)结合了上面两个模型的特点，都是只有三层，即输入层、映射层和输出层。CBOW模型与NNLM模型类似，用上下文的词向量作为输入，映射层在所有的词间共享，输出层为一个分类器，目标是使当前词的概率最大。Skip-gram模型与CBOW的输入跟输出恰好相反，输入层为当前词向量，输出层是使得上下文的预测概率最大，如下图所示。训练采用SGD。<br><img src="media/14740499814306.jpg" alt=""></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>Code: <a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="external">C++代码</a><br>Dataset: <a href="https://sites.google.com/site/semeval2012task2/" target="_blank" rel="external">SemEval-2012</a>,用来评估语义相关性。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Bengio[1]在2003年就提出了language model的思路，同样是三层（输入层，隐含层和输出层）用上下文的词向量来预测中间词，但是计算复杂度较高，对于较大的数据集运行效率低；实验中也发现将上下文的n-gram出现的频率结合进去会提高性能，这个优点体现在CBOW和Skip-gram模型的输出层中，用hierarchical softmax（with huffman trees）来计算词概率。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的实验结果显示CBOW比NNLM在syntactic和semantic上的预测都要好，而Skip-gram在semantic上的性能要优于CBOW，但是其计算速度要低于CBOW。结果显示用较大的数据集和较少的epoch，可以取得较好的效果，并且在速度上有所提升。与LSI和LDA相比，word2vec利用了词的上下文，语义信息更加丰富。基于word2vec，出现了phrase2vec, sentence2vec和doc2vec，仿佛一下子进入了embedding的世界。NLP的这些思想也在用于recommendation等方面，并且与image结合，将image跟text之间进行转换。</p>
<h1 id="Distributed-Representations-of-Sentences-and-Documents"><a href="#Distributed-Representations-of-Sentences-and-Documents" class="headerlink" title="Distributed Representations of Sentences and Documents"></a><a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Quoc V. Le, Tomas Mikolov</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Google Inc, Mountain View, CA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>sentence representation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ICML 2014</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>基于word2vec的思路，如何表示sentence和document？</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p><img src="media/14740512129190.jpg" alt=""><br>利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。</p>
<p>接下来是段落的向量表示方法：<br><img src="media/14740512491434.jpg" alt=""><br>依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。</p>
<p>最后一种就是没有词序的段落向量表示方法：<br><img src="media/14740512902836.jpg" alt=""><br>从图中就可以感觉到这个方法明显和skip-gram非常相似，这里只是把重点放在了段落的表示中，通过段落的表示，来预测相应的context 词的表示。最后我们依然可以得到段落矩阵D，这样就可以对段落进行向量化表示了。但是输入起码是句子级别的表示，而输出则是词的向量表示，因此个人比较怀疑这种方法的合理性。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>这篇文章是word2vec的方法提出一年后提出的方法，因此本文并没有使用目前非常流行的word2vec的训练方法来训练词向量，而是利用word2vec的思路，提出了一种更加简单的网络结构来训练任意长度的文本表示方法。这样一方面好训练，另一方面减少了参数，避免模型过拟合。优点就是在训练paragraph vector的时候加入了一个paragraph matrix，这样在训练过程中保留了一部分段落或者文档信息。这点在目前看来也是有一定优势的。但是目前深度学习发展迅速，可以处理非常大的计算量，同时word2vec以及其变种被应用得非常普遍，因此该文章提出的方法思路大于模型，思路我们可以借鉴，模型就不具有优势了。</p>
<h1 id="Enriching-Word-Vectors-with-Subword-Information"><a href="#Enriching-Word-Vectors-with-Subword-Information" class="headerlink" title="Enriching Word Vectors with Subword Information"></a><a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" target="_blank" rel="external">Enriching Word Vectors with Subword Information</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Facebook AI Research</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Word embedding, morphological, character n-gram</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201607</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>word2vec在词汇建模方面产生了巨大的贡献，然而其依赖于大量的文本数据进行学习，如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。</p>
<p>方法上，本文沿用了word2vec的skip-gram模型，主要区别体现在特征上。word2vec使用word作为最基本的单位，即通过中心词预测其上下文中的其他词汇。而subword model使用字母n-gram作为单位，本文n取值为3~6。这样每个词汇就可以表示成一串字母n-gram，一个词的embedding表示为其所有n-gram的和。这样我们训练也从用中心词的embedding预测目标词，转变成用中心词的n-gram embedding预测目标词。</p>
<p>实验分为三个部分，分别是（1）计算两个词之间的语义相似度，与人类标注的相似度进行相关性比较；（2）与word2vec一样的词类比实验；（3）与其他考虑morphology的方法比较。结果是本文方法在语言形态丰富的语言（土耳其语，法语等）及小数据集上表现优异，与预期一致。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>源码公布在Facebook的fastText项目中： <a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>利用语言形态学来改进nlp的研究源远流长，本文提及的许多关于character-level和morphology的有趣工作值得参考。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>文章中提出的思路对于morphologically rich languages（例如土耳其语，词缀的使用极为普遍而有趣）来说十分有意义。词缀作为字母与单词之间的中层单位，本身具有一定的语义信息。通过充分利用这种中层语义来表征罕见词汇，直观上讲思路十分合理，也是应用了compositionality的思想。</p>
<p>利用形态学改进word embedding的工作十分丰富，但中文NLP似乎很难利用这一思路。其实个人感觉中文中也有类似于词缀的单位，比如偏旁部首等等，只不过不像使用字母系统的语言那样容易处理。期待今后也有闪光的工作出现在中文环境中。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从Word2Vec到FastText，从word representation到sentence classification，Tomas Mikolov的工作影响了很多人。虽然有个别模型和实验结果曾遭受质疑，但终究瑕不掩瑜。word2vec对NLP的研究起到了极大地推动作用，其实不仅仅是在NLP领域中，在其他很多领域中都可以看到word2vec的思想和作用，也正是从word2vec开始，这个世界变得都被vector化了，person2vec，sentence2vec，paragraph2vec，anything2vec，world2vec。</p>
<p>以上为本期Paperweekly的主要内容，感谢memray、zhkun、gcyydxf、jell四位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="Representation" scheme="http://rsarxiv.github.io/tags/Representation/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.09.05-2016.09.09</title>
    <link href="http://rsarxiv.github.io/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/"/>
    <id>http://rsarxiv.github.io/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/</id>
    <published>2016-09-10T19:38:13.000Z</published>
    <updated>2016-09-10T19:56:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level"><a href="#Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level" class="headerlink" title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" target="_blank" rel="external">Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level</a></h1><p>张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。</p>
<p>（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）</p>
<h1 id="Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering"><a href="#Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering" class="headerlink" title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" target="_blank" rel="external">Skipping Word: A Character-Sequential Representation based Framework for Question Answering</a></h1><p>本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><p>本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。</p>
<p>（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><p>本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。</p>
<p>用到的数据集在Dropbox有一份<a href="http://t.cn/Rcbcpfl" target="_blank" rel="external">copy</a></p>
<h1 id="Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling"><a href="#Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling" class="headerlink" title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" target="_blank" rel="external">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</a></h1><p>和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)</p>
<h1 id="Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations"><a href="#Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations" class="headerlink" title="Ask the GRU: Multi-task Learning for Deep Text Recommendations"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" target="_blank" rel="external">Ask the GRU: Multi-task Learning for Deep Text Recommendations</a></h1><p>本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。</p>
<p>以下内容为arXiv外的<b>优质内容</b>：</p>
<h1 id="Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems"><a href="#Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems" class="headerlink" title="Discriminative Methods for Statistical Spoken Dialogue Systems"></a><a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" target="_blank" rel="external">Discriminative Methods for Statistical Spoken Dialogue Systems</a></h1><p>剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。</p>
<p>如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。</p>
<h1 id="CONNECTING-IMAGES-AND-NATURAL-LANGUAGE"><a href="#CONNECTING-IMAGES-AND-NATURAL-LANGUAGE" class="headerlink" title="CONNECTING IMAGES AND NATURAL LANGUAGE"></a><a href="http://cs.stanford.edu/people/karpathy/main.pdf" target="_blank" rel="external">CONNECTING IMAGES AND NATURAL LANGUAGE</a></h1><p>斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！</p>
<p>最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。 <a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="external">A Survival Guide to a PhD</a></p>
<h1 id="Mendeley-Docs"><a href="#Mendeley-Docs" class="headerlink" title="Mendeley Docs"></a><a href="https://pan.baidu.com/share/link?shareid=317480&amp;uk=1594817379" target="_blank" rel="external">Mendeley Docs</a></h1><p>paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。</p>
<p>Easily organize your papers, read &amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：&lt;br&gt;（点击标题可看原文）&lt;/p&gt;
&lt;h1 id=&quot;Convolutional-Neural-Networks-for-Text-Categorization-Shallo
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="arXiv" scheme="http://rsarxiv.github.io/tags/arXiv/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly第四期</title>
    <link href="http://rsarxiv.github.io/2016/09/09/PaperWeekly%E7%AC%AC%E5%9B%9B%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/09/09/PaperWeekly第四期/</id>
    <published>2016-09-09T19:48:42.000Z</published>
    <updated>2016-09-10T02:52:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：</p>
<p>(1)《Generating Text with Deep Reinforcement Learning》<br>应用Deep Q-Network作为生成模型用于改善seq2seq模型</p>
<p>(2)    《Deep Reinforcement Learning for Dialogue Generation》<br>应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<p>(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》<br>以任务为导向的户内导航对话系统用分层强化学习进行文本生成</p>
<p>以下为三篇文章的主要信息：</p>
<h1 id="Generating-Text-with-Deep-Reinforcement-Learning"><a href="#Generating-Text-with-Deep-Reinforcement-Learning" class="headerlink" title="Generating Text with Deep Reinforcement Learning"></a><a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Hongyu Guo</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>National Research Council Canada</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>NIPS2015 Workshop (2015.10.30)</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：</p>
<p><img src="media/14734508069657.jpg" alt=""></p>
<p>如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。</p>
<p>对照上图我们把算法解剖分为4个步骤：</p>
<p>Step 1: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。</p>
<p>Step 2: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。</p>
<p>Step 3: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。</p>
<p>Step 4: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。</p>
<p>总结DQN所需的四个元素对应如下：<br>(1) i时刻下的state：(EnSen(i), DeSen(i))；<br>(2) i时刻下的action：beam search得到的每个位置的hypotheses；<br>(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；<br>(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；</p>
<p>为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：</p>
<p><img src="media/14734509263452.jpg" alt=""></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734510298695.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。</p>
<h1 id="Deep-Reinforcement-Learning-for-Dialogue-Generation"><a href="#Deep-Reinforcement-Learning-for-Dialogue-Generation" class="headerlink" title="Deep Reinforcement Learning for Dialogue Generation"></a><a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>(1) Stanford University, Stanford, CA, USA<br>(2) Microsoft Research, Redmond, WA, USA<br>(3) Ohio State University, OH, USA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv.org(2016.06.25)</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>强化学习中的reward</p>
<p><img src="media/14734512073402.jpg" alt=""></p>
<p>易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应</p>
<p><img src="media/14734512278456.jpg" alt=""></p>
<p>信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦</p>
<p><img src="media/14734512443645.jpg" alt=""></p>
<p>语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。</p>
<p><img src="media/14734512828474.jpg" alt=""></p>
<p>最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.</p>
<p>对比试验：<br>(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。</p>
<p>(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。</p>
<p>(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。</p>
<p><img src="media/14734513584870.jpg" alt=""></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734513827800.jpg" alt=""></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。</p>
<h1 id="Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation"><a href="#Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation" class="headerlink" title="Hierarchical Reinforcement Learning for Adaptive Text Generation"></a><a href="http://www.aclweb.org/anthology/W10-4204" target="_blank" rel="external">Hierarchical Reinforcement Learning for Adaptive Text Generation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Nina Dethlefs, Heriberto Cuay´ahuitl</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>University of Bremen, Germany</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NLG, 分层强化学习, 文本生成, wayfinding</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>国际自然语言生成会议INLG(2010)</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。</p>
<p>文章将户内导航对话系统的文本生成问题分为四块：</p>
<p>(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致<br>(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。<br>(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”<br>(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。</p>
<p>强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。<br><img src="media/14734516131737.jpg" alt=""></p>
<p>agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。</p>
<p>分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。</p>
<p><img src="media/14734516802648.jpg" alt=""></p>
<p>每个agent定义为半马尔科夫决策过程，可以表示成一个四元组</p>
<p><img src="media/14734517382304.jpg" alt=""></p>
<p>分别为状态集，动作集，转换函数，奖励函数。</p>
<p>奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，</p>
<p><img src="media/14734524023811.jpg" alt=""></p>
<p>使得在从当前状态转换到新的状态获得的累计奖励最多。</p>
<p>本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。</p>
<p>本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>词性标注工具：<a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">http://nlp.stanford.edu/software/tagger.shtml</a></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>将来的工作：将分层强化学习应用于其他NLG任务<br>不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。</p>
<p>以上为本期Paperweekly的主要内容，感谢lshowway、美好时光海苔、Tonya三位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha 
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="paperweekly" scheme="http://rsarxiv.github.io/tags/paperweekly/"/>
    
      <category term="chatbot" scheme="http://rsarxiv.github.io/tags/chatbot/"/>
    
      <category term="reinforcement learning" scheme="http://rsarxiv.github.io/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.08.29-2016.09.02</title>
    <link href="http://rsarxiv.github.io/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/"/>
    <id>http://rsarxiv.github.io/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/</id>
    <published>2016-09-03T17:02:40.000Z</published>
    <updated>2016-09-03T17:13:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond"><a href="#Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond" class="headerlink" title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond"></a><a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" target="_blank" rel="external">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a></h1><p>一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。</p>
<h1 id="Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer"><a href="#Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer" class="headerlink" title="Machine Comprehension Using Match-LSTM and Answer Pointer"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">Machine Comprehension Using Match-LSTM and Answer Pointer</a></h1><p>本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。 </p>
<h1 id="Measuring-Machine-Intelligence-Through-Visual-Question-Answering"><a href="#Measuring-Machine-Intelligence-Through-Visual-Question-Answering" class="headerlink" title="Measuring Machine Intelligence Through Visual Question Answering"></a><a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" target="_blank" rel="external">Measuring Machine Intelligence Through Visual Question Answering</a></h1><p>本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：www.visualqa.org.</p>
<h1 id="How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions"><a href="#How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions" class="headerlink" title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" target="_blank" rel="external">How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions</a></h1><p>文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-1-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -1-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ），每天会发布arXiv cs.CL高质量paper和简评。<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：&lt;br&gt;（点击标题可看原文）&lt;/p&gt;
&lt;h1 id=&quot;Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RN
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="arXiv" scheme="http://rsarxiv.github.io/tags/arXiv/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第三期</title>
    <link href="http://rsarxiv.github.io/2016/09/01/PaperWeekly-%E7%AC%AC%E4%B8%89%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/09/01/PaperWeekly-第三期/</id>
    <published>2016-09-01T21:58:14.000Z</published>
    <updated>2016-09-02T17:21:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。</p>
<p>有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。</p>
<p>PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。</p>
<p>寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。</p>
<h1 id="Sentence-Rewriting-for-Semantic-Parsing"><a href="#Sentence-Rewriting-for-Semantic-Parsing" class="headerlink" title="Sentence Rewriting for Semantic Parsing"></a><a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" target="_blank" rel="external">Sentence Rewriting for Semantic Parsing</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Semantic Parsing、Sentence Rewriting</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。</p>
<h2 id="文章思路"><a href="#文章思路" class="headerlink" title="文章思路"></a>文章思路</h2><p>先给出一个语义分析的例子：</p>
<p><img src="media/14727920453411.jpg" alt=""></p>
<p>给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。</p>
<p>作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：</p>
<p><img src="media/14727921250895.jpg" alt=""></p>
<p>针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。</p>
<p>1）问题一：1-N mismatch<br>是指一个单词（word）对应一个复合的逻辑形式（compound formula）。</p>
<p>例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。</p>
<p>2）问题二：N-1 mismatch<br>是指将复杂的自然语言表达对应为单个逻辑表达。</p>
<p>例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。</p>
<p>沿用之前的句子来了解算法流程。</p>
<p><img src="media/14727921375652.jpg" alt=""></p>
<p>Step 1 替换实体生成候选template，例如得到模板how many people live in #y。<br>Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，<br>Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。 </p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727925154995.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。</p>
<h1 id="Language-to-Logical-Form-with-Neural-Attention"><a href="#Language-to-Logical-Form-with-Neural-Attention" class="headerlink" title="Language to Logical Form with Neural Attention"></a><a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" target="_blank" rel="external">Language to Logical Form with Neural Attention</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Logical Forms, Sequence to Sequence</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>如何把自然语言转化成Structured Logical Forms？</p>
<h2 id="文章思路-1"><a href="#文章思路-1" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727925632141.jpg" alt=""></p>
<p>模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。</p>
<p><img src="media/14727705332596.jpg" alt=""></p>
<p>和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符<n>代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。</n></p>
<p><img src="media/14727925854664.jpg" alt=""></p>
<p>作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="external">https://github.com/donglixp/lang2logic</a><br>Jobs和GEO数据集：<a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf" target="_blank" rel="external">http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。</p>
<h1 id="Neural-Summarization-by-Extracting-Sentences-and-Words"><a href="#Neural-Summarization-by-Extracting-Sentences-and-Words" class="headerlink" title="Neural Summarization by Extracting Sentences and Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" target="_blank" rel="external">Neural Summarization by Extracting Sentences and Words</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Summarization、Hierarchical Document Encoder、Attention-based Extractor</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何使用数据驱动的方法来做提取式摘要？</p>
<h2 id="文章思路-2"><a href="#文章思路-2" class="headerlink" title="文章思路"></a>文章思路</h2><p>本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。</p>
<p>使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。</p>
<p><img src="media/14727709292807.jpg" alt=""></p>
<p>在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。</p>
<p>word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。</p>
<p><img src="media/14727709957739.jpg" alt=""></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/s1537177/resources.html</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。</p>
<h1 id="Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings"><a href="#Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings" class="headerlink" title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings"></a><a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" target="_blank" rel="external">Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings</a></h1><h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Sequence to Sequence、Natural Language Generation、Chatbot</p>
<h2 id="来源-3"><a href="#来源-3" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何通过小规模、未对齐语料生成对话语句？</p>
<h2 id="文章思路-3"><a href="#文章思路-3" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者介绍了两个模型:</p>
<p>1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）</p>
<p><img src="media/14727713613292.jpg" alt=""></p>
<p>2、将两部分结合起来，直接生成语句。步骤如下：</p>
<p>Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)</p>
<p><img src="media/14727714252636.jpg" alt=""></p>
<p>Step 2 基于seq2seq generation technique生出语句或句法依赖树。<br>Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>代码: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727926849132.jpg" alt=""></p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of  meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。</p>
<h1 id="On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems"><a href="#On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems" class="headerlink" title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"></a><a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="external">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a></h1><h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Dialogue System、Reinforcement Learning、Online Active Reward Learning</p>
<h2 id="来源-4"><a href="#来源-4" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。</p>
<h2 id="文章思路-4"><a href="#文章思路-4" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727785168705.jpg" alt=""></p>
<p>框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。</p>
<p>无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="external">http://camdial.org/~mh521/dstc/</a></p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量<br>2、用协同过滤表征用户偏好<br>3、用逆强化学习从行为中推出reward</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-5"><a href="#来源-5" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-5"><a href="#文章思路-5" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：<br>a. 传统的基于词（word level）的seq2seq模型；<br>b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。</p>
<p><img src="media/14727723863213.jpg" alt=""></p>
<p>具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用<unk>作为下一步的输入。</unk></p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。<br>另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="关键词-6"><a href="#关键词-6" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-6"><a href="#来源-6" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-6"><a href="#文章思路-6" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。</p>
<p>1、Attention-based机器翻译模型<br><img src="media/14727726836085.jpg" alt=""><br>经典的attention model这里不再赘述。</p>
<p>2、Pointer Softmax模型<br><img src="media/14727727829495.jpg" alt=""></p>
<p>两个问题有待解决解决：<br>a. 是否进行copy？<br>b. copy的位置在哪？</p>
<p>先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。</p>
<p>再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。</p>
<h2 id="资源-4"><a href="#资源-4" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/caglar/pointer_softmax" target="_blank" rel="external">https://github.com/caglar/pointer_softmax</a></p>
<h2 id="简评-6"><a href="#简评-6" class="headerlink" title="简评"></a>简评</h2><p>本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。</p>
<h1 id="Harnessing-Deep-Neural-Networks-with-Logic-Rules"><a href="#Harnessing-Deep-Neural-Networks-with-Logic-Rules" class="headerlink" title="Harnessing Deep Neural Networks with Logic Rules"></a><a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" target="_blank" rel="external">Harnessing Deep Neural Networks with Logic Rules</a></h1><h2 id="关键词-7"><a href="#关键词-7" class="headerlink" title="关键词"></a>关键词</h2><p>CNN、RNN、First-order Logic, Iterative Distillation Method</p>
<h2 id="来源-7"><a href="#来源-7" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-7"><a href="#问题-7" class="headerlink" title="问题"></a>问题</h2><p>如何将深度学习与逻辑规则结合使用？</p>
<h2 id="文章思路-7"><a href="#文章思路-7" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727734980533.png" alt=""></p>
<p>系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。</p>
<p>1、训练过程</p>
<p>假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了</p>
<p><img src="media/14727735567000.png" alt=""></p>
<p>可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.</p>
<p>2、教师网络</p>
<p>教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。</p>
<p>神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是</p>
<p><img src="media/14727736225787.png" alt=""></p>
<p>λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。</p>
<p>3、应用</p>
<p>a. 基于CNN的情感分析<br>b. 基于BLSTM-CNN的NER任务</p>
<h2 id="相关工作-6"><a href="#相关工作-6" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络<br>2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据<br>3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)<br>4、Posterior regularization (PR) method (Ganchev et al., 2010)</p>
<h2 id="简评-7"><a href="#简评-7" class="headerlink" title="简评"></a>简评</h2><p>创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。</p>
<h1 id="Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering"><a href="#Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering" class="headerlink" title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering"></a><a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" target="_blank" rel="external">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</a></h1><h2 id="关键词-8"><a href="#关键词-8" class="headerlink" title="关键词"></a>关键词</h2><p>Curriculum Learning、Self-paced Learning、Question Answering</p>
<h2 id="来源-8"><a href="#来源-8" class="headerlink" title="来源"></a>来源</h2><p>ACL2016</p>
<h2 id="问题-8"><a href="#问题-8" class="headerlink" title="问题"></a>问题</h2><p>文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。</p>
<h2 id="文章思路-8"><a href="#文章思路-8" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:</p>
<p><img src="media/14727739856834.jpg" alt=""></p>
<p>其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer. </p>
<p>之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:</p>
<p><img src="media/14727740344982.jpg" alt=""></p>
<p>其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。</p>
<p>文章给出并分析了四种流行的self-paced regularizer如Table 1:</p>
<p><img src="media/14727745747996.jpg" alt=""></p>
<p>之后提出了7种新的heuristics:</p>
<p>1)    Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。<br>2)    Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。<br>3)    Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。<br>4)    Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。<br>5)    Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。<br>6)    Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。<br>7)    Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。</p>
<h2 id="资源-5"><a href="#资源-5" class="headerlink" title="资源"></a>资源</h2><p>MCTest: <a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" target="_blank" rel="external">http://research.microsoft.com/en-us/um/redmond/projects/mctest/</a><br>Science Textbook: <a href="http://http://www.ck12.org/" target="_blank" rel="external">http://http://www.ck12.org/</a><br>Science question answering: <a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" target="_blank" rel="external">http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip</a><br>Simple English Wikipedia: <a href="https://dumps.wikimedia.org/simplewiki/20151102/" target="_blank" rel="external">https://dumps.wikimedia.org/simplewiki/20151102/</a><br>QANTA: <a href="https://cs.umd.edu/~miyyer/qblearn/" target="_blank" rel="external">https://cs.umd.edu/~miyyer/qblearn/</a></p>
<h2 id="相关工作-7"><a href="#相关工作-7" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Curriculum Learning: </p>
<p>早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。 </p>
<p>2、QA:</p>
<p>Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].<br>基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。</p>
<h2 id="简评-8"><a href="#简评-8" class="headerlink" title="简评"></a>简评</h2><p>在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。</p>
<p>通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。</p>
<p>然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。</p>
<p>总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。</p>
<h1 id="The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context"><a href="#The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context" class="headerlink" title="The LAMBADA dataset:Word prediction requiring a broad discourse context"></a><a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" target="_blank" rel="external">The LAMBADA dataset:Word prediction requiring a broad discourse context</a></h1><h2 id="关键词-9"><a href="#关键词-9" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension、Dataset</p>
<h2 id="来源-9"><a href="#来源-9" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-9"><a href="#问题-9" class="headerlink" title="问题"></a>问题</h2><p>构建了一个难度更大的机器阅读理解数据集。</p>
<h2 id="构建思路"><a href="#构建思路" class="headerlink" title="构建思路"></a>构建思路</h2><p>以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。</p>
<p>在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。</p>
<h2 id="资源-6"><a href="#资源-6" class="headerlink" title="资源"></a>资源</h2><p>本文数据集Lambada dataset: <a href="http://clic.cimec.unitn.it/lambada/" target="_blank" rel="external">http://clic.cimec.unitn.it/lambada/</a><br>众包网站Crowdflower: <a href="http://www.crowdflower.com/" target="_blank" rel="external">http://www.crowdflower.com/</a><br>原始数据集Book Corpus: <a href="http://www.cs.toronto.edu/~mbweb/" target="_blank" rel="external">http://www.cs.toronto.edu/~mbweb/</a><br>CNN/Daily Mail dataset: <a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">https://github.com/deepmind/rc-data</a><br>CBT dataset: <a href="http://fb.ai/babi/" target="_blank" rel="external">http://fb.ai/babi/</a><br>MSRCC dataset:  <a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" target="_blank" rel="external">https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/</a></p>
<h2 id="相关数据集"><a href="#相关数据集" class="headerlink" title="相关数据集"></a>相关数据集</h2><p><img src="media/1.png" alt="1"></p>
<h2 id="简评-9"><a href="#简评-9" class="headerlink" title="简评"></a>简评</h2><p>大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。</p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>本期的10篇文章由以下同学完成：</p>
<p>苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。</p>
<p>感谢大家地辛勤付出。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/14727755950469.jpg" alt=""></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>cs.CL weekly 2016.08.22-2016.08.26</title>
    <link href="http://rsarxiv.github.io/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/"/>
    <id>http://rsarxiv.github.io/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/</id>
    <published>2016-08-26T16:20:19.000Z</published>
    <updated>2016-08-26T16:36:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。</p>
<h1 id="Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views"><a href="#Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views" class="headerlink" title="Learning Word Embeddings from Intrinsic and Extrinsic Views"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" target="_blank" rel="external">Learning Word Embeddings from Intrinsic and Extrinsic Views</a></h1><p>本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。 </p>
<h1 id="Context-Gates-for-Neural-Machine-Translation"><a href="#Context-Gates-for-Neural-Machine-Translation" class="headerlink" title="Context Gates for Neural Machine Translation"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" target="_blank" rel="external">Context Gates for Neural Machine Translation</a></h1><p>本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。</p>
<h1 id="Topic-Sensitive-Neural-Headline-Generation"><a href="#Topic-Sensitive-Neural-Headline-Generation" class="headerlink" title="Topic Sensitive Neural Headline Generation"></a><a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" target="_blank" rel="external">Topic Sensitive Neural Headline Generation</a></h1><p>本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。 </p>
<h1 id="Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine"><a href="#Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine" class="headerlink" title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"></a><a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" target="_blank" rel="external">Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</a></h1><p>本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><p>本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于<a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">Github</a></p>
<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：</p>
<p>1、PaperWeekly<a href="http://weibo.com/2678093863/" target="_blank" rel="external">官方微博</a></p>
<p>2、PaperWeekly官方微信</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430.jpg" alt="qrcode_for_gh_5138cebd4585_430"></p>
<p>3、PaperWeekly<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">知乎专栏</a></p>
<p>4、PaperWeekly微信交流群（+微信zhangjun168305入群）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为Pape
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>从api.ai工作原理来看构建简单场景chatbot的一般方法</title>
    <link href="http://rsarxiv.github.io/2016/08/21/%E4%BB%8Eapi-ai%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%9D%A5%E7%9C%8B%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E5%9C%BA%E6%99%AFchatbot%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/"/>
    <id>http://rsarxiv.github.io/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/</id>
    <published>2016-08-22T02:05:52.000Z</published>
    <updated>2016-08-23T04:19:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。<br><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)</p>
<p>对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：</p>
<p><b>Act(Slot=Value)</b></p>
<p>Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。</p>
<p>紧接着是NLG的部分，前几天在<a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/">PaperWeekly第二期</a>中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。</p>
<p>本文首先从<a href="api.ai">api.ai</a>这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。</p>
<h1 id="api-ai"><a href="#api-ai" class="headerlink" title="api.ai"></a>api.ai</h1><h2 id="api-ai公司介绍"><a href="#api-ai公司介绍" class="headerlink" title="api.ai公司介绍"></a>api.ai公司介绍</h2><blockquote>
<p>Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.</p>
</blockquote>
<p>这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。</p>
<p>api.ai公司成立于2010年（数据来自<a href="https://www.crunchbase.com/organization/api-ai#/entity" target="_blank" rel="external">CrunchBase</a>），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：<br><img src="media/2.png" alt="2"></p>
<p>每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。</p>
<h2 id="重要概念和工作原理"><a href="#重要概念和工作原理" class="headerlink" title="重要概念和工作原理"></a>重要概念和工作原理</h2><h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><p>1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：<br><img src="media/3.png" alt="3"></p>
<p>2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。</p>
<p>这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。</p>
<p>3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：<br><img src="media/4.png" alt="4"></p>
<p>这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。</p>
<p>4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&gt;三里屯，query-&gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。</p>
<p>5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>以RSarXiv chatbot为例，简单介绍下工作原理。<br>（注：RSarXiv是我之前写的一个arxiv paper推荐系统）</p>
<p>step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。<br><img src="media/5.png" alt="5"><br>定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。</p>
<p>step 2  自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。<br><img src="media/6.png" alt="6"></p>
<p>接下来，我需要定义下Actions，如下图：<br><img src="media/7.png" alt="7"><br>Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。</p>
<p>step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：<br><img src="media/8.png" alt="8"><br>chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。</p>
<p>step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。</p>
<p>step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。<br><img src="media/10.png" alt="10"></p>
<p>大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。</p>
<h1 id="简单场景chatbot构建方法"><a href="#简单场景chatbot构建方法" class="headerlink" title="简单场景chatbot构建方法"></a>简单场景chatbot构建方法</h1><p>介绍了下api.ai提供的服务，下面简单地提炼一下。</p>
<p>chatbot = NLU + NLG</p>
<p>api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：</p>
<p>1、从user inputs中识别出user intent和对应的action。</p>
<p>2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。</p>
<p>NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：<br><img src="media/9.png" alt="9"></p>
<p>跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：</p>
<p>1、从特定任务中归纳出Intents、Actions、Entities。</p>
<p>2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。</p>
<p>3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。</p>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。</p>
<p>NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）</p>
<p>Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。</p>
<p>本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。</p>
<h1 id="PaperWeekly招人广告"><a href="#PaperWeekly招人广告" class="headerlink" title="PaperWeekly招人广告"></a>PaperWeekly招人广告</h1><p>PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode.jpg" alt="qrcode"></p>
<p>知乎专栏：<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a></p>
<p>微信交流群：</p>
<p><img src="media/paperweekly.jpg" alt="paperweekly"></p>
<p>群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域b
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="chatbot" scheme="http://rsarxiv.github.io/tags/chatbot/"/>
    
      <category term="api.ai" scheme="http://rsarxiv.github.io/tags/api-ai/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第二期</title>
    <link href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/08/16/PaperWeekly-第二期/</id>
    <published>2016-08-16T23:53:50.000Z</published>
    <updated>2016-08-17T05:50:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。</p>
<p>DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。</p>
<p>生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。</p>
<p>本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。</p>
<h1 id="Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems"><a href="#Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems" class="headerlink" title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"></a><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" target="_blank" rel="external">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</a></h1><h2 id="关键词：NLG、bot、自定义LSTM"><a href="#关键词：NLG、bot、自定义LSTM" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：EMNLP-2015"><a href="#来源：EMNLP-2015" class="headerlink" title="来源：EMNLP 2015"></a>来源：EMNLP 2015</h2><h2 id="问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？"><a href="#问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？" class="headerlink" title="问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？"></a>问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？</h2><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><p>首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。</p>
<p>本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。</p>
<h2 id="评论："><a href="#评论：" class="headerlink" title="评论："></a>评论：</h2><p>这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。</p>
<h1 id="Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data"><a href="#Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data" class="headerlink" title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"></a><a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" target="_blank" rel="external">Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data</a></h1><h2 id="关键词：NLG、bot、自定义LSTM-1"><a href="#关键词：NLG、bot、自定义LSTM-1" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：arXiv-2016-06-11-cs-CL"><a href="#来源：arXiv-2016-06-11-cs-CL" class="headerlink" title="来源：arXiv 2016.06.11 cs.CL"></a>来源：arXiv 2016.06.11 cs.CL</h2><h2 id="问题：task-oriented-bot-NLG问题，是第一篇的升级版。"><a href="#问题：task-oriented-bot-NLG问题，是第一篇的升级版。" class="headerlink" title="问题：task-oriented bot NLG问题，是第一篇的升级版。"></a>问题：task-oriented bot NLG问题，是第一篇的升级版。</h2><h2 id="方法：-1"><a href="#方法：-1" class="headerlink" title="方法："></a>方法：</h2><p>本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。</p>
<p>task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。</p>
<h2 id="评论：-1"><a href="#评论：-1" class="headerlink" title="评论："></a>评论：</h2><p>本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。</p>
<h1 id="DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents"><a href="#DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents" class="headerlink" title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"></a><a href="http://aclweb.org/anthology/P16-1049" target="_blank" rel="external">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</a></h1><h2 id="关键词：Retrieve-Based-Bot，Unstructured-Documents"><a href="#关键词：Retrieve-Based-Bot，Unstructured-Documents" class="headerlink" title="关键词：Retrieve-Based Bot，Unstructured Documents"></a>关键词：Retrieve-Based Bot，Unstructured Documents</h2><h2 id="来源：ACL-2016"><a href="#来源：ACL-2016" class="headerlink" title="来源：ACL 2016"></a>来源：ACL 2016</h2><h2 id="问题：如何从大量非结构化文本中select出合适的response返回给用户？"><a href="#问题：如何从大量非结构化文本中select出合适的response返回给用户？" class="headerlink" title="问题：如何从大量非结构化文本中select出合适的response返回给用户？"></a>问题：如何从大量非结构化文本中select出合适的response返回给用户？</h2><h2 id="方法：-2"><a href="#方法：-2" class="headerlink" title="方法："></a>方法：</h2><p>本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：</p>
<p>1、response检索，根据query，从documents中找到合适的N句话作为候选。</p>
<p>2、response排序，将候选中的utterances进行排序。</p>
<p>本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。</p>
<p>3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。</p>
<h2 id="评论：-2"><a href="#评论：-2" class="headerlink" title="评论："></a>评论：</h2><p>本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。</p>
<p>1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;media/1.png&quot; alt=&quot;1&quot;&gt;&lt;br&gt;图片来自paper &lt;a href=&quot;https://www.microsof
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>pet,baby and bot</title>
    <link href="http://rsarxiv.github.io/2016/08/16/pat-baby-and-bot/"/>
    <id>http://rsarxiv.github.io/2016/08/16/pat-baby-and-bot/</id>
    <published>2016-08-16T16:06:36.000Z</published>
    <updated>2016-08-16T21:07:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。</p>
<p>首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。</p>
<p>我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。</p>
<p>pet的事情我们先聊到这里，接下来聊一聊baby的事情。</p>
<p>身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。</p>
<p>说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。</p>
<p>小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。</p>
<p>1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。</p>
<p>2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。</p>
<p>3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。</p>
<p>4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。</p>
<p>5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。</p>
<p>从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。&lt;/p&gt;
&lt;p&gt;首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
</feed>
